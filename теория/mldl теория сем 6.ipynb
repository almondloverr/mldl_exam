{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ОГЛАВЛЕНИЕ**\n",
    "\n",
    "[1. Модель перцептрона. Проблема линейно неразделимых множеств и ее решение. Логика построения многослойных ИНС.](#_xdecv9uw1gd2)\n",
    "\n",
    "[2.     Функции активации. Требования к функциям активации Популярные функции активации.](#_wa8ipr7gx2gj)\n",
    "\n",
    "[3.     Глубокое обучение. «Вторая весна искусственного интеллекта» и ее причины.](#_kxkyf4r1zlp2)\n",
    "\n",
    "[4.     Линейное отображение. Векторно-матричное дифференцирование.](#_d8i3ccb2ikik)\n",
    "\n",
    "[5.     Проблема поиска градиента в общей логике обучения нейронной сети. Градиент функции многих переменных. Методы вычисления.](#_7n68o7ss7zbb)\n",
    "\n",
    "[6.     Кросс-валидация. Выборки train, validation, test. Проблема переобучения. Ранняя остановка.](#_bncc34v5i7ve)\n",
    "\n",
    "[7.     Преобразование Softmax и функция потерь Cross Entropy loss.](#_w9eb1qjyju1)\n",
    "\n",
    "[8.     Механизм обратного распространения ошибки.](#_kre7tkw9dm25)\n",
    "\n",
    "[9.     Дифференцируемое программирование и реализация обратного распространения ошибки.](#_8y6r0zczs3t)\n",
    "\n",
    "[10.  Стохастический градиентный спуск. Батчи обучающей выборки.](#_kvapya6q2ntq)\n",
    "\n",
    "[11.  Адаптивные методы градиентного спуска. Метод импульсов. Метод Нестерова.](#_neamc5qhwd61)\n",
    "\n",
    "[12.  Проблема инициализации весов при обучении ИНС. Инициализация Ксавье.](#_7v3029k0t0ig)\n",
    "\n",
    "[13.  Гиперпараметры. Скорость обучения и размер батча.](#_tjljcqrt0hjo)\n",
    "\n",
    "[14.  Переобучение модели и регуляризация. Dropout.](#_jiakoxpcorgd)\n",
    "\n",
    "[15.  Минбатчи – причина использования. Нормализация по мини-батчам.](#_5shaez93hiaq)\n",
    "\n",
    "[16.  Многослойные сети. Граф потока вычислений.](#_o5v9vnv62pm7)\n",
    "\n",
    "[17.  Специфика задач машинного обучения на изображениях. Принцип работы сверточных сетей. Преимущества сверточных сетей при решении этих задач.](#_ody41rdnap40)\n",
    "\n",
    "[18.  Архитектура многослойной ИНС распознавания изображений на основе сверточных сетей.](#_yqknt9yj7o2t)\n",
    "\n",
    "[19.  Приемы для глубокого обучения на небольших наборах изображений.](#_idfo912cs870)\n",
    "\n",
    "[20.  Схема работ слоя сверточной сети. Пулинг. Гиперпараметры: padding, kernel size, stride, dilation.](#_1e7x11n0uyb)\n",
    "\n",
    "[21.  Задачи обработки текста: дистрибутивная семантика, матрица совместной встречаемости, представление слов в виде векторов малой размерности.](#_5uswhwv18uv8)\n",
    "\n",
    "[22.  Word2vec: модель CBOW.](#_xh8rp5sirjy6)\n",
    "\n",
    "[23.  Word2vec: модель Skip-Gram.](#_8lyw2nszslxm)\n",
    "\n",
    "[24.  Рекуррентная нейронная сеть, принципы ее обучения. Сложности применения рекуррентных нейронных сетей.](#_3ejcf8toot35)\n",
    "\n",
    "[25.  Модуль LSTM.](#_hgsznhijpdp9)\n",
    "\n",
    "[26.  Механизм Attention. Пример использования Attention.](#_x1biyos9tkhq)\n",
    "\n",
    "[27.  Архитектура Transformer.](#_62zujsf74go8)\n",
    "\n",
    "[28.  Модель BERT.](#_9ssq0ztrin0b)\n",
    "\n",
    "[29.  Класс Tensor. Операции, изменяющие размер тензора. Операции агрегации.](#_1fl0qd9nz02i)\n",
    "\n",
    "[30.  Принципиальная логика обучения нейронной сети.](#_ykxureqwngs7)\n",
    "\n",
    "[31.  Автоматическое дифференцирование в PyTorch. Пример и применение в обучении ИНС.](#_1ps03u9gp5h3)\n",
    "\n",
    "[32.  Загрузка и преобразование данных. Классы Dataset, DataLoader, Transforms (и композиция трансформеров).](#_v1zsqwgka1zx)\n",
    "\n",
    "[33.  Класс nn.Module. Назначение. Основные поля, методы.](#_a3obv2hsgvpk)\n",
    "\n",
    "[34.  Линейные слои (Linear Layers).](#_7qfg7qnwnu6t)\n",
    "\n",
    "[35.  Слои нелинейной активации (Non Linear Activations).](#_36550ywvw9xw)\n",
    "\n",
    "[36.  Слои нормализации (Normalization Layers).](#_lkn12j3n412c)\n",
    "\n",
    "[37.  Слои регуляризации (Dropout Layers).](#_r5m9vub88xia)\n",
    "\n",
    "[38.  Сверточные слои (Convolution Layers). Сжимающие слои (Pooling Layers).](#_i3mapvr8ryuz)\n",
    "\n",
    "[39.  Слои функций потерь (Loss Functions).](#_26s9kwio6sqp)\n",
    "\n",
    "[40.  Слои эмбеддингов nn.Embedding и их применение.](#_1n63h6eqv0b5)\n",
    "\n",
    "[41.  Класс torch.nn.LSTM и torch.nn.GRU.](#_1nzci3hj79ax)\n",
    "\n",
    "## <a name=\"_xdecv9uw1gd2\"></a>**1. Модель перцептрона. Проблема линейно неразделимых множеств и ее решение. Логика построения многослойных ИНС.**\n",
    "Модель перцептрона является одной из самых простых форм нейронных сетей. В идеальной ситуации, перцептрон может быть использован для разделения двух линейно разделимых классов данных. Однако, если классы данных не могут быть линейно разделены, то возникает проблема линейно неразделимых множеств.\n",
    "\n",
    "Проблема линейно неразделимых множеств может быть решена путем использования многослойных нейронных сетей, таких как многослойные перцептроны (MLP) или глубокие нейронные сети. \n",
    "\n",
    "Многослойный перцептрон (MLP) состоит из нескольких слоев нейронов, включая входной слой, скрытые слои и выходной слой. Каждый нейрон в слое связан с нейронами в соседних слоях. Нейроны в скрытых слоях и выходном слое обычно имеют нелинейную функцию активации, такую как сигмоидальная функция или функция ReLU (Rectified Linear Unit).\n",
    "\n",
    "Идея построения многослойных нейронных сетей заключается в том, чтобы позволить нейронной сети учиться более сложным нелинейным отображениям данных. Каждый скрытый слой может изучать новые признаки или абстракции, на основе которых выходной слой может принять окончательное решение о классификации данных.\n",
    "\n",
    "Обучение многослойных нейронных сетей, таких как MLP, обычно выполняется с использованием алгоритма обратного распространения ошибки (backpropagation). Этот алгоритм позволяет нейронной сети корректировать веса связей между нейронами во время обучения, минимизируя ошибку между предсказанными и фактическими значениями.\n",
    "\n",
    "Таким образом, использование многослойных нейронных сетей позволяет решать проблему линейно неразделимых множеств и обрабатывать более сложные задачи классификации или регрессии.\n",
    "\n",
    "## <a name=\"_wa8ipr7gx2gj\"></a>**2.     Функции активации. Требования к функциям активации Популярные функции активации.**\n",
    "Функции активации являются неотъемлемой частью нейронных сетей и используются для введения нелинейности в выходные значения нейронов. Они применяются после выполнения взвешенной суммы входов нейрона для определения его активации или выхода.\n",
    "\n",
    "**Требования к функциям активации:**\n",
    "\n",
    "1\\. Нелинейность: Функции активации должны быть нелинейными, поскольку линейные функции активации приводят к эквивалентности многослойных сетей однослойным сетям.😭2. Дифференцируемость: Функции активации должны быть дифференцируемыми, чтобы градиентный спуск и обратное распространение ошибки могли быть применены для обучения нейронных сетей.\n",
    "\n",
    "3\\. Монотонность: Желательно, чтобы функции активации были монотонными, то есть, чем больше вход, тем больше выход функции активации.\n",
    "\n",
    "**Некоторые из популярных функций активации в нейронных сетях:**\n",
    "\n",
    "1\\. Сигмоидная функция (Sigmoid): Функция, которая сжимает входное значение в диапазоне от 0 до 1. Она определена как f(x) = 1 / (1 + exp(-x)).\n",
    "\n",
    "2\\. Гиперболический тангенс (Tanh): Похожа на сигмоидную функцию, но сжимает входное значение в диапазоне от -1 до 1. Она определена как f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x)).\n",
    "\n",
    "3\\. Функция ReLU (Rectified Linear Unit): Является простой нелинейной функцией, которая возвращает 0 для отрицательных значений и само значение для положительных значений. Она определена как f(x) = max(0, x).\n",
    "\n",
    "4\\. Leaky ReLU: Похожа на функцию ReLU, но имеет небольшой наклон для отрицательных значений, чтобы избежать нулевого градиента. Она определена как f(x) = max(0.01x, x).\n",
    "\n",
    "5\\. Гиперболический тангенс с усечением (Hard Tanh): Аналогично функции Tanh, но с усечением значений в диапазоне от -1 до 1. Она определена как f(x) = max(-1, min(1, x)).\n",
    "\n",
    "6\\. Softmax: Часто используется в последнем слое нейронной сети для многоклассовой классификации. Преобразует входные значения в вероятности, сумма которых равна 1.\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.001.png)\n",
    "## <a name=\"_kxkyf4r1zlp2\"></a>**3.     Глубокое обучение. «Вторая весна искусственного интеллекта» и ее причины.**\n",
    "Глубокое обучение — это подобласть машинного обучения, которая использует нейронные сети с несколькими слоями для извлечения высокоуровневых признаков из данных. Оно получило большую популярность и стало прорывом в области искусственного интеллекта благодаря нескольким факторам.\n",
    "\n",
    "**\"Вторая весна искусственного интеллекта\"** - это термин, который относится к возрождению и прорыву глубокого обучения, произошедшему в последние годы. \n",
    "\n",
    "**Этот прорыв обусловлен несколькими факторами:**\n",
    "\n",
    "1\\. Увеличение доступности данных: С появлением Интернета и развитием цифровых технологий мы собираем и генерируем огромные объемы данных. Доступность больших наборов данных (Big Data) стала одним из ключевых факторов успеха глубокого обучения. Большие наборы данных позволяют обучать сложные модели глубокого обучения, которые способны извлекать более сложные и абстрактные признаки.\n",
    "\n",
    "2\\. Вычислительная мощность: Графические процессоры (GPU) и специализированные аппаратные ускорители, такие как тензорные процессоры (TPU), стали доступны для обучения нейронных сетей. Эти вычислительные ресурсы позволяют эффективно выполнять операции с большими матрицами и ускоряют процесс обучения глубоких моделей.\n",
    "\n",
    "3\\. Архитектурные инновации: В процессе развития глубокого обучения были предложены новые архитектуры нейронных сетей, такие как сверточные нейронные сети (CNN) для обработки изображений и рекуррентные нейронные сети (RNN) для обработки последовательностей. Также появились архитектуры, основанные на внимании (attention), такие как трансформеры (transformers), которые показали выдающиеся результаты в обработке естественного языка и машинном переводе.\n",
    "\n",
    "4\\. Улучшение алгоритмов обучения: Появление новых методов оптимизации, таких как стохастический градиентный спуск (SGD) с моментом, адаптивные методы оптимизации (например, Adam), нормализация пакетов (batch normalization) и др., значительно улучшило процесс обучения глубоких моделей.\n",
    "\n",
    "Все эти факторы вместе способствовали второй волне развития глубокого обучения и привели к его широкому применению в различных областях, таких как компьютерное зрение, обработка естественного языка, речевые технологии и многое другое.\n",
    "\n",
    "## <a name=\"_d8i3ccb2ikik\"></a>**4.     Линейное отображение. Векторно-матричное дифференцирование.**\n",
    "Линейное отображение в математике относится к отображению между двумя векторными пространствами, которое обладает двумя основными свойствами: сохранением линейных комбинаций и сохранением скалярного умножения. Формально, линейное отображение L: V -> W между векторными пространствами V и W определено следующим образом:\n",
    "\n",
    "1\\. L(u + v) = L(u) + L(v) для всех u, v из V (сохранение линейных комбинаций).\n",
    "\n",
    "2\\. L(αu) = αL(u) для всех α из полей скаляров и всех u из V (сохранение скалярного умножения).\n",
    "\n",
    "Здесь u и v - произвольные векторы из V, α - произвольный скаляр, а L(u) и L(v) - соответствующие образы этих векторов в W.\n",
    "\n",
    "Векторно-матричное дифференцирование является техникой дифференцирования, применяемой для нахождения производных линейных отображений, представленных в виде матриц. Когда линейное отображение задается матрицей A, векторно-матричное дифференцирование позволяет находить производные этого отображения по отношению к входным векторам.\n",
    "\n",
    "Пусть f(x) = Ax, где A - матрица размерности m x n, а x - вектор размерности n. Тогда производная отображения f(x) по вектору x, обозначаемая как df(x)/dx или ∂f/∂x, может быть найдена путем векторно-матричного дифференцирования.\n",
    "\n",
    "Результатом векторно-матричного дифференцирования является матрица, называемая матрицей Якобиана или матрицей производных. Матрица Якобиана имеет размерность m x n и содержит частные производные элементов функции f(x) по элементам вектора x.\n",
    "\n",
    "Векторно-матричное дифференцирование является важным инструментом в оптимизации, обратном распространении ошибки (backpropagation) в нейронных сетях и других областях, где требуется нахождение градиента или производных линейных отображений.\n",
    "\n",
    "## <a name=\"_7n68o7ss7zbb\"></a>**5.     Проблема поиска градиента в общей логике обучения нейронной сети. Градиент функции многих переменных. Методы вычисления.**\n",
    "\n",
    "Проблема поиска градиента в общей логике обучения нейронной сети связана с тем, что нейронные сети обычно имеют большое количество параметров, и вычисление градиента функции с таким количеством переменных может быть вычислительно затратным и требовать большого объема памяти. Это может стать препятствием для эффективного обучения модели.\n",
    "\n",
    "Градиент функции многих переменных представляет собой вектор, состоящий из частных производных функции по каждой переменной. Для функции f(x₁, x₂, ..., xn), где x₁, x₂, ..., xn - переменные, градиент функции обозначается как ∇f или grad(f) и определяется следующим образом:\n",
    "\n",
    "∇f = (∂f/∂x₁, ∂f/∂x₂, ..., ∂f/∂xn)\n",
    "\n",
    "Методы вычисления градиента функции многих переменных включают:\n",
    "\n",
    "1\\. Аналитический метод: Если функция f(x) имеет аналитическую формулу, то градиент может быть вычислен аналитически путем нахождения частных производных функции по каждой переменной.\n",
    "\n",
    "2\\. Численный метод: В численных методах градиент вычисляется приближенно путем численного дифференцирования. Наиболее распространенными численными методами являются метод конечных разностей и метод конечных разностей со сглаживанием (smoothed finite differences).\n",
    "\n",
    "3\\. Автоматическое дифференцирование: Этот метод использует вычислительные графы и цепное правило дифференцирования для автоматического вычисления градиента. Автоматическое дифференцирование позволяет вычислить градиент функции, используя только значение функции и операции, применяемые для ее вычисления, без явного вычисления аналитической формулы или численного дифференцирования.\n",
    "\n",
    "4\\. Градиентный спуск с обратным распространением ошибки (backpropagation): В контексте обучения нейронных сетей, градиентный спуск с обратным распространением ошибки является методом вычисления градиента для обновления весов нейронной сети. Он использует цепное правило дифференцирования для эффективного вычисления градиента на основе ошибки модели.\n",
    "\n",
    "Эти методы позволяют эффективно вычислять градиент функции многих переменных и используются в различных задачах оптимизации и обучения нейронных сетей.\n",
    "\n",
    "## <a name=\"_bncc34v5i7ve\"></a>**6.     Кросс-валидация. Выборки train, validation, test. Проблема переобучения. Ранняя остановка.**\n",
    "### <a name=\"_ho4krhguf68j\"></a>**Кросс-валидация**\n",
    "Кросс-валидация (перекрестная проверка) – это метод оценки Моделей (Model) Машинного обучения (ML) путем обучения нескольких из них на подмножествах доступных входных данных и их оценки на другом дополнительном подмножестве. Такая проверка используется для обнаружения Переобучения (Overfitting), т.е. неспособности распознать паттерн.\n",
    "\n",
    "Всегда необходимо проверять стабильность предсказывающего Алгоритма (Algorithm): нам нужна уверенность в том, что модель имеет представление о большинстве шаблонов в данных, что ее эффективность не падает от шумных данных.\n",
    "#### <a name=\"_1vb4a6em7x2e\"></a>**Метод hold-out**\n",
    "Метод hold-out представляет из себя простое разделение на train и test\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model\\_selection import train\\_test\\_split\n",
    "\n",
    "X, y = np.arange(1000).reshape((500, 2)), np.arange(500)\n",
    "\n",
    "X\\_train, X\\_test, y\\_train, y\\_test = train\\_test\\_split(\n",
    "\n",
    "`\t`X, y,\n",
    "\n",
    "`\t`test\\_size=0.2,\n",
    "\n",
    "`\t`random\\_state=42\n",
    "\n",
    ")\n",
    "#### <a name=\"_j0uweujp9ekr\"></a>**Метод k-Fold**\n",
    "Метод k-Fold чаще всего имеют в виду, когда говорят о кросс-валидации. Он является обобщением метода hold-out и представляет из себя следующий алгоритм:\n",
    "\n",
    "·        Фиксируется некоторое целое число *k* (обычно от 5 до 10), меньшее числа семплов в датасете.\n",
    "\n",
    "·        Датасет разбивается на *k* одинаковых частей (в последней части может быть меньше семплов, чем в остальных). Эти части называются фолдами.\n",
    "\n",
    "·        Далее происходит *k* итераций, во время каждой из которых один фолд выступает в роли тестового множества, а объединение остальных — в роли тренировочного. Модель учится на *k – 1* фолде и тестируется на оставшемся.\n",
    "\n",
    "·        Финальный скор модели получается либо усреднением *k* получившихся тестовых результатов, либо измеряется на отложенном тестовом множестве, не участвовавшем в кросс-валидации.\n",
    "\n",
    "**Sklearn: from** sklearn.model\\_selection **import** KFold\n",
    "### <a name=\"_v3lovexbp7wn\"></a>**Выборки:**\n",
    "Обучающая выборка (training sample) — выборка, по которой производится настройка (оптимизация параметров) модели зависимости.\n",
    "\n",
    "Если модель зависимости построена по обучающей выборке X^m, то оценка качества этой модели, сделанная по той же выборке X^m оказывается, как правило, оптимистически смещённой. Это нежелательное явление называют переобучением. На практике оно встречается очень часто. Хорошую эмпирическую оценку качества построенной модели даёт её проверка на независимых данных, которые не использовались для обучения.\n",
    "\n",
    "Тестовая (или контрольная) выборка (test sample) — выборка, по которой оценивается качество построенной модели. Если обучающая и тестовая выборки независимы, то оценка, сделанная по тестовой выборке, является несмещённой.\n",
    "\n",
    "Оценку качества, сделанную по тестовой выборке, можно применить для выбора наилучшей модели. Однако тогда она снова окажется оптимистически смещённой. Для получения немсещённой оценки выбранной модели приходится выделять третью выборку.\n",
    "\n",
    "Проверочная выборка (validation sample) — выборка, по которой осуществляется выбор наилучшей модели из множества моделей, построенных по обучающей выборке.\n",
    "### <a name=\"_ulou6x5okx9j\"></a>**Переобучение:**\n",
    "Переобучение — это явление, когда обучаемая модель хорошо распознает примеры из обучающего множества, но при этом не распознает или плохо распознает любые другие примеры, не участвовавшие в процессе обучения (т.е. предъявляемые ей в процессе практического использования).\n",
    "\n",
    "Переобучение — это результат чрезмерной подгонки параметров модели к зависимостям, содержащимся в обучающем множестве. Если происходит переобучение, то модель не приобретает способности к обобщению — возможности распространять обнаруженные на обучающем множестве зависимости и закономерности на новые данные.\n",
    "\n",
    "Проблема переобучения в той или иной степени характерна для всех видов обучаемых моделей, но особенно остро она стоит для нейронных сетей. В процессе обучения производится подгонка весов нейронной сети таким образом, что сеть преобразовывала входы к желаемым выходам в соответствии с зависимостями, обнаруженными в обучающих данных.\n",
    "\n",
    "Для того, чтобы избежать переобучения, можно использовать следующие несложные правила.\n",
    "\n",
    "·        Применение тестового множества. Тестовое множество формируется из обучающего набора данных случайным образом и его примеры подаются на вход сети между обучающими примерами, но корректировку весов сети на вызывают. Вначале обучения ошибка и на обучающем, и на тестовом множестве уменьшаются. Но начиная с какого-то ошибка на тестовом множестве начинает расти. Это сигнализирует о начале переобучения и необходимости принудительно остановить процесс обучения.\n",
    "\n",
    "·        Использование перекрёстной проверки. Все данные, на которых строится модель, разделяются на k блоков равного размера. При этом обучение производится на k-1 блоках, а тестирование — на k-м. Процедура повторяется k раз, при этом для тестирования каждый раз выбирается другой блок. В результате все блоки оказываются используемыми и как обучающие, и как тестирующие.\n",
    "\n",
    "·        Выбор конфигурации нейронной сети. Нужно выбирать конфигурацию сети (число слоёв и нейронов), чтобы количество параметров модели (весов) была в 2-3 раза меньше числа примеров обучающего множества. Если число параметров модели и обучающих примеров окажется соизмеримым, то сеть просто «запомнит» все комбинации вход-выход в примерах обучающего множества, и будет воспроизводить только их, а на новых данных допускать ошибки.\n",
    "### <a name=\"_g1lsaurtrjna\"></a>**Ранняя остановка**\n",
    "Ранняя остановка (early stopping) - это метод регуляризации в машинном обучении, который позволяет избежать переобучения модели.\n",
    "\n",
    "Суть метода заключается в том, что обучение модели прерывается, когда ошибка на тестовых данных начинает увеличиваться. Это происходит потому, что в начале обучения модель обучается на более общих паттернах, которые лучше обобщают данные, а в конце обучения модель начинает запоминать шумы и нюансы в данных, что приводит к переобучению.\n",
    "\n",
    "Ранняя остановка может быть реализована путем отслеживания ошибки на тестовых данных на каждой эпохе обучения. Если ошибка на тестовых данных начинает увеличиваться, обучение прерывается и модель сохраняется на последней эпохе, когда ошибка на тестовых данных была минимальной. \n",
    "### <a name=\"_blrltanr96bl\"></a>**Обобщенно и кратко**\n",
    "При разработке моделей машинного обучения очень важно не только обучить модель на данных обучающей выборки, но и оценить качество ее работы на независимых данных, которые отличаются от тех, на которых модель была обучена.\n",
    "\n",
    "Для этого необходимо использовать тестовую выборку, которая должна быть независима от обучающей и содержать данные, которые модель еще не видела в процессе обучения. Оценка качества модели на тестовой выборке позволяет оценить ее способность обобщать данные и делать предсказания на новых данных.\n",
    "\n",
    "Для избежания переобучения модели, когда она получает хороший результат на обучающей выборке, но плохой на новых данных, можно применять различные методы регуляризации. Один из таких методов - ранняя остановка, заключается в прерывании обучения модели, когда ошибка на тестовых данных начинает увеличиваться. Это происходит потому, что в начале обучения модель обучается на более общих паттернах, которые лучше обобщают данные, а в конце обучения модель начинает запоминать шумы и нюансы в данных, что приводит к переобучению. Таким образом, ранняя остановка позволяет сохранять модель на этапе, когда ее качество на тестовых данных было оптимальным и избежать переобучения.\n",
    "\n",
    "Для выбора наилучшей модели можно также использовать перекрестную проверку. Данные разделяются на k блоков, из которых один блок используется для тестирования, а остальные для обучения. Процедура повторяется k раз, при этом для тестирования каждый раз выбирается другой блок. Этот метод позволяет получить более надежную оценку качества модели, так как каждый блок данных используется как для обучения, так и для тестирования.\n",
    "\n",
    "Еще одним методом регуляризации является выбор конфигурации нейронной сети. Необходимо выбирать конфигурацию сети (число слоев и нейронов), чтобы количество параметров модели (весов) было в 2-3 раза меньше числа примеров обучающего множества. Если число параметров модели и обучающих примеров окажется соизмеримым, то сеть просто «запомнит» все комбинации вход-выход в примерах обучающего множества, и будет воспроизводить только их, а на новых данных допускать ошибки.\n",
    "\n",
    "В целом, использование различных методов регуляризации и оценки качества модели на независимых данных позволяет избежать переобучения и получить более надежные результаты предсказаний.\n",
    "\n",
    "## <a name=\"_w9eb1qjyju1\"></a>**7.     Преобразование Softmax и функция потерь Cross Entropy loss.**\n",
    "### <a name=\"_4jc7uaf4ehtr\"></a>**Softmax**\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.002.png)\n",
    "\n",
    "График функции\n",
    "\n",
    "Софтмакс – функция, превращающая логиты (наборы чисел) в вероятности, причем сумма последних равна единице. Функция выводит в качестве результата вектор, представляющий распределения вероятностей списка потенциальных результатов.\n",
    "\n",
    "Формула функции Softmax выглядит следующим образом:\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.003.png)\n",
    "\n",
    "где z\\_i - это элемент входного вектора, а k - это общее число элементов в векторе.\n",
    "\n",
    "График функции Softmax представляет собой гладкую кривую, начинающуюся от 0 и заканчивающуюся на 1, что соответствует сумме вероятностей всех элементов вектора. Кривая функции Softmax имеет свойство, что вероятность любого элемента вектора увеличивается, если значения других элементов уменьшаются, что позволяет использовать эту функцию для многоклассовой классификации.\n",
    "\n",
    "Хотя функция Softmax имеет множество применений в машинном обучении, она также может иметь недостатки, такие как чувствительность к выбросам и несбалансированным данным, что может приводить к неверным вероятностным оценкам.\n",
    "### <a name=\"_jaz8wcr5towb\"></a>**Cross entropy loss**\n",
    "Функция потерь перекрестной энтропии – это метрика, позволяющая оценить, насколько хорошо функционирует модель классификации в машинном обучении. Потеря (или ошибка) оценивается как число, находящееся между 0 и 1, где 0 – идеальная модель. Цель, как правило, заключается в том, чтобы максимально приблизить вашу модель к 0.\n",
    "\n",
    "Функцию потерь перекрестной энтропии часто считают взаимозаменяемой с логистической ошибкой (или логистической функцией потерь и иногда рассматриваемой как функция потерь бинарной перекрестной энтропии), но это не всегда корректно.\n",
    "\n",
    "Используя перекрестную энтропию, можно оценить ошибку (или разницу) между двумя вероятностными распределениями.\n",
    "\n",
    "Например, в случае бинарной классификации перекрестная энтропия определяется как:\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.004.png)\n",
    "\n",
    "где:\n",
    "\n",
    "p – предсказанная вероятность и\n",
    "\n",
    "y – индикатор (0 или 1 в случае бинарной классификации)\n",
    "\n",
    "Реализация:\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "### <a name=\"_a33hyiszdpxu\"></a>**Обобщенно и кратко**\n",
    "Softmax - функция, которая преобразует логиты в вероятности, где сумма вероятностей равна единице. Функция Softmax может использоваться для многоклассовой классификации. Она имеет свойство, что вероятность любого элемента вектора увеличивается, если значения других элементов уменьшаются. Однако, она может быть чувствительной к выбросам и несбалансированным данным, что приводит к неверным вероятностным оценкам.\n",
    "\n",
    "Функция потерь перекрестной энтропии используется для оценки, насколько хорошо функционирует модель классификации в машинном обучении. Потеря оценивается как число, находящееся между 0 и 1, где 0 – идеальная модель. Она может быть использована для оценки ошибки между двумя вероятностными распределениями. В случае бинарной классификации, перекрестная энтропия определяется как p - предсказанная вероятность и y - индикатор (0 или 1 в случае бинарной классификации).\n",
    "\n",
    "## <a name=\"_kre7tkw9dm25\"></a>**8.     Механизм обратного распространения ошибки.**\n",
    "Механизм обратного распространения ошибки - это алгоритм, используемый в нейронных сетях для обучения модели с учителем.\n",
    "\n",
    "Он работает путем вычисления градиента функции потерь по параметрам модели и последующего изменения этих параметров с целью минимизации потерь.\n",
    "\n",
    "Процесс начинается с передачи входных данных через нейронную сеть для получения предсказаний. Затем вычисляется ошибка между предсказанными значениями и фактическими значениями.\n",
    "\n",
    "Далее, ошибка обратно распространяется через сеть, и для каждого параметра вычисляется его вклад в общую ошибку. Это делается с помощью цепного правила дифференцирования.\n",
    "\n",
    "И, наконец, параметры модели обновляются с использованием градиентного спуска, чтобы минимизировать ошибку.\n",
    "\n",
    "Механизм обратного распространения ошибки является основой обучения нейронных сетей и имеет широкое применение в различных областях, включая компьютерное зрение, обработку естественного языка и другие.\n",
    "\n",
    "## <a name=\"_8y6r0zczs3t\"></a>**9.     Дифференцируемое программирование и реализация обратного распространения ошибки.**\n",
    "Дифференцируемое программирование – это подход к машинному обучению, который позволяет оптимизировать модели, используя градиенты функций ошибок. Он используется для поиска наилучших параметров модели, которые минимизируют ошибки на обучающих данных.\n",
    "\n",
    "Дифференцируемое программирование основано на математической концепции дифференцирования, которая используется для вычисления производных функций. В машинном обучении дифференцирование используется для нахождения градиента функции ошибок – величины, которая показывает, как изменится значение функции ошибок при изменении параметров модели.\n",
    "\n",
    "Одной из самых популярных техник дифференцируемого программирования является обратное распространение ошибки. Эта техника позволяет вычислить градиент функции ошибок по отношению к весам модели.\n",
    "\n",
    "Обратное распространение ошибки работает путем прохода через модель в обратном направлении, начиная с выходных значений и заканчивая входными значениями. Во время этого процесса вычисляются градиенты функций активации и весов, используемых в модели.\n",
    "\n",
    "В настоящее время существует множество библиотек и фреймворков, которые предоставляют реализацию обратного распространения ошибки для различных типов моделей. Эти инструменты делают дифференцируемое программирование доступным для широкого круга исследователей и разработчиков, которые хотят создавать более эффективные и точные модели машинного обучения.\n",
    "\n",
    "## <a name=\"_kvapya6q2ntq\"></a>**10.  Стохастический градиентный спуск. Батчи обучающей выборки.**\n",
    "### <a name=\"_x3d2178bu85t\"></a>**Стохастический градиентный спуск**\n",
    "Стохастический градиентный спуск (Stochastic Gradient Descent) - это алгоритм оптимизации, используемый для обучения машинного обучения. Он является одним из самых популярных алгоритмов обучения и широко применяется в различных задачах, таких как распознавание образов, классификация и регрессия.\n",
    "\n",
    "Основная идея стохастического градиентного спуска заключается в том, чтобы на каждом шаге обновлять параметры модели, используя градиент функции потерь, вычисленный на небольшом подмножестве обучающих данных (батче). В отличие от обычного градиентного спуска, который вычисляет градиент на всей обучающей выборке, стохастический градиентный спуск может работать гораздо быстрее, так как он использует только часть данных на каждом шаге.\n",
    "\n",
    "Другим важным преимуществом стохастического градиентного спуска является его способность работать с большими объемами данных. Вместо того, чтобы загружать все данные в память компьютера, как это делается при использовании обычного градиентного спуска, стохастический градиентный спуск может использовать данные порциями и обновлять параметры модели на каждом шаге.\n",
    "\n",
    "Несмотря на свою эффективность, стохастический градиентный спуск имеет свои недостатки. В частности, из-за случайности выбора подмножества данных на каждом шаге, алгоритм может сходиться к локальному минимуму вместо глобального. Также возможен риск переобучения модели, особенно если размер батча слишком мал.\n",
    "### <a name=\"_ods5czxlnkt6\"></a>**Батчи обучающей выборки**\n",
    "Батчи обучающей выборки - это подмножества данных, которые используются для обновления параметров модели на каждом шаге стохастического градиентного спуска. В машинном обучении, обучающая выборка - это набор данных, который используется для тренировки модели. Она состоит из множества примеров, каждый из которых представляет собой пару входных и выходных значений. Батчи выборки - это небольшие группы примеров, которые передаются модели для обновления ее параметров.\n",
    "\n",
    "Выбор размера батча является важным гиперпараметром при использовании стохастического градиентного спуска. Размер батча определяет, сколько примеров будет использоваться на каждом шаге для обновления параметров модели. Он может оказать значительное влияние на эффективность и скорость обучения модели.\n",
    "\n",
    "Существует компромисс между размером батча и стабильностью обучения. Маленькие батчи могут привести к быстрой сходимости, так как они требуют меньшего количества вычислений, но могут также вызвать нестабильность градиента, что может привести к неэффективному обучению модели. Большие же батчи могут оказаться более стабильными, но могут также привести к более медленной сходимости, так как они требуют большего количества вычислений.\n",
    "\n",
    "Выбор оптимального размера батча зависит от конкретной задачи и может потребовать некоторых экспериментов. Например, при обработке изображений и видео, рекомендуется использовать батчи размером от нескольких десятков до нескольких сотен элементов, так как они требуют большого количества вычислений, а использование слишком маленьких батчей может привести к нестабильности градиента. Однако, в целом, выбор оптимального размера батча зависит от конкретной задачи и может потребовать некоторых экспериментов.\n",
    "### <a name=\"_vp4dj85im73u\"></a>**Обобщенно и кратко**\n",
    "Стохастический градиентный спуск (Stochastic Gradient Descent) является одним из самых популярных алгоритмов обучения машинного обучения. Он используется для обучения моделей в различных задачах, таких как распознавание образов, классификация и регрессия. Основная идея стохастического градиентного спуска заключается в том, чтобы на каждом шаге обновлять параметры модели, используя градиент функции потерь, вычисленный на небольшом подмножестве обучающих данных (батче). В отличие от обычного градиентного спуска, который вычисляет градиент на всей обучающей выборке, стохастический градиентный спуск может работать гораздо быстрее, так как он использует только часть данных на каждом шаге. Это также позволяет ему работать с большими объемами данных. Батчи обучающей выборки - это подмножества данных, которые используются для обновления параметров модели на каждом шаге стохастического градиентного спуска. Выбор размера батча является важным гиперпараметром при использовании стохастического градиентного спуска. Размер батча определяет, сколько примеров будет использоваться на каждом шаге для обновления параметров модели. Существует компромисс между размером батча и стабильностью обучения. Оптимальный размер батча зависит от конкретной задачи и может потребовать некоторых экспериментов.\n",
    "## <a name=\"_neamc5qhwd61\"></a>**11.  Адаптивные методы градиентного спуска. Метод импульсов. Метод Нестерова.**\n",
    "\n",
    "Адаптивные методы градиентного спуска разработаны для оптимизации скорости обучения по отдельности для каждого параметра. Это особенно полезно при работе с многомерными и разреженными данными. Примеры включают:\n",
    "\n",
    "- Adagrad: Изменяет скорость обучения на основе частоты параметра в данных. Параметры, которые встречаются часто, получают меньший шаг обучения, в то время как редкие параметры получают больший шаг. Это может быть полезно в задачах обработки естественного языка, где редкие слова необходимо обучать быстрее.\n",
    "- Adadelta и RMSprop: Являются улучшенными версиями Adagrad, которые пытаются решить проблему затухающей скорости обучения. Они делают это, используя скользящее среднее квадратов градиентов вместо накопительной суммы.\n",
    "- Adam: Сочетает идеи Momentum и RMSprop. Он поддерживает скользящее среднее как моментов, так и квадратов градиентов для обновления весов.\n",
    "\n",
    "Метод импульса (Momentum) использует идею физического импульса и применяет ее к градиентному спуску. Это основано на идее, что если мы движемся в определенном направлении, то у нас есть больше шансов продолжить движение в этом же направлении. Это уменьшает колебания и ускоряет сходимость.\n",
    "\n",
    "Метод Нестерова (Nesterov Accelerated Gradient, NAG) представляет собой модификацию метода импульса, где мы сначала делаем большой шаг в направлении предыдущего импульса (моментум), затем вычисляем градиент в новом \"предвосхищенном\" месте и делаем коррекцию. Это приводит к более устойчивым и быстрым обновлениям.\n",
    "\n",
    "## <a name=\"_7v3029k0t0ig\"></a>**12.  Проблема инициализации весов при обучении ИНС. Инициализация Ксавье.**\n",
    "\n",
    "Инициализация весов является важной стадией в обучении нейронных сетей. Причина в том, что начальные веса сети существенно влияют на то, к какому минимуму сходится процесс обучения. Если веса инициализированы неверно, нейронная сеть может столкнуться с проблемами затухания или взрыва градиентов, что замедляет процесс обучения и может привести к плохим результатам.\n",
    "\n",
    "Затухание градиентов возникает, когда веса инициализируются слишком малыми значениями. В результате градиенты могут стать слишком малыми, что замедляет процесс обучения или даже делает его невозможным. Наоборот, взрыв градиентов происходит, когда веса инициализируются слишком большими значениями, и градиенты становятся слишком большими, что приводит к нестабильности в обучении.\n",
    "\n",
    "Инициализация Ксавье, также известная как инициализация Glorot, предлагает решение этой проблемы. Она выбирает веса из равномерного или нормального распределения, которое масштабировано с учетом числа входных и выходных нейронов в слое. Это обеспечивает равномерность вариации активаций и градиентов по слоям, что приводит к более эффективному обучению.\n",
    "\n",
    "Пример реализации в PyTorch:\t\t\t\t\t\t\n",
    "\n",
    "conv1 **=** torch.nn.Conv2d(**...**) \n",
    "\n",
    "torch.nn.init.xavier\\_uniform(conv1.weight) \n",
    "### <a name=\"_jzzwrekpyfgs\"></a>**Из лекции макрушина**\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.005.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.006.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.007.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.008.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.009.png)\n",
    "\n",
    "## <a name=\"_tjljcqrt0hjo\"></a>**13.  Гиперпараметры. Скорость обучения и размер батча.**\n",
    "\n",
    "Гиперпараметры - это параметры, которые определяются до начала процесса обучения и не изменяются во время обучения. Они могут иметь значительное влияние на производительность и скорость обучения модели.\n",
    "\n",
    "Скорость обучения является одним из наиболее важных гиперпараметров. Она определяет, насколько быстро модель обновляет свои веса в ответ на ошибку. Если скорость обучения слишком высока, обучение может стать нестабильным, и модель может пропустить оптимальное решение. Если скорость обучения слишком низкая, обучение может замедлиться, и модель может застрять в локальном минимуме.\n",
    "\n",
    "Размер батча - это количество обучающих примеров, обрабатываемых одновременно. Большой размер батча может ускорить процесс обучения, но также может привести к менее точной оценке градиента. С другой стороны, маленький размер батча может замедлить обучение и увеличить вероятность застревания в локальном минимуме.\n",
    "\n",
    "## <a name=\"_jiakoxpcorgd\"></a>**14.  Переобучение модели и регуляризация. Dropout.**\n",
    "\n",
    "Переобучение (overfitting) - это проблема, при которой модель слишком хорошо обучается на обучающих данных и становится плохо обобщена на новых, неизвестных данных. Это может быть результатом слишком сложной модели или недостаточного количества данных для обучения.\n",
    "\n",
    "Регуляризация - это техника, используемая для предотвращения переобучения, путем добавления штрафа к функции потерь, чтобы ограничить сложность модели. Это может включать L1-регуляризацию (лассо), L2-регуляризацию (гребневая регрессия) или оба вида.\n",
    "\n",
    "Dropout - это техника регуляризации, используемая в нейронных сетях, которая случайным образом исключает (обнуляет) нейроны в слое при каждом прохождении вперед. Это заставляет сеть учиться на более робустных функциях и предотвращает переобучение.\n",
    "\n",
    "### <a name=\"_palm445nslfd\"></a>**Из лекции макрушина**\n",
    "**Проблема переобучения модели**\t\t\t\t\t\t\n",
    "\n",
    "модель, у которой слишком много свободных параметров, **плохо обобщается**: то есть слишком близко «облизывает» точки из тренировочного множества и в результате недостаточно хорошо предсказывает нужные значения в новых точках.\t\t\n",
    "\n",
    "В современных нейронных сетях огромное число параметров (даже не самая сложная архитектура может содержать миллионы весов) **надо регуляризовать параметры**! \n",
    "\n",
    "**Dropout**\n",
    "\n",
    "**Регуляризация с помощью дропаута** (dropout regularization) - один из важнейших методов регуляризации нейронных сетей обеспечивший революцию глубокого обучения. \n",
    "\n",
    "Идея метода (очень простая!):\n",
    "\n",
    "- Для каждого нейрона (кроме самого последнего, выходного слоя) установим некоторую вероятность p, с которой он будет выброшен из сети.\n",
    "\n",
    "Алгоритм обучения меняется таким образом:\n",
    "\n",
    "- на каждом новом тренировочном примере x мы сначала для каждого **разыгрываем вероятность p** и в зависимости от результата либо используем нейрон как обычно, **либо устанавливаем его выход всегда строго равным нулю** (вероятность этого события 1 - p).\n",
    "- **Дальше все происходит без изменений**; ноль на выходе приводит к тому, что нейрон фактически выпадает из графа вычислений: и прямое вычисление, и обратное распространение градиента останавливаются на этом нейроне и дальше не идут.\n",
    "- Для применения обученной сети **используются все нейроны** в конфигурации, которая была до применения дропаута, но **выход каждого нейрона умножается на вероятность p** (с которой нейрон оставляли при обучении)\n",
    "\n",
    "Для очень широкого спектра архитектур и приложений замечательно подходит p = 1/2\n",
    "\n",
    "`\t\t`![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.010.png)\t\t\n",
    "\n",
    "Практика обучения нейронных сетей показывает, что дропаут действительно дает очень серьезные улучшения в качестве обученной модели. \n",
    "\n",
    "Дропаут — это метод добиться **усреднения огромного чмсла моделей** (до 2^N возможных моделей, N — число нейронов, которые подвергаются дропауту). Он эквивалентен усреднению всех моделей, которые получались на каждом шаге случайным выбрасыванием отдельных нейронов. \n",
    "\n",
    "Пример использования dropuot в pytorch: \n",
    "\n",
    "**def** \\_\\_init\\_\\_(self, rnn\\_type, input\\_size, node\\_fdim, hidden\\_size, depth, dropout):\n",
    "\n",
    "super(MPNEncoder, self).\\_\\_init\\_\\_()\n",
    "self.hidden\\_size **=** hidden\\_size\n",
    "self.input\\_size **=** input\\_size\t\t\t\t\t\t\n",
    "\n",
    "self.depth **=** depth self.\n",
    "\n",
    "W\\_o **=** nn.Sequential(\t\t\t\t\t\n",
    "\n",
    "nn.Linear(node\\_fdim **+** hidden\\_size, hidden\\_size),\n",
    "\n",
    "nn.ReLU(),\n",
    "\n",
    "nn.Dropout(dropout)\t\t\t\t\t\t\n",
    "\n",
    ")\t\t\t\t\t\t\n",
    "\n",
    "**if** rnn\\_type **==** 'GRU':\n",
    "\n",
    "self.rnn **=** GRU(input\\_size, hidden\\_size, depth)\t\t\t\t\n",
    "\n",
    "**elif** rnn\\_type **==** 'LSTM':\n",
    "\n",
    "self.rnn **=** LSTM(input\\_size, hidden\\_size, depth)\t\t\t\t\n",
    "\n",
    "**else**:\n",
    "\n",
    "` `**raise** ValueError('unsupported rnn cell type ' **+** rnn\\_type) \n",
    "\n",
    "\n",
    "## <a name=\"_5shaez93hiaq\"></a>**15.  Минбатчи – причина использования. Нормализация по мини-батчам.**\n",
    "\n",
    "Минибатчи используются в обучении моделей для оптимизации процесса обучения. Вместо того чтобы обрабатывать все обучающие примеры сразу или по одному, используется подмножество данных - минибатч. Есть несколько причин использования минибатчей:\n",
    "\n",
    "- Эффективность вычислений: обработка небольших батчей позволяет параллелизовать вычисления, что приводит к более эффективному использованию ресурсов (например, графических процессоров).\n",
    "- Улучшенная сходимость: обновления весов на основе минибатчей дают более точную оценку градиента, чем обновления на основе одного примера, что обычно приводит к более быстрой сходимости.\n",
    "- Уменьшение переобучения: минибатчи добавляют некоторую степень шума в процесс обучения, что может помочь предотвратить переобучение.\n",
    "\n",
    "Нормализация по мини-батчам является техникой масштабирования входов в слои нейронной сети. Вместо масштабирования всех входных данных сразу, она масштабирует каждый минибатч независимо. Это позволяет модели более эффективно справляться с проблемами внутренней ковариации (когда распределение входных данных меняется в процессе обучения), что обычно приводит к ускорению обучения и улучшению обобщающей способности модели.\n",
    "\n",
    "### <a name=\"_t4t47wdycfwa\"></a>**Из лекции макрушина**\n",
    "\n",
    "\n",
    "## <a name=\"_o5v9vnv62pm7\"></a>**16.  Многослойные сети. Граф потока вычислений.**\n",
    "\n",
    "Многослойные сети, также известные как многослойные перцептроны (MLP), состоят из нескольких слоев нейронов, каждый из которых подключен к нейронам следующего слоя. Это позволяет MLP обучаться и представлять более сложные функции, чем однослойные сети. Например, MLP способен представлять функции, которые отображают входные данные в нелинейные пространства признаков, что может быть полезно для задач, в которых линейная разделимость не является возможной.\n",
    "\n",
    "Граф потока вычислений - это визуализация, которая отражает, как операции в нейронной сети соединяются для формирования конечного вывода. Он представляет собой направленный ациклический граф, где каждый узел представляет операцию (например, сложение, умножение, активацию), а ребра представляют тензоры, которые передаются между операциями. Это является основой для многих библиотек глубокого обучения, таких как TensorFlow и PyTorch, и позволяет эффективно вычислять градиенты с использованием метода обратного распространения ошибки.\n",
    "\n",
    "## <a name=\"_ody41rdnap40\"></a>**17.  Специфика задач машинного обучения на изображениях. Принцип работы сверточных сетей. Преимущества сверточных сетей при решении этих задач.**\n",
    "\n",
    "Задачи машинного обучения на изображениях, также известные как задачи компьютерного зрения, связаны с анализом и обработкой визуальной информации, представленной в виде изображений. Некоторые из таких задач включают классификацию изображений, обнаружение объектов, сегментацию изображений, распознавание образов и генерацию изображений.\n",
    "\n",
    "Принцип работы сверточных сетей основан на использовании сверточных слоев, которые позволяют эффективно обрабатывать изображения. Сверточные слои представляют собой набор фильтров (ядер свертки), которые скользят по входному изображению, выполняя операцию свертки. Операция свертки состоит в поэлементном перемножении значений пикселей изображения с соответствующими значениями фильтра и суммировании результатов. Это позволяет выделять локальные особенности и закономерности на разных уровнях абстракции.\n",
    "\n",
    "После сверточных слоев в сверточной сети обычно следуют слои подвыборки (pooling), которые позволяют уменьшить размерность представления, сохраняя наиболее важные характеристики. Затем полученные признаки передаются в полносвязные слои, которые выполняют классификацию или другую необходимую задачу.\n",
    "\n",
    "Преимущества сверточных сетей при решении задач компьютерного зрения включают:\n",
    "\n",
    "1. Локальность: сверточные сети способны захватывать локальные особенности и шаблоны в изображениях, что делает их эффективными для анализа пространственной структуры данных.\n",
    "\n",
    "1. Параметры совместного использования: использование общих весов для фильтров свертки позволяет сети эффективно использовать параметры и обобщать свои знания на разные области изображений.\n",
    "\n",
    "1. Инвариантность к пространственным трансформациям: сверточные сети устойчивы к небольшим изменениям в положении или масштабе объектов на изображении благодаря операции свертки.\n",
    "\n",
    "1. Устойчивость к изменению масштаба: сверточные сети способны обнаруживать объекты на изображениях разного масштаба без необходимости явного изменения размера входных данных.\n",
    "\n",
    "1. Иерархическое представление: сверточные сети создают иерархическое представление изображений, где более высокие уровни соответствуют более абстрактным концепциям, что облегчает классификацию и обнаружение объектов.\n",
    "\n",
    "1. Автоматическое изучение признаков: сверточные сети способны автоматически извлекать и выделять важные признаки из изображений без необходимости вручную определять характеристики.\n",
    "\n",
    "В целом, сверточные сети предоставляют мощный инструмент для обработки и анализа изображений, их эффективность и способность к изучению признаков делают их особенно полезными для задач компьютерного зрения.\n",
    "\n",
    "## <a name=\"_yqknt9yj7o2t\"></a>**18.  Архитектура многослойной ИНС распознавания изображений на основе сверточных сетей.**\n",
    "Архитектура многослойной ИНС (нейронной сети) для распознавания изображений на основе сверточных сетей обычно состоит из нескольких типов слоев. Вот типичная архитектура такой сети:\n",
    "\n",
    "1. Сверточные слои: Слои свертки выполняют операцию свертки на входном изображении с использованием нескольких фильтров. Каждый фильтр обнаруживает определенные признаки, такие как границы, текстуры или формы. Сверточные слои последовательно применяются для извлечения более абстрактных признаков на разных уровнях.\n",
    "\n",
    "1. Слои подвыборки (pooling): Следующий тип слоев в архитектуре сверточной сети - это слои подвыборки. Они служат для уменьшения размерности пространства признаков, сохраняя важные характеристики. Обычно это достигается путем выбора максимального значения или усреднения значений в некотором окне.\n",
    "\n",
    "1. Полносвязные слои: После сверточных и слоев подвыборки следуют полносвязные слои. Полносвязные слои соединяют каждый нейрон предыдущего слоя с каждым нейроном текущего слоя. Эти слои обрабатывают извлеченные признаки и выполняют классификацию или другие задачи, связанные с распознаванием изображений.\n",
    "\n",
    "1. Выходной слой: В конце архитектуры сверточной сети обычно находится выходной слой, который принимает результаты от полносвязных слоев и генерирует соответствующий выход. Например, в задаче классификации изображений, выходной слой может состоять из нескольких нейронов, соответствующих различным классам, с использованием функции активации, такой как softmax.\n",
    "\n",
    "В архитектуре сверточной сети могут присутствовать и другие слои или модификации, такие как слои нормализации, слои активации, слои снижения переобучения и т. д. Однако вышеперечисленные компоненты являются основными элементами архитектуры сверточных сетей для распознавания изображений.\n",
    "\n",
    "## <a name=\"_idfo912cs870\"></a>**19.  Приемы для глубокого обучения на небольших наборах изображений.**\n",
    "Глубокое обучение требует больших объемов данных для эффективного обучения моделей. Однако, когда у нас есть ограниченный набор изображений, можно применить несколько приемов для повышения производительности и обобщающей способности модели. Вот несколько таких приемов для глубокого обучения на небольших наборах изображений:\n",
    "\n",
    "1. Перенос обучения (Transfer Learning): Используйте предварительно обученные модели, предварительно обученные на больших наборах данных, и дообучайте их на своих небольших данных. Это позволяет модели использовать знания, полученные на других задачах, и может значительно улучшить производительность модели.\n",
    "\n",
    "1. Аугментация данных (Data Augmentation): Применяйте различные преобразования к существующим изображениям для создания новых образцов данных. Например, можно применить случайные сдвиги, повороты, масштабирование, отражение и изменение яркости/контрастности. Это позволяет увеличить разнообразие данных и предотвратить переобучение модели.\n",
    "\n",
    "1. Генерация синтетических данных: Если у вас есть достаточно знаний о задаче, можно создать синтетические изображения, которые имитируют реальные данные. Например, при обучении модели для распознавания лиц, можно создать синтетические изображения с различными освещением, позами и выражениями лица.\n",
    "\n",
    "1. Регуляризация: Применяйте методы регуляризации, такие как L1 или L2 регуляризация, для контроля переобучения модели. Это поможет снизить сложность модели и улучшить ее обобщающую способность.\n",
    "\n",
    "1. Постепенное обучение (Progressive Learning): Начните обучение модели на небольшом подмножестве данных и постепенно увеличивайте размер обучающей выборки. Это позволяет модели постепенно адаптироваться к новым данным и избегать переобучения на ранних этапах.\n",
    "\n",
    "1. Ранняя остановка (Early Stopping): Остановите обучение модели, когда ее производительность на валидационной выборке перестает улучшаться. Это помогает предотвратить переобучение и сохранить лучшие обобщающие способности модели.\n",
    "\n",
    "1. Использование малых моделей: Вместо использования глубоких моделей с большим числом параметров, рассмотрите использование более компактных архитектур, таких как MobileNet или SqueezeNet. Это позволяет снизить количество требуемых обучающих данных и ресурсов для обучения.\n",
    "\n",
    "Комбинация этих приемов может помочь повысить производительность моделей глубокого обучения на небольших наборах изображений и сделать их более обобщающими.\n",
    "## <a name=\"_1e7x11n0uyb\"></a>**20.  Схема работ слоя сверточной сети. Пулинг. Гиперпараметры: padding, kernel size, stride, dilation.**\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.011.png)\n",
    "\n",
    "Схема работы слоя сверточной сети:\n",
    "\n",
    "1. Вход: Входной слой принимает изображение или выход предыдущего слоя. Изображение представлено в виде трехмерного тензора, где первое измерение соответствует высоте, второе измерение — ширине, а третье измерение — числу каналов изображения (например, RGB изображение имеет три канала).\n",
    "\n",
    "1. Свертка: В слое свертки применяются фильтры (ядра свертки) к входному изображению. Каждый фильтр представлен трехмерным тензором, который \"скользит\" по входу и выполняет операцию свертки. Результатом является карты признаков, которые представляют собой трехмерные тензоры, где первые два измерения соответствуют высоте и ширине карты, а третье измерение — числу фильтров.\n",
    "\n",
    "1. Функция активации: После операции свертки на карты признаков обычно применяется нелинейная функция активации, такая как ReLU (Rectified Linear Unit), для добавления нелинейности в сеть. Это помогает модели изучать более сложные и абстрактные представления данных.\n",
    "\n",
    "1. Пулинг: Слой пулинга (или субдискретизации) следует после слоя свертки и служит для уменьшения размерности карты признаков. Наиболее распространенным типом пулинга является слой максимального подвыборки (max pooling), который выбирает максимальное значение в каждом окне пулинга. Это позволяет уменьшить количество параметров и сделать представления более инвариантными к небольшим сдвигам искомых признаков.\n",
    "\n",
    "1. Выход: Выход слоя сверточной сети передается в следующий слой сверточной сети или полносвязный слой для дальнейшей обработки.\n",
    "\n",
    "Гиперпараметры слоя сверточной сети:\n",
    "\n",
    "1. Padding (заполнение): Параметр, определяющий, каким образом обрабатывать границы изображения при операции свертки. Значение \"valid\" означает отсутствие заполнения, а \"same\" означает заполнение, чтобы сохранить размеры входа.\n",
    "\n",
    "1. Kernel Size (размер ядра свертки): Размер фильтра, используемого для операции свертки. Он задается в виде двухмерного целочисленного значения, например, (3, 3) для квадратного ядра 3x3.\n",
    "\n",
    "1. Stride (шаг): Параметр, определяющий шаг, с которым фильтр перемещается по входной карте признаков. Значение 1 означает перемещение с шагом 1 пиксель, а большие значения увеличивают шаг.\n",
    "\n",
    "1. Dilation (диляция): Параметр, определяющий интервал между элементами фильтра при операции свертки. Значение 1 означает, что фильтр применяется на каждый пиксель, а большие значения добавляют пропуски между элементами фильтра.\n",
    "\n",
    "Комбинация этих гиперпараметров и их значений определяет размеры и характеристики операций свертки и пулинга в слоях сверточной сети, что влияет на ее способность извлекать признаки и классифицировать изображения.\n",
    "\n",
    "## <a name=\"_5uswhwv18uv8\"></a>**21.  Задачи обработки текста: дистрибутивная семантика, матрица совместной встречаемости, представление слов в виде векторов малой размерности.**\n",
    "Задачи обработки текста, такие как дистрибутивная семантика, матрица совместной встречаемости и представление слов в виде векторов малой размерности, являются ключевыми в области обработки естественного языка (Natural Language Processing, NLP). Рассмотрим каждую из этих задач подробнее:\n",
    "\n",
    "1. Дистрибутивная семантика: Дистрибутивная семантика изучает связь между значением слова и его контекстом в тексте. Она основана на предположении, что слова, встречающиеся в похожих контекстах, имеют схожие значения. Для решения задачи дистрибутивной семантики используются методы анализа статистических связей между словами, такие как матрица совместной встречаемости.\n",
    "\n",
    "1. Матрица совместной встречаемости: Матрица совместной встречаемости представляет собой таблицу, в которой каждый элемент указывает на количество раз, когда два слова встречаются в одном контексте. Путем анализа этой матрицы можно выявить семантические связи между словами. Например, если два слова часто встречаются в одном контексте, то вероятно, они имеют схожие значения. Матрица совместной встречаемости может быть использована для вычисления различных метрик, таких как коэффициент сходства, семантическая близость или факторы важности слов.\n",
    "\n",
    "1. Представление слов в виде векторов малой размерности: Представление слов в виде векторов малой размерности (word embeddings) позволяет кодировать семантическую информацию о словах. Одним из популярных методов является Word2Vec, который обучает векторные представления слов на основе их контекста в большом корпусе текста. Word embeddings позволяют выполнять алгебраические операции с словами, такие как вычисление семантических расстояний или нахождение ближайших соседей по смыслу.\n",
    "\n",
    "Эти задачи и методы имеют важное значение в NLP, позволяя моделям понимать и обрабатывать текстовые данные на более семантическом уровне. Они применяются в различных задачах, таких как определение тональности, машинный перевод, анализ сентиментов и многих других.\n",
    "\n",
    "## <a name=\"_xh8rp5sirjy6\"></a>**22.  Word2vec: модель CBOW.**\n",
    "Идея word2vec состоит в том, чтобы напрямую обучать вектора слов малой размерности\n",
    "\n",
    "- A neural probabilistic language model (Bengio et al., 2003)\n",
    "- word2vec (Mikolov et al. 2013) A recent, even simpler and faster model\n",
    "- Faster and can easily incorporate a new sentence/document or add a word to the vocabulary\n",
    "\n",
    "Для word2vec разработаны два основных алгоритма обучения:\n",
    "\n",
    "- CBoW (англ. Continuous Bag of Words, «непрерывный мешок со словами», bag — мультимножество) предсказывает текущее слово, исходя из окружающего его контекста.\n",
    "- Skip-gram - использует текущее слово, чтобы предугадывать окружающие его слова.\n",
    "\n",
    "Модель CBOW\n",
    "\n",
    "Модель CBOW учится как можно лучше по заданному контексту слова восстановить само слово.\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.012.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.013.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.014.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.015.png)\n",
    "\n",
    "Пример реализации на всякий случай:\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "\n",
    "`    `def \\_\\_init\\_\\_(self, vocab\\_size, embd\\_size, context\\_size, hidden\\_size):\n",
    "\n",
    "`        `super(CBOW, self).\\_\\_init\\_\\_()\n",
    "\n",
    "`        `self.embeddings = nn.Embedding(vocab\\_size, embd\\_size)\n",
    "\n",
    "`        `self.linear1 = nn.Linear(2\\*context\\_size\\*embd\\_size, hidden\\_size)\n",
    "\n",
    "`        `self.linear2 = nn.Linear(hidden\\_size, vocab\\_size)\n",
    "\n",
    "`   `def forward(self, inputs):\n",
    "\n",
    "`        `embedded = self.embeddings(inputs).view((1, -1))\n",
    "\n",
    "`        `hid = F.relu(self.linear1(embedded))\n",
    "\n",
    "`        `out = self.linear2(hid)\n",
    "\n",
    "`       `log\\_probs = F.log\\_softmax(out)\n",
    "\n",
    "`       `return log\\_probs\n",
    "## <a name=\"_8lyw2nszslxm\"></a>**23.  Word2vec: модель Skip-Gram.**\n",
    "\n",
    "Идея word2vec состоит в том, чтобы напрямую обучать вектора слов малой размерности\n",
    "\n",
    "Для word2vec разработаны два основных алгоритма обучения:\n",
    "\n",
    "- CBoW (англ. Continuous Bag of Words, «непрерывный мешок со словами», bag — мультимножество) предсказывает текущее слово, исходя из окружающего его контекста.\n",
    "- Skip-gram - использует текущее слово, чтобы предугадывать окружающие его слова.![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.016.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.017.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.018.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.019.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.020.png)\n",
    "\n",
    "\n",
    "## <a name=\"_3ejcf8toot35\"></a>**24.  Рекуррентная нейронная сеть, принципы ее обучения. Сложности применения рекуррентных нейронных сетей.**\n",
    "Рекуррентная нейронная сеть (RNN) - это класс искусственных нейронных сетей, в которых узел может получать входы не только от других узлов и текущих входных данных но и выходы узлов, полученные при рассмотрении предыдущих входных данных последовательности.\n",
    "\n",
    "- обмен вектором внутреннего состояния, полученного на предыдущем шаге, позволяет использовать информацию о предыдущих шагах, которые сеть уже обработала\n",
    "- при рассмотрении всей последовательности веса каждого узла одни и те же при рассмотрении всех входных данных последовательности\n",
    "- Такая архитектура сети позволяет обрабатывать серии событий во времени или последовательные пространственные цепочки произвольной размерности\n",
    "\n",
    "Трудность рекуррентной сети:\n",
    "\n",
    "- если учитывать каждый шаг времени, то становится необходимым для каждого шага времени (последовательности) создавать свой слой нейронов, что создает серьезные вычислительные сложности\n",
    "- многослойные реализации вычислительно неустойчивы: в них как правило либо исчезают либо зашкаливают веса\n",
    "- если ограничить расчет фиксированным временным окном, то полученные модели не будут отражать долгосрочных трендов\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.021.png)\n",
    "\n",
    "` `Распространение ошибок в узле RNN\n",
    "\n",
    "𝑎𝑡=𝑏+𝑊𝑠𝑡−1+𝑈𝑥𝑡 \n",
    "\n",
    "𝑠𝑡=𝑓(𝑎𝑡) \n",
    "\n",
    "𝑜𝑡=𝑐+𝑉𝑠𝑡 \n",
    "\n",
    "𝑦𝑡=ℎ(𝑜𝑡) \n",
    "\n",
    "Где:\n",
    "\n",
    "𝑓  — это нелинейность рекуррентной сети (обычно  𝜎 ,  tanh  или  𝑅𝑒𝐿𝑈 )\n",
    "\n",
    "ℎ  — функция, с помощью которой получается ответ (например,  𝑠𝑜𝑓𝑡𝑚𝑎𝑥 )\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.022.png)\n",
    "\n",
    "Распространение ошибки в архитектуре RNN\n",
    "\n",
    "- В прямой нейронной сети ошибка на конкретном нейроне вычисляется как функция от ошибок нейронов, которые используют его выходное значение формируется ациклический графы вычислений:\n",
    "- В архитектуре RNN нейрон принимает в качестве входа результат вычисления в нем самом (через вектор состояния)\n",
    "- Важно понимать, что при этом петли в графе вычислений не образуется\n",
    "- Вычисления, которые делает рекуррентная сеть, можно развернуть обратно до начала обрабатываемой последовательности\n",
    "- Можно сказать, что на каждом шаге обрабатываемой последовательности сеть создает копии самой себя\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.023.png)\n",
    "\n",
    "И на каждом последовательности мы фактически обучаем глубокую нейронную сеть, в которой столько слоев, сколько элементов в последовательности на данный момент мы уже видели\n",
    "\n",
    "Рекуррентная сеть — разворачиваться вдоль элементов последовательности 1… в очень-очень многоуровневую обычную сеть, в которой одни и те же веса переиспользуются на каждом уровне.\n",
    "\n",
    "- Для хранения весов достаточно одной матрицы\n",
    "- Градиенты по весам не затухают до нуля сразу же (как это бывает в обычных глубоких сетях)\n",
    "- Если матрица весов меняет норму вектора градиента при проходе через один «слой» обратного распространения, то при проходе через T слоев эта норма изменяется экспоненциально (т.к. веса матрицы одни и те же) это приводит: \n",
    "  - к \"взрыву градиентов\" (exploding gradients), если матрица заметно увеличивает норму вектора градиента\n",
    "  - к экспоненциальному затуханию градиентов (Vanishing gradients), если матрица заметно уменьшает норму вектора градиента\n",
    "\n",
    "пример реализации:\n",
    "\n",
    "Модель:\n",
    "\n",
    "torch.nn.RNN(\\*args, \\*\\*kwargs)\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "def \\_\\_init\\_\\_(self, input\\_size, output\\_size, hidden\\_dim, n\\_layers):\n",
    "\n",
    "super(Model, self).\\_\\_init\\_\\_()\n",
    "\n",
    "self.hidden\\_dim = hidden\\_dim\n",
    "\n",
    "self.n\\_layers = n\\_layers\n",
    "\n",
    "\\# RNN Layer\n",
    "\n",
    "self.rnn = nn.RNN(input\\_size, hidden\\_dim, n\\_layers, batch\\_first=True)\n",
    "\n",
    "self.fc = nn.Linear(hidden\\_dim, output\\_size)\n",
    "\n",
    "def forward(self, x):\n",
    "\n",
    "batch\\_size = x.size(0)\n",
    "\n",
    "hidden = self.init\\_hidden(batch\\_size)\n",
    "\n",
    "out, hidden = self.rnn(x, hidden)\n",
    "\n",
    "out = out.contiguous().view(-1, self.hidden\\_dim)\n",
    "\n",
    "out = self.fc(out)\n",
    "\n",
    "return out, hidden\n",
    "\n",
    "def init\\_hidden(self, batch\\_size):\n",
    "\n",
    "hidden = torch.zeros(self.n\\_layers, batch\\_size, self.hidden\\_dim).to(device)\n",
    "\n",
    "return hidden\n",
    "\n",
    "\\# Создаем инстанс модели с установленными гиперпараметрами\n",
    "\n",
    "model = Model(input\\_size=dict\\_size, output\\_size=dict\\_size, hidden\\_dim=12, n\\_layers=1)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "n\\_epochs = 100\n",
    "\n",
    "lr=0.01\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "Построение многослойных нейронных сетей на базе архитектуры RNN\n",
    "\n",
    "Рассмотрим всю рекуррентную сеть как слой и используем ее выходы как входы для следующего рекуррентного слоя.\n",
    "\n",
    "Мотивация: каждый слой действует в своем собственном «масштабе времени», примерно как каждый слой сверточной сети действует в своем масштабе, на свой размер окна входов.\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.024.png)\n",
    "\n",
    "Двунаправленные рекуррентные сети (bidirectional RNN): для входной последовательности запустим RNN (обычно с разными весами) два раза: один слой будет читать последовательность слева направо, а другой — справа налево\n",
    "\n",
    "- Матрицы весов для двух направлений абсолютно независимы и между ними нет взаимодействия\n",
    "- Ограничение: данный подход возможен только для последовательностей, которые даны сразу целиком (например для предложений естественного языка).\n",
    "- Мотивация в том, чтобы получить состояние, отражающее контекст и слева, и справа для каждого элемента последовательности (например для отнесения слова к части речи т.к. важно анализировать все предложение, и слева, и справа от слова)\n",
    "- Вместо классической рекуррентной сети из трех матриц, может использоваться любая другая конструкция, например LSTM или GRU.\n",
    "\n",
    "## <a name=\"_hgsznhijpdp9\"></a>**25.  Модуль LSTM.**\n",
    "\n",
    "LSTM (Long Short-Term Memory)\n",
    "\n",
    "- обычные рекуррентные сети очень плохо справляются с ситуациями, когда нужно что-то «запомнить» надолго: влияние скрытого состояния или входа с шага t на последующие состояния рекуррентной сети экспоненциально затухает\n",
    "- LSTM хорошо приспособлена к обучению на задачах классификации, обработки и прогнозирования временных рядов в случаях, когда важные события разделены временными лагами с неопределённой продолжительностью и границами вместо одного-единственного числа, на которое влияют все последующие состояния, используется специального вида ячейка моделирующая \"долгую память\"\n",
    "- LSTM моделирует процессы записи и чтения из этой \"ячейки памяти\"\n",
    "- у ячейки не один набор весов, как у обычного нейрона, а сразу несколько\n",
    "\n",
    "В LSTM есть три основных вида узлов, которые называются гейтами:\n",
    "\n",
    "- входной (input gate)\n",
    "- забывающий (forget gate)\n",
    "- выходной (output gate)\n",
    "- рекуррентная ячейка со скрытым состоянием\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.025.png)\n",
    "\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.026.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.027.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.028.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.029.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.030.png)\n",
    "\n",
    "Модель:\n",
    "\n",
    "torch.nn.LSTM(\\*args, \\*\\*kwargs)\n",
    "\n",
    "пример использования:\n",
    "class RNNModule(nn.Module):\n",
    "\n",
    "def \\_\\_init\\_\\_(self, n\\_vocab, seq\\_size, embedding\\_size, lstm\\_size):\n",
    "\n",
    "super(RNNModule, self).\\_\\_init\\_\\_()\n",
    "\n",
    "self.seq\\_size = seq\\_size\n",
    "\n",
    "self.lstm\\_size = lstm\\_size\n",
    "\n",
    "self.embedding = nn.Embedding(n\\_vocab, embedding\\_size)\n",
    "\n",
    "self.lstm = nn.LSTM(embedding\\_size, lstm\\_size, batch\\_first=True)\n",
    "\n",
    "self.dense = nn.Linear(lstm\\_size, n\\_vocab)\n",
    "\n",
    "def forward(self, x, prev\\_state):\n",
    "\n",
    "embed = self.embedding(x)\n",
    "\n",
    "output, state = self.lstm(embed, prev\\_state)\n",
    "\n",
    "logits = self.dense(output)\n",
    "\n",
    "return logits, state\n",
    "\n",
    "def zero\\_state(self, batch\\_size):\n",
    "\n",
    "return (torch.zeros(1, batch\\_size, self.lstm\\_size), torch.zeros(1, batch\\_size, self.lstm\\_size))\n",
    "\n",
    "## <a name=\"_x1biyos9tkhq\"></a>**26.  Механизм Attention. Пример использования Attention.**\n",
    "\n",
    "После успеха этой методики в машинном переводе последовали ее внедрения в:\n",
    "\n",
    "- других задачах обработки естественного языка\n",
    "- задачах генерации описания изображения (в применении к CNN)\n",
    "- в порождающих состязательных сетях (GAN)\n",
    "\n",
    "\n",
    "Специфика:\n",
    "\n",
    "- Для энкодера и декодера используются различные веса сети (RNN модуля)\n",
    "- Скрытое состояние энкодера на последнем шаге обработки предложения (последовательности) является ключевым т.к. по сути кодирует все предложение. Затем декодер использует именно это состояние для того, чтобы сгенерировать перевод предложения на другом языке.\n",
    "- Результат сэмплинга декодера на предыдущем шаге передается на следующий блок декодера в добавок к внутреннему состоянию RNN декодера.\n",
    "\n",
    "Проблемы:\n",
    "\n",
    "- Расстояние между местом кодирования слова и местом его декодирования большое.\n",
    "- Последовательность слов в исходном и целевом предложении часто должна быть разная.\n",
    "- Часто количество слов в исходном и целевом предложении различается.\n",
    "\n",
    "Базовая архитектура Seq2seq\n",
    "\n",
    "Seq2seq состоит из двух рекуррентных нейронных сетей (RNN): Энкодера и Декодера.\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.031.png)\n",
    "\n",
    "Энкодер - принимает последовательность (например: предложение на языке A) и сжимает его в вектор скрытого состояния.\n",
    "\n",
    "Декодер - выдает слово на языке B, принимает последнее скрытое состояние энкодера (для первого слова) / предыдущее скрытое состояние декодера (последующие слова) и предыдущее предсказанное слово.\n",
    "\n",
    "Применение механизма внимания для Seq2seq: базовый принцип\n",
    "\n",
    "Использование механизма внимания позволяет решать задачу нахождения закономерности между словами находящимися на большом расстоянии друг от друга. LSTM, GRU и аналогичные блоки используются для улучшения передачи информации на большое количество итераций по сравнению с базовыми RNN, несмотря на это сохраняется проблема: влияние предыдущих состояний на текущее уменьшается экспоненциально от расстояния между словами\n",
    "\n",
    "В классическом применении RNN результатом является только последнее скрытое\n",
    "\n",
    "состояние ℎ , где - длина последовательности входных данных.\n",
    "\n",
    "Механизм внимания улучшает этот показатель до линейного.\n",
    "\n",
    "Использование механизма внимания позволяет использовать информацию, полученную не только из последнего скрытого состояния, но и из любого скрытого состояния ℎ для любого\n",
    "\n",
    "t ∈ 1…m .\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.032.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.033.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.034.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.035.png)\n",
    "\n",
    "При помощи механизма внимания достигается \"фокусирование\" декодера на определенных скрытых состояниях энкодера, на любом из шагов энкодера.\n",
    "\n",
    "В случаях машинного перевода эта возможность помогает декодеру предсказывать на какие скрытые состояния при исходных определенных словах на языке A необходимо обратить больше внимания при генерации очередного слова перевода на язык B.\n",
    "\n",
    "При этом расстояние (в шагах последовательности) между генерируемым словом и\n",
    "\n",
    "влияющими на него словами из исходной последовательности никак не влияют на\n",
    "\n",
    "возможность использование скрытых состояний, сформированных под их воздействием.\n",
    "\n",
    "Для других задач\n",
    "\n",
    "Задача Image Captioning : на вход подается изображение, а на выходе создается текстовое\n",
    "\n",
    "предложение, описывающее визуальное содержание картинки.\n",
    "\n",
    "Классическая нейростевая модель для решения задачи Image Captioning состоит из: сверточной нейронной сети (CNN) для извлечения визуальных характеристик из картинки и рекуррентной нейронной сети (RNN) для перевода результата работы сверточной сети в текст.\n",
    "\n",
    "Сверточный модуль внимания (сonvolutional block attention module) — модуль внимания для сверточных нейросетей. Применяется для задач детектирования объектов на изображениях и классификации с входными данными больших размерностей.\n",
    "\n",
    "## <a name=\"_62zujsf74go8\"></a>**27.  Архитектура Transformer.**\n",
    "### <a name=\"_nk3qx8692uzn\"></a>**Трансформер**\n",
    "Трансформеры — относительно новый тип нейросетей, направленный на решение последовательностей с легкой обработкой дальнодействующих зависимостей. На сегодня это самая продвинутая техника в области обработки естественной речи (NLP).\n",
    "\n",
    "С их помощью можно переводить текст, писать стихи и статьи и даже генерировать компьютерный код.В отличие от рекуррентных нейронных сетей (RNN), трансформеры не обрабатывают последовательности по порядку. Например, если исходные данные — текст, то им не нужно обрабатывать конец предложения после обработки начала. Благодаря этому такую нейросеть можно распараллелить и обучить значительно быстрее.\n",
    "\n",
    "Основными компонентами трансформеров являются энкодер и декодер.\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.036.png)\n",
    "\n",
    "Энкодер преобразовывает входящую информацию (например, текст) и конвертирует ее в вектор (набор чисел). Декодер, в свою очередь, расшифровывает ее в виде новой последовательности (например, ответ на вопрос) слов на другом языке — смотря для каких целей создавалась нейросеть.\n",
    "\n",
    "Трансформеры изначально позиционировались как нейросеть для обработки и понимания естественного языка. За четыре года с момента их появления они обрели популярность и появились во множестве сервисов, используемых ежедневно миллионами людей.\n",
    "\n",
    "Одним из самых простых примеров является языковая модель BERT компании Google, разработанная в 2018 году.\n",
    "\n",
    "Другой пример популярной языковой модели на базе трансформеров — это GPT (Generative Pre-trained Transformer) компании OpenAI.\n",
    "\n",
    "Другие инновации, лежащие в основе трансформеров, сводятся к трем основным концепциям:\n",
    "\n",
    "·        позиционные энкодеры (Positional Encodings);\n",
    "\n",
    "·        внимание (Attention);\n",
    "\n",
    "·        самовнимание (Self-Attention).\n",
    "### <a name=\"_odq9yovagdw6\"></a>**Позиционные энкодеры**\n",
    "Начнем с первого — позиционных энкодеров. Допустим, необходимо перевести текст с английского на русский. Стандартные модели RNN «понимают» порядок слов и обрабатывают их последовательно. Однако это затрудняет распараллеливание процесса.\n",
    "\n",
    "Позиционные кодировщики позволяют преодолеть этот барьер. Идея состоит в том, чтобы взять все слова во входной последовательности — в данном случае английское предложение — и добавить к каждому номер в его порядке.\n",
    "### <a name=\"_mgeg271j9nz7\"></a>**Внимание**\n",
    "Внимание помогает избегать таких ситуаций как например перевод фраз с одного языка на другой. Его механизм позволяет текстовой модели «смотреть» на каждое слово в исходном предложении при принятии решения о том, как их переводить. Узнать модели, на какие слова «обращать внимание» на каждом шаге, помогают тренировочные данные. Наблюдая за тысячами английских и французских предложений, алгоритм узнает взаимозависимые типы слов. Он учится учитывать пол, множественность и другие правила грамматики.\n",
    "### <a name=\"_lmmz8vb27a7c\"></a>**Самовнимание**\n",
    "Последняя часть трансформеров — это поворот внимания, называемый «самовниманием».\n",
    "\n",
    "Если внимание помогает выравнивать слова при переводе с одного языка на другой, то самовнимание позволяет модели понимать смысл и закономерности языка.\n",
    "### <a name=\"_bxp7arypp0a4\"></a>**Обобщенно и кратко**\n",
    "Трансформеры – это новый тип нейросетей, который позволяет решать последовательности с легкой обработкой дальнодействующих зависимостей. Они являются самой продвинутой техникой в области обработки естественного языка (NLP), позволяя переводить текст, писать стихи и статьи, генерировать компьютерный код и многое другое. Трансформеры не обрабатывают последовательности по порядку, благодаря чему их можно распараллелить и обучить значительно быстрее, чем рекуррентные нейронные сети (RNN).\n",
    "\n",
    "Основными компонентами трансформеров являются энкодер и декодер. Энкодер преобразовывает входящую информацию (например, текст) и конвертирует ее в вектор. Декодер расшифровывает конвертированный вектор в виде новой последовательности (например, ответ на вопрос) слов на другом языке, смотря для каких целей создавалась нейросеть.\n",
    "\n",
    "Трансформеры позиционируются как нейросеть для обработки и понимания естественного языка. Они обрели популярность и появились во множестве сервисов, используемых ежедневно миллионами людей. Языковая модель BERT компании Google и GPT (Generative Pre-trained Transformer) компании OpenAI являются популярными примерами языковых моделей на базе трансформеров.\n",
    "\n",
    "Основные концепции, лежащие в основе трансформеров, сводятся к позиционным энкодерам, вниманию и самовниманию. Позиционные энкодеры позволяют обрабатывать слова во входной последовательности и добавлять к каждому слову номер в его порядке. Внимание помогает модели «смотреть» на каждое слово в исходном предложении при принятии решения о том, как их переводить. Самовнимание позволяет модели понимать смысл и закономерности языка.\n",
    "\n",
    "\n",
    "## <a name=\"_9ssq0ztrin0b\"></a>**28.  Модель BERT.**\n",
    "**BERT (Bidirectional Encoder Representations from Transformers)** — это языковая модель, разработанная Google в 2018 году. Она является одной из самых продвинутых языковых моделей на базе трансформеров и используется для обработки естественного языка. BERT обучается на огромном объеме текстовых данных, что позволяет ему понимать контекст и смысл слов в предложении.\n",
    "\n",
    "BERT используется для таких задач, как анализ тональности текста, ответы на вопросы, генерация текстов и многое другое. Он может использоваться как самостоятельно, так и в сочетании с другими моделями машинного обучения.\n",
    "\n",
    "BERT обучается на огромных корпусах текстов, что позволяет ему понимать контекст и смысл слов в предложении. Он использует методы self-attention, что позволяет ему лучше понимать зависимости между словами в предложении.\n",
    "\n",
    "BERT имеет две основные модификации: BERT-base и BERT-large. BERT-large имеет большую мощность, но требует большего количества вычислительных ресурсов.\n",
    "\n",
    "BERT стал очень популярной моделью, используемой во многих сервисах, таких как поисковые системы, машинный перевод и другие. Он также является одной из основных моделей, используемых в обработке естественного языка и машинном обучении.\n",
    "\n",
    "Архитектура BERT состоит из двух частей: энкодера и декодера. Энкодер преобразовывает предложение в вектор фиксированной длины, а декодер использует полученный вектор для выполнения задачи, например, предсказания следующего слова в предложении. BERT обучается на огромном количестве данных, что позволяет ему изучать контекст и смысл слов в предложении.\n",
    "\n",
    "При подаче текста на вход сети сначала выполняется его токенизация. Токенами служат слова, доступные в словаре, или их составные части — если слово отсутствует в словаре, оно разбивается на части, которые в словаре присутствуют (см. рис. 1). Словарь является составляющей модели — так, в BERT-Base используется словарь около 30,000 слов. В самой нейронной сети токены кодируются своими [векторными представлениями (англ. embeddings), а именно, соединяются представления самого токена (предобученные), номера его предложения, а также позиции токена внутри своего предложения. Входные данные поступают на вход и обрабатываются сетью параллельно, а не последовательно, но информация о взаимном расположении слов в исходном предложении сохраняется, будучи включённой в позиционную часть эмбеддинга соответствующего токена.\n",
    "\n",
    "Выходной слой основной сети имеет следующий вид: поле, отвечающее за ответ в задаче предсказания следующего предложения, а также токены в количестве, равном входному. Обратное преобразование токенов в вероятностное распределение слов осуществляется полносвязным слоем с количеством нейронов, равным числу токенов в исходном словаре.\n",
    "\n",
    "BERT обучается одновременно на двух задачах — предсказания следующего предложения (англ. next sentence prediction) и генерации пропущенного токена (англ. masked language modeling). На вход BERT подаются токенизированные пары предложений, в которых некоторые токены скрыты. Таким образом, благодаря маскированию токенов, сеть обучается глубокому двунаправленному представлению языка, учится понимать контекст предложения. Задача же предсказания следующего предложения есть задача бинарной классификации — является ли второе предложение продолжением первого. Благодаря ей сеть можно обучить различать наличие связи между предложениями в тексте.\n",
    "\n",
    "Интерпретация этапа предобучения — обучение модели языку.\n",
    "\n",
    "Этот этап обучения зависит от задачи, и выход сети, полученной на этапе предобучения, может использоваться как вход для решаемой задачи. Так, например, если решаем задачу построения вопросно-ответной системы, можем использовать в качестве ответа последовательность токенов, следующую за разделителем предложений. В общем случае дообучаем модель на данных, специфичных задаче: знание языка уже получено на этапе предобучения, необходима лишь коррекция сети.\n",
    "\n",
    "Интерпретация этапа fine-tuning — обучение решению конкретной задачи при уже имеющейся общей модели языка.\n",
    "\n",
    "Гиперпараметрами модели являются\n",
    "\n",
    "H— размерность скрытого пространства кодировщика,\n",
    "\n",
    "L— количество слоёв-кодировщиков,\n",
    "\n",
    "A— количество голов в механизме внимания\n",
    "### <a name=\"_rwzb4zto04cl\"></a>**Обобщенно и кратко**\n",
    "BERT, или Bidirectional Encoder Representations from Transformers, - это модель обработки естественного языка, которая стала все более популярной в последние годы. Он используется для широкого спектра задач, включая анализ тональности текста, ответы на вопросы, генерацию текста и многое другое. Архитектура BERT состоит из двух основных компонентов: кодировщика и декодировщика.\n",
    "\n",
    "Одной из ключевых особенностей BERT является его способность учиться на огромных объемах данных, что позволяет ему понимать контекст и смысл слов в предложении. При обработке текста BERT сначала токенизирует его, разбивая его на отдельные слова или подслова. Затем эти токены кодируются в векторные представления.\n",
    "\n",
    "BERT обучается на двух задачах одновременно: предсказания следующего предложения и генерации пропущенного слова. Это позволяет ему учиться глубокому двунаправленному представлению языка и понимать контекст предложения.\n",
    "\n",
    "Интерпретация этапа предварительного обучения заключается в задаче моделирования языка, где BERT обучается понимать общую структуру языка. Заключительным этапом является дообучение, где модель обучается решению конкретных задач, используя свои предварительно обученные знания языка.\n",
    "\n",
    "Что касается гиперпараметров модели, они включают в себя размерность скрытого пространства кодировщика, количество слоев кодировщика и количество голов в механизме внимания.\n",
    "\n",
    "В целом, BERT - это мощный инструмент для обработки естественного языка, который революционизировал эту область, обеспечивая передовые результаты на различных задачах. Его способность учиться и понимать язык на глубоком уровне сделала его популярным выбором для многих приложений, включая поисковые системы, чат-ботов и многое другое.\n",
    "\n",
    "## <a name=\"_1fl0qd9nz02i\"></a>**29.  Класс Tensor. Операции, изменяющие размер тензора. Операции агрегации.**\n",
    "### <a name=\"_wttoomaztaje\"></a>**Класс Tensor**\n",
    "Класс Tensor - это основной класс в библиотеке PyTorch, который представляет многомерный массив. Tensor может быть создан из списка или массива numpy.\n",
    "\n",
    "Tensor - это не просто массив, это объект, который содержит в себе данные и информацию о своей форме (размерности). Это позволяет выполнять на нем различные операции, например, изменять его форму или вычислять среднее значение.\n",
    "\n",
    "Класс Tensor в PyTorch поддерживает множество операций, которые позволяют выполнять различные вычисления с тензорами, такие как сложение, вычитание, умножение, деление, экспоненту и логарифм. Также в PyTorch есть операции сравнения, которые позволяют сравнивать тензоры поэлементно.\n",
    "\n",
    "\n",
    "### <a name=\"_sfb93yqe5mdb\"></a>**Операции изменения размера тензора**\n",
    "PyTorch предоставляет множество операций, которые позволяют изменять форму тензора. Они могут быть полезны в случае, когда тензор нужно привести к нужной размерности или сделать его подходящим для выполнения операции.\n",
    "\n",
    "Некоторые из операций изменения размера тензора:\n",
    "\n",
    "\\-  torch.Tensor.view(\\*shape)  - метод, который изменяет форму тензора без изменения его данных. Он возвращает новый тензор с указанными размерами. Это полезно, когда нужно изменить форму тензора, но при этом сохранить его данные.\n",
    "\n",
    "\\-  torch.Tensor.reshape(\\*shape)  - метод, который изменяет форму тензора, сохраняя его данные. Он возвращает новый тензор с указанными размерами. Этот метод поддерживает более широкий диапазон форм, чем  view , но может потребовать копирования данных.\n",
    "\n",
    "\\-  torch.Tensor.permute(\\*dims)  - метод, который переставляет размерности тензора. Он возвращает новый тензор с переставленными размерностями. Это полезно, когда нужно изменить порядок размерностей в тензоре.\n",
    "\n",
    "\\-  torch.Tensor.squeeze(dim=None)  - метод, который удаляет размерность из тензора, если она имеет размер 1. Если аргумент  dim  указан, то он удаляет только размерность  dim . Это полезно, когда нужно убрать не нужную размерность из тензора.\n",
    "\n",
    "\\-  torch.Tensor.unsqueeze(dim)  - метод, который добавляет размерность к тензору на указанную позицию. Это полезно, когда нужно добавить размерность к тензору для выполнения операции или для соответствия форме другого тензора.\n",
    "### <a name=\"_v73hyhgnfx3q\"></a>**Операции агрегации**\n",
    "PyTorch также предоставляет множество операций агрегации, которые позволяют получить одно значение из тензора. Они могут быть полезны в случае, когда нужно вычислить сумму значений тензора или найти максимальное значение.\n",
    "\n",
    "Некоторые из операций агрегации:\n",
    "\n",
    "\\-  torch.Tensor.mean(dim=None)  - метод, который вычисляет среднее значение тензора по указанным размерностям. Это полезно, когда нужно вычислить среднее значение пикселей в изображении или среднее значение предсказаний модели на тестовом наборе данных.\n",
    "\n",
    "\\-  torch.Tensor.sum(dim=None)  - метод, который вычисляет сумму значений тензора по указанным размерностям. Это полезно, когда нужно вычислить общее количество объектов в выборке или сумму всех элементов в матрице.\n",
    "\n",
    "\\-  torch.Tensor.max(dim=None)  - метод, который вычисляет максимальное значение тензора по указанным размерностям. Это полезно, когда нужно найти максимальное значение в массиве или выбрать наибольшее предсказание модели.\n",
    "\n",
    "\\-  torch.Tensor.min(dim=None)  - метод, который вычисляет минимальное значение тензора по указанным размерностям. Это полезно, когда нужно найти минимальное значение в массиве или выбрать наименьшее предсказание модели.\n",
    "\n",
    "\n",
    "### <a name=\"_rqbdqp8v6g2b\"></a>**Обобщенно и кратко**\n",
    "Класс Tensor является основным классом в библиотеке PyTorch, который представляет многомерный массив. Он позволяет выполнять на нем различные операции, такие как сложение, вычитание, умножение, деление, экспоненту и логарифм, а также операции сравнения.\n",
    "\n",
    "PyTorch предоставляет множество операций, которые позволяют изменять форму тензора, такие как методы  view ,  reshape ,  permute ,  squeeze  и  unsqueeze . Они позволяют изменять форму тензора без изменения его данных, переставлять размерности тензора, удалять размерность из тензора или добавлять размерность к тензору.\n",
    "\n",
    "PyTorch также предоставляет множество операций агрегации, которые позволяют получить одно значение из тензора, такие как методы mean, sum,  max  и  min . Они могут быть полезны в случае, когда нужно вычислить среднее значение, сумму значений, максимальное или минимальное значение тензора по указанным размерностям.\n",
    "\n",
    "## <a name=\"_ykxureqwngs7\"></a>**30.  Принципиальная логика обучения нейронной сети.**\n",
    "Обучение нейронной сети на PyTorch состоит из нескольких шагов, требующих настройки различных параметров. Однако, несмотря на это, сам процесс обучения нейронной сети на PyTorch является относительно простым.\n",
    "\n",
    "Первым шагом является подготовка данных. Необходимо разделить данные на тренировочный и тестовый наборы и преобразовать их в тензоры PyTorch. Тензоры - это многомерные массивы, которые используются для хранения и обработки данных в нейронных сетях.\n",
    "\n",
    "Вторым шагом является определение модели. Необходимо создать модель нейронной сети, определить количество скрытых слоев, количество нейронов в каждом слое и функцию активации. Функция активации - это нелинейная функция, которая активирует нейрон при получении определенного входного сигнала.\n",
    "\n",
    "Третьим шагом является определение функции потерь. Необходимо выбрать функцию потерь, которая будет минимизироваться во время обучения. Функция потерь измеряет разницу между предсказанными и фактическими значениями и используется для определения того, насколько хорошо нейронная сеть предсказывает выходные данные.\n",
    "\n",
    "Четвертым шагом является определение оптимизатора. Необходимо выбрать оптимизатор, который будет обновлять веса нейронной сети в процессе обучения. Оптимизаторы - это алгоритмы, которые используются для настройки весов нейронов в процессе обучения.\n",
    "\n",
    "Пятый шаг - это обучение модели. Необходимо передать тренировочные данные в модель и выполнить обратное распространение ошибки, чтобы обновить веса нейронной сети. Обратное распространение ошибки - это процесс, который используется для настройки весов нейронов в соответствии с выбранной функцией потерь.\n",
    "\n",
    "В процессе обучения модели необходимо следить за параметрами обучения, такими как скорость обучения и количество эпох. Скорость обучения определяет, насколько быстро веса нейронной сети будут обновляться в процессе обучения. Слишком низкая скорость обучения может привести к долгому процессу обучения, а слишком высокая - к нестабильности в обучении. Количество эпох - это количество раз, которое тренировочный набор данных будет передан в модель.\n",
    "\n",
    "Шестой и последний шаг - это оценка модели. После обучения модели необходимо оценить ее производительность на тестовых данных. При оценке модели можно использовать различные метрики, такие как точность, полноту и F1-меру.\n",
    "### <a name=\"_v7xrh1hfb1gd\"></a>**Обобщенно**\n",
    "Обучение нейронной сети на PyTorch состоит из нескольких этапов: подготовка данных, определение модели, выбор функции потерь и оптимизатора, обучение модели и оценка ее производительности на тестовых данных. В процессе обучения модели необходимо следить за параметрами обучения, такими как скорость обучения и количество эпох. После обучения модели можно использовать различные метрики, такие как точность, полнота и F1-мера, для оценки ее производительности.\n",
    "\n",
    "## <a name=\"_1ps03u9gp5h3\"></a>**31.  Автоматическое дифференцирование в PyTorch. Пример и применение в обучении ИНС.**\n",
    "### <a name=\"_ocsv25l1ylq6\"></a>**Автоматическое дифференцирование**\n",
    "Автоматическое дифференцирование - это процесс вычисления производных функции во время вычисления значения этой функции. Это значит, что при использовании автоматического дифференцирования в PyTorch можно не задумываться о том, как вычислять градиенты функций вручную. PyTorch автоматически вычисляет градиенты функции, что является необходимым для обучения нейронных сетей.\n",
    "\n",
    "При обучении нейронных сетей мы хотим минимизировать ошибку нашей модели. Для этого мы используем градиентный спуск, который требует вычисления градиентов функции ошибки по параметрам нашей модели. С помощью автоматического дифференцирования в PyTorch мы можем легко вычислить эти градиенты и использовать их для обновления параметров нашей модели в процессе обучения.\n",
    "\n",
    "В PyTorch автоматическое дифференцирование реализовано через классы torch.Tensor и torch.autograd.Function. Когда мы создаем тензор в PyTorch, мы можем указать, что нам нужно вычислять градиенты для этого тензора, установив параметр requires\\_grad=True. Затем, когда мы вычисляем функцию, содержащую этот тензор, PyTorch автоматически создает граф вычислений и вычисляет градиенты функции относительно этого тензора.\n",
    "\n",
    "Одним из преимуществ автоматического дифференцирования в PyTorch является то, что оно позволяет вычислять градиенты для сложных функций, включая функции, которые содержат другие функции, которые в свою очередь содержат другие функции, и так далее. Это делает процесс обучения более эффективным и удобным для разработчиков.\n",
    "\n",
    "Пример использования автоматического дифференцирования в PyTorch:\n",
    "\n",
    "import torch\n",
    "\n",
    "\\# Создание тензоров\n",
    "\n",
    "x = torch.tensor([5.], requires\\_grad=True)\n",
    "\n",
    "y = torch.tensor([7.], requires\\_grad=True)\n",
    "\n",
    "\\# Вычисление функции\n",
    "\n",
    "f = 3\\*x\\*\\*2 + 2\\*y\n",
    "\n",
    "\\# Вычисление градиентов\n",
    "\n",
    "f.backward()\n",
    "\n",
    "\\# Вывод градиентов\n",
    "\n",
    "print(x.grad)  # Выводит тензор 30.0\n",
    "\n",
    "print(y.grad)  # Выводит тензор 2.0\n",
    "\n",
    "В этом примере мы создаем два тензора x и y, которые являются переменными, для которых мы хотим вычислить градиенты. Затем мы вычисляем функцию f с использованием этих переменных. После этого мы вызываем метод backward(), который автоматически вычисляет градиенты функции f по переменным x и y. В конце мы выводим градиенты переменных x и y.\n",
    "### <a name=\"_9qe0hmlngxn\"></a>**Применение автоматического дифференцирования в обучении ИНС**\n",
    "В обучении ИНС мы хотим минимизировать ошибку нашей модели. Для этого мы используем градиентный спуск, который требует вычисления градиентов функции ошибки по параметрам нашей модели. С помощью автоматического дифференцирования в PyTorch мы можем легко вычислить эти градиенты и использовать их для обновления параметров нашей модели в процессе обучения.\n",
    "\n",
    "В заключение, автоматическое дифференцирование в PyTorch очень полезно для обучения нейронных сетей, так как оно позволяет вычислять градиенты функций автоматически. Это делает процесс обучения более эффективным и удобным для разработчиков.\n",
    "## <a name=\"_v1zsqwgka1zx\"></a>**32.  Загрузка и преобразование данных. Классы Dataset, DataLoader, Transforms (и композиция трансформеров).**\n",
    "Загрузка и преобразование данных являются важными шагами при работе с анализом данных и машинным обучением. В PyTorch для этих целей используются классы Dataset, DataLoader и Transforms, а также возможность композиции трансформеров.\n",
    "\n",
    "**Класс Dataset** предоставляет интерфейс для доступа к данным и их преобразования. Он представляет собой абстрактный класс, от которого можно наследоваться для создания пользовательских наборов данных. Класс Dataset требует реализации двух методов: \\_\\_len\\_\\_() для получения размера набора данных и \\_\\_getitem\\_\\_(index) для получения элемента данных по индексу.\n",
    "\n",
    "**Класс DataLoader** предоставляет удобный способ загрузки данных из Dataset и предоставляет функциональность по работе с пакетами (batching), перемешиванию данных (shuffling), параллельной загрузке и другими возможностями. Он позволяет эффективно итерироваться по данным во время обучения модели.\n",
    "\n",
    "**Класс Transforms** предоставляет механизмы для преобразования данных. Он представляет собой набор предопределенных преобразований данных, таких как изменение размера изображений, нормализация, аугментация и т.д. Класс Transforms может применяться непосредственно к данным или использоваться вместе с Dataset и DataLoader.\n",
    "\n",
    "**Композиция трансформеров** позволяет применять несколько преобразований последовательно к данным. В PyTorch это достигается с помощью класса transforms.Compose, который позволяет объединять несколько трансформеров в цепочку.\n",
    "## <a name=\"_a3obv2hsgvpk\"></a>**33.  Класс nn.Module. Назначение. Основные поля, методы.**\n",
    "Класс nn.Module является одним из ключевых компонентов библиотеки PyTorch, используемой для создания и обучения нейронных сетей. Он предоставляет базовый функционал для определения и управления моделями глубокого обучения.\n",
    "\n",
    "**Назначение класса nn.Module** заключается в обеспечении модульности и гибкости при построении нейронных сетей. Он представляет собой базовый класс, от которого наследуются все пользовательские модели, создаваемые в PyTorch. Класс nn.Module обеспечивает удобный способ определения структуры модели, хранения обучаемых параметров и прямого/обратного распространения сигнала в сети.\n",
    "\n",
    "**Основные поля класса nn.Module:**\n",
    "\n",
    "1. self.training: булевое поле, указывающее на режим работы модели (обучение или оценка). Влияет на поведение некоторых слоев, таких как Dropout или Batch Normalization.\n",
    "1. self.\\_parameters: словарь, содержащий все обучаемые параметры модели, такие как веса и смещения слоев. Они автоматически оптимизируются в процессе обучения.\n",
    "1. self.\\_buffers: словарь, содержащий необучаемые параметры модели, которые могут изменяться, но не оптимизируются автоматически, например, средние и дисперсии в Batch Normalization.\n",
    "1. self.\\_modules: словарь, содержащий все подмодули модели. Это позволяет иерархически организовывать модель и управлять ее частями.\n",
    "\n",
    "**Основные методы класса nn.Module:**\n",
    "\n",
    "1. \\_\\_init\\_\\_(): конструктор класса, инициализирующий модель. Здесь определяются все слои и параметры модели.\n",
    "1. forward(input): метод, определяющий прямой проход модели. В этом методе определяется порядок применения слоев и преобразований для получения выходного значения на основе входных данных.\n",
    "1. parameters(): метод, возвращающий итератор по всем обучаемым параметрам модели. Это позволяет передать параметры оптимизатору для обновления во время обучения.\n",
    "1. zero\\_grad(): метод, обнуляющий градиенты всех обучаемых параметров модели. Используется перед вычислением градиентов в процессе обратного распространения ошибки.\n",
    "1. to(device): метод, перемещающий модель и все ее параметры на указанное устройство (например, GPU). Это позволяет ускорить вычисления при наличии поддерживаемого аппаратного обеспечения.\n",
    "## <a name=\"_7qfg7qnwnu6t\"></a>**34.  Линейные слои (Linear Layers).**\n",
    "Линейные слои являются одними из основных составляющих нейронных сетей. Они представляют собой линейное преобразование входных данных, которое выполняется путем умножения входных значений на матрицу весов и последующего добавления смещений.\n",
    "\n",
    "В контексте нейронных сетей, линейный слой может быть представлен как функция:\n",
    "\n",
    "**f(x) = Wx + b,**\n",
    "\n",
    "где x - входные данные, W - матрица весов, b - вектор смещений, и f(x) - выходные значения слоя.\n",
    "\n",
    "**Ключевая особенность** линейных слоев состоит в их способности выучивать нелинейные зависимости между данными. Хотя сам слой выполняет только линейное преобразование, в сочетании с нелинейной функцией активации, такой как ReLU (Rectified Linear Unit), линейные слои могут моделировать сложные нелинейные отображения.\n",
    "\n",
    "В многослойной нейронной сети, линейные слои часто объединяются с нелинейной функцией активации, такой как ReLU или Sigmoid, для создания более мощных моделей, способных изучать сложные данные.\n",
    "\n",
    "**При обучении нейронной сети**, веса и смещения линейного слоя обновляются в процессе обратного распространения ошибки с использованием градиентного спуска или других оптимизационных алгоритмов. Это позволяет модели подстраиваться под данные и находить оптимальные веса для выполнения поставленной задачи.\n",
    "\n",
    "Линейные слои **широко применяются** в различных архитектурах нейронных сетей, включая перцептроны, сверточные нейронные сети (CNN) и рекуррентные нейронные сети (RNN). Они являются ключевыми строительными блоками для обработки и анализа данных в задачах машинного обучения, включая классификацию, регрессию, сегментацию и многие другие.\n",
    "\n",
    "**Пример использования линейного слоя в PyTorch:**\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\\# Создание линейного слоя\n",
    "\n",
    "linear\\_layer = nn.Linear(in\\_features=10, out\\_features=5)\n",
    "\n",
    "\\# Пример применения линейного слоя\n",
    "\n",
    "input\\_data = torch.randn(32, 10)  # входные данные размером 32x10\n",
    "\n",
    "output = linear\\_layer(input\\_data)  # применение линейного слоя\n",
    "\n",
    "print(output.shape)  # вывод размерности выходных данных\n",
    "\n",
    "В этом примере мы создаем линейный слой с помощью nn.Linear, указывая количество входных (in\\_features) и выходных (out\\_features) признаков. Затем мы применяем линейный слой к некоторым входным данным (input\\_data) и получаем выходные значения (output). Размерность выходных данных можно узнать с помощью свойства shape.\n",
    "## <a name=\"_36550ywvw9xw\"></a>**35.  Слои нелинейной активации (Non Linear Activations).**\n",
    "Слои нелинейной активации являются важным компонентом нейронных сетей, позволяющим моделировать сложные нелинейные зависимости в данных. Они добавляют нелинейность в выходные значения слоя и позволяют нейронной сети изучать и аппроксимировать более сложные функции.\n",
    "\n",
    "В отличие от линейных слоев, которые выполняют только линейное преобразование входных данных, слои нелинейной активации применяют нелинейную функцию к выходу линейного слоя. Это позволяет модели изучать и приближать нелинейные отображения между входными и выходными данными.\n",
    "\n",
    "Некоторые из наиболее распространенных функций активации включают в себя:\n",
    "\n",
    "1. ReLU (Rectified Linear Unit): Функция активации ReLU определяется как f(x) = max(0, x). Она преобразует все отрицательные значения в ноль, сохраняя положительные значения без изменений. ReLU широко используется в нейронных сетях из-за своей простоты и эффективности.\n",
    "1. Sigmoid: Функция активации сигмоид (Sigmoid) определяется как f(x) = 1 / (1 + exp(-x)). Она ограничивает выходное значение в диапазоне от 0 до 1 и широко применяется в задачах бинарной классификации.\n",
    "1. Tanh (гиперболический тангенс): Функция активации тангенс гиперболический (Tanh) определяется как f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x)). Она ограничивает выходное значение в диапазоне от -1 до 1 и используется в различных задачах.\n",
    "1. LeakyReLU: Функция активации LeakyReLU определяется как f(x) = max(αx, x), где α - маленькое положительное число (обычно около 0.01). Она вводит небольшой отрицательный наклон для отрицательных значений, чтобы предотвратить проблему \"мертвых нейронов\" (dead neurons) в нейронной сети.\n",
    "\n",
    "Выбор конкретной функции активации зависит от задачи и свойств данных. В некоторых случаях может быть полезно применять различные функции активации в разных слоях сети.\n",
    "\n",
    "Пример использования функции активации ReLU в PyTorch:\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\\# Создание слоя с функцией активации ReLU\n",
    "\n",
    "relu\\_layer = nn.ReLU()\n",
    "\n",
    "\\# Пример применения функции активации\n",
    "\n",
    "input\\_data = torch.randn(32, 10)  # входные данные размером 32x10\n",
    "\n",
    "output = relu\\_layer(input\\_data)  # применение функции активации\n",
    "\n",
    "print(output.shape)  # вывод размерности выходных данных\n",
    "\n",
    "В этом примере мы создаем слой с функцией активации ReLU с помощью nn.ReLU(). Затем мы применяем эту функцию активации к некоторым входным данным (input\\_data) и получаем выходные значения (output). Размерность выходных данных можно узнать с помощью свойства shape.\n",
    "## <a name=\"_lkn12j3n412c\"></a>**36.  Слои нормализации (Normalization Layers).**\n",
    "В глубоком обучении, нормализация данных является важной частью процесса обучения нейронных сетей. Она помогает уменьшить влияние различных масштабов значений признаков на процесс обучения, ускорить сходимость модели и повысить ее точность. В PyTorch, существуют различные слои нормализации, которые можно использовать для этой цели.\n",
    "\n",
    "Процесс нормализации данных в PyTorch осуществляется путем применения определенных математических операций к выходным данным слоя. В зависимости от того, на каком уровне происходит нормализация, выделяют три типа слоев нормализации: Batch Normalization (BN), Layer Normalization (LN) и Instance Normalization (IN).\n",
    "### <a name=\"_a44lg3riaj94\"></a>**Batch Normalization**\n",
    "Batch Normalization - это метод нормализации данных, который используется для ускорения обучения нейронных сетей. Он применяется к выходным данным слоя и нормализует их по среднему значению и стандартному отклонению батча. Таким образом, BN работает на уровне батча, а не на уровне отдельных примеров. Использование BN слоя позволяет достичь более быстрой сходимости модели и существенно сократить время обучения.\n",
    "\n",
    "Пример использования BN в PyTorch:\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "`\t`def \\_\\_init\\_\\_(self):\n",
    "\n",
    "`    \t`super(NeuralNetwork, self).\\_\\_init\\_\\_()\n",
    "\n",
    "`    \t`self.fc1 = nn.Linear(10, 20)\n",
    "\n",
    "`    \t`self.bn1 = nn.BatchNorm1d(20)\n",
    "\n",
    "`    \t`self.fc2 = nn.Linear(20, 2)\n",
    "\n",
    "`\t`def forward(self, x):\n",
    "\n",
    "`    \t`x = self.fc1(x)\n",
    "\n",
    "`    \t`x = self.bn1(x)\n",
    "\n",
    "`    \t`x = self.fc2(x)\n",
    "\n",
    "`    \t`return x\n",
    "### <a name=\"_cwh74oh5xt6m\"></a>**Layer Normalization**\n",
    "Layer Normalization - это метод нормализации данных, который применяется на уровне слоя. Он нормализует выходные данные слоя по среднему значению и стандартному отклонению слоя. В отличие от BN, который работает на уровне батча, LN нормализует данные на уровне слоя. Таким образом, LN позволяет устранить нежелательное влияние различных батчей на процесс обучения модели.\n",
    "\n",
    "Пример использования LN в PyTorch:\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "`\t`def \\_\\_init\\_\\_(self):\n",
    "\n",
    "`    \t`super(NeuralNetwork, self).\\_\\_init\\_\\_()\n",
    "\n",
    "`    \t`self.fc1 = nn.Linear(10, 20)\n",
    "\n",
    "`    \t`self.ln1 = nn.LayerNorm(20)\n",
    "\n",
    "`    \t`self.fc2 = nn.Linear(20, 2)\n",
    "\n",
    "`\t`def forward(self, x):\n",
    "\n",
    "`    \t`x = self.fc1(x)\n",
    "\n",
    "`    \t`x = self.ln1(x)\n",
    "\n",
    "`    \t`x = self.fc2(x)\n",
    "\n",
    "`    \t`return x\n",
    "### <a name=\"_4e5c84d2ibq2\"></a>**Instance Normalization**\n",
    "Instance Normalization - это метод нормализации данных, который применяется на уровне каждого примера в батче. Он нормализует выходные данные по среднему значению и стандартному отклонению примера. Этот метод нормализации используется для обработки изображений, где каждый пиксель рассматривается как отдельный пример. Использование IN позволяет добиться лучшей производительности модели на задачах компьютерного зрения.\n",
    "\n",
    "Пример использования IN в PyTorch:\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "`\t`def \\_\\_init\\_\\_(self):\n",
    "\n",
    "`    \t`super(NeuralNetwork, self).\\_\\_init\\_\\_()\n",
    "\n",
    "`    \t`self.conv1 = nn.Conv2d(3, 64, kernel\\_size=3)\n",
    "\n",
    "`  \t  `self.in1 = nn.InstanceNorm2d(64)\n",
    "\n",
    "`    \t`self.conv2 = nn.Conv2d(64, 128, kernel\\_size=3)\n",
    "\n",
    "`    \t`self.in2 = nn.InstanceNorm2d(128)\n",
    "\n",
    "`\t`def forward(self, x):\n",
    "\n",
    "`    \t`x = self.conv1(x)\n",
    "\n",
    "`    \t`x = self.in1(x)\n",
    "\n",
    "`    \t`x = self.conv2(x)\n",
    "\n",
    "`    \t`x = self.in2(x)\n",
    "\n",
    "`    \t`return x\n",
    "\n",
    "С помощью этих слоев нормализации данных в PyTorch можно добиться лучшей производительности нейронной сети и улучшить ее обучение. Однако, при выборе метода нормализации данных необходимо учитывать особенности конкретной задачи и размера датасета.\n",
    "### <a name=\"_xo3fo726t3qn\"></a>**Обобщенно и кратко**\n",
    "В глубоком обучении, нормализация данных является важной частью процесса обучения нейронных сетей. Она помогает уменьшить влияние различных масштабов значений признаков на процесс обучения, ускорить сходимость модели и повысить ее точность. В PyTorch, существуют три типа слоев нормализации: Batch Normalization (BN), Layer Normalization (LN) и Instance Normalization (IN).\n",
    "\n",
    "Batch Normalization - это метод нормализации данных, который используется для ускорения обучения нейронных сетей. Он применяется к выходным данным слоя и нормализует их по среднему значению и стандартному отклонению батча.\n",
    "\n",
    "Layer Normalization - это метод нормализации данных, который применяется на уровне слоя. Он нормализует выходные данные слоя по среднему значению и стандартному отклонению слоя.\n",
    "\n",
    "Instance Normalization - это метод нормализации данных, который применяется на уровне каждого примера в батче. Он нормализует выходные данные по среднему значению и стандартному отклонению примера.\n",
    "\n",
    "Применение этих слоев нормализации данных в PyTorch позволяет добиться лучшей производительности и точности нейронной сети при обучении. Однако, при выборе метода нормализации данных необходимо учитывать особенности конкретной задачи и размера датасета.\n",
    "\n",
    "## <a name=\"_r5m9vub88xia\"></a>**37.  Слои регуляризации (Dropout Layers).**\n",
    "Слои регуляризации, такие как слои Dropout, являются важными инструментами в глубоком обучении для борьбы с переобучением моделей. Переобучение возникает, когда модель слишком точно запоминает обучающие данные и не может обобщать на новые данные.\n",
    "\n",
    "Слой Dropout работает путем случайного обнуления (отключения) некоторых выходных признаков во время обучения. Это делается независимо для каждого образца входных данных. На каждой итерации обучения каждый признак отключается с определенной вероятностью p, или оставляется включенным с вероятностью (1-p). Таким образом, каждый раз, когда передается пакет данных через слой Dropout, некоторые признаки случайным образом отключаются, и модель обучается на подмножестве признаков.\n",
    "\n",
    "Преимущество слоя Dropout заключается в том, что он предотвращает переобучение и снижает взаимозависимость между нейронами в сети. Он заставляет модель стать более устойчивой и генерализировать лучше на новых данных.\n",
    "\n",
    "В pytorch dropout-регуляризация используется с помощью torch.nn.Dropout(p=0.5, inplace=False), где p ([*float*](https://docs.python.org/3/library/functions.html#float)) – вероятность того, что элемент будет обнулен. По умолчанию: 0,5. \n",
    "\n",
    "пример использования дропаута при построении модели: \n",
    "### <a name=\"_hcjs66cdt7sp\"></a>**Из лекции макрушина**\n",
    "**Проблема переобучения модели**\t\t\t\t\t\t\n",
    "\n",
    "модель, у которой слишком много свободных параметров, **плохо обобщается**: то есть слишком близко «облизывает» точки из тренировочного множества и в результате недостаточно хорошо предсказывает нужные значения в новых точках.\t\t\n",
    "\n",
    "В современных нейронных сетях огромное число параметров (даже не самая сложная архитектура может содержать миллионы весов) **надо регуляризовать параметры**! \n",
    "\n",
    "**Dropout**\n",
    "\n",
    "**Регуляризация с помощью дропаута** (dropout regularization) - один из важнейших методов регуляризации нейронных сетей обеспечивший революцию глубокого обучения. \n",
    "\n",
    "Идея метода (очень простая!):\n",
    "\n",
    "- Для каждого нейрона (кроме самого последнего, выходного слоя) установим некоторую вероятность p, с которой он будет выброшен из сети.\n",
    "\n",
    "Алгоритм обучения меняется таким образом:\n",
    "\n",
    "- на каждом новом тренировочном примере x мы сначала для каждого **разыгрываем вероятность p** и в зависимости от результата либо используем нейрон как обычно, **либо устанавливаем его выход всегда строго равным нулю** (вероятность этого события 1 - p).\n",
    "- **Дальше все происходит без изменений**; ноль на выходе приводит к тому, что нейрон фактически выпадает из графа вычислений: и прямое вычисление, и обратное распространение градиента останавливаются на этом нейроне и дальше не идут.\n",
    "- Для применения обученной сети **используются все нейроны** в конфигурации, которая была до применения дропаута, но **выход каждого нейрона умножается на вероятность p** (с которой нейрон оставляли при обучении)\n",
    "\n",
    "Для очень широкого спектра архитектур и приложений замечательно подходит p = 1/2\n",
    "\n",
    "`\t\t`![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.010.png)\t\t\n",
    "\n",
    "Практика обучения нейронных сетей показывает, что дропаут действительно дает очень серьезные улучшения в качестве обученной модели. \n",
    "\n",
    "Дропаут — это метод добиться **усреднения огромного чмсла моделей** (до 2^N возможных моделей, N — число нейронов, которые подвергаются дропауту). Он эквивалентен усреднению всех моделей, которые получались на каждом шаге случайным выбрасыванием отдельных нейронов. \n",
    "\n",
    "Пример использования dropuot в pytorch: \n",
    "\n",
    "**def** \\_\\_init\\_\\_(self, rnn\\_type, input\\_size, node\\_fdim, hidden\\_size, depth, dropout):\n",
    "\n",
    "super(MPNEncoder, self).\\_\\_init\\_\\_()\n",
    "self.hidden\\_size **=** hidden\\_size\n",
    "self.input\\_size **=** input\\_size\t\t\t\t\t\t\n",
    "\n",
    "self.depth **=** depth self.\n",
    "\n",
    "W\\_o **=** nn.Sequential(\t\t\t\t\t\n",
    "\n",
    "nn.Linear(node\\_fdim **+** hidden\\_size, hidden\\_size),\n",
    "\n",
    "nn.ReLU(),\n",
    "\n",
    "nn.Dropout(dropout)\t\t\t\t\t\t\n",
    "\n",
    ")\t\t\t\t\t\t\n",
    "\n",
    "**if** rnn\\_type **==** 'GRU':\n",
    "\n",
    "self.rnn **=** GRU(input\\_size, hidden\\_size, depth)\t\t\t\t\n",
    "\n",
    "**elif** rnn\\_type **==** 'LSTM':\n",
    "\n",
    "self.rnn **=** LSTM(input\\_size, hidden\\_size, depth)\t\t\t\t\n",
    "\n",
    "**else**:\n",
    "\n",
    "` `**raise** ValueError('unsupported rnn cell type ' **+** rnn\\_type) \n",
    "## <a name=\"_i3mapvr8ryuz\"></a>**38.  Сверточные слои (Convolution Layers). Сжимающие слои (Pooling Layers).**\n",
    "### <a name=\"_3xymupjyu4jb\"></a>**Обобщенно и кратко** \n",
    "Сверточные слои и слои сжатия (пулинга) являются ключевыми компонентами сверточных нейронных сетей (Convolutional Neural Networks, CNN) и широко используются в обработке изображений и анализе последовательностей.\n",
    "\n",
    "Сверточные слои выполняют операцию свертки между входными данными и фильтрами (ядрами свертки), чтобы извлечь локальные пространственные шаблоны. Каждый фильтр перемещается по входным данным, применяя свертку, и результаты суммируются для создания карты признаков. Это позволяет нейронной сети обнаруживать различные уровни абстракции в данных, начиная от простых функций, таких как границы и углы, до более сложных шаблонов.\n",
    "\n",
    "Слой сжатия (пулинга) используется для уменьшения размерности карты признаков, сохраняя важные информационные характеристики. Самая распространенная операция пулинга - это операция субдискретизации (subsampling), которая уменьшает размер карты признаков, выбирая наиболее значимые значения в заданной области.\n",
    "\n",
    "Сверточные слои и слои сжатия вместе позволяют моделям CNN автоматически извлекать иерархические признаки из входных данных, что делает их особенно эффективными для задач компьютерного зрения и обработки изображений.\n",
    "\n",
    "### <a name=\"_uxpo3dqezn45\"></a>**Реализация в питхурче:** \t\t\t\t\t\t\n",
    "**torch.nn.Conv2d**(in\\_channels, out\\_channels, kernel\\_size, stride=1, padding=0,\n",
    "\n",
    "dilation=1, groups=1, bias=True, padding\\_mode='zeros')\n",
    "\n",
    "- in\\_channels (int) – Number of channels in the input image ( ) \n",
    "- out\\_channels (int) – Number of channels produced by the convolution ( ) \n",
    "- kernel\\_size (int or tuple) – Size of the convolving kernel\n",
    "\n",
    "Shape:\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.037.png)\n",
    "\n",
    "torch.nn.MaxPool2d(kernel\\_size, stride=None, padding=0, dilation=1, return\\_indices=False, ceil\\_mode=False) - Applies a 2D max pooling over an input signal composed of several input planes\n",
    "\n",
    "- kernel\\_size – the size of the window to take a max over\n",
    "- stride – the stride of the window. **Default value is kernel\\_size**\n",
    "- padding – implicit zero padding to be added on both sides\n",
    "- dilation – a parameter that controls the stride of elements in the window\n",
    "- return\\_indices – if True, will return the max indices along with the outputs. Useful for torch.nn.MaxUnpool2d later\n",
    "- ` `ceil\\_mode – when True, will use ceil instead of floor to compute the output shape ![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.038.png)\n",
    "\n",
    "пример: \n",
    "\n",
    "\n",
    "\n",
    "ex1 **=** example\\_data \n",
    "\n",
    "print('ex1:', ex1.shape)\n",
    "\n",
    "conv1 **=** nn.Conv2d(1, 10, kernel\\_size**=**5) \n",
    "\n",
    "ex2 **=** conv1(ex1)\n",
    "\n",
    "print('ex2:', ex2.shape)\n",
    "\n",
    "ex3 **=** F.max\\_pool2d(ex2, 2) \n",
    "\n",
    "print('ex3:', ex3.shape)\n",
    "\n",
    "conv2 **=** nn.Conv2d(10, 20, kernel\\_size**=**5) \n",
    "\n",
    "ex4 **=** conv2(ex3)\n",
    "\n",
    "print('ex4:', ex4.shape)\n",
    "ex5 **=** F.max\\_pool2d(ex4, 2)\t\t\t\t\t\n",
    "\n",
    "print('ex5:', ex5.shape)\n",
    "\n",
    "output: \n",
    "\n",
    "ex1: torch.Size([1000, 1, 28, 28])\n",
    "\n",
    "ex2: torch.Size([1000, 10, 24, 24])\n",
    "\n",
    "ex3: torch.Size([1000, 10, 12, 12])\n",
    "\n",
    "ex4: torch.Size([1000, 20, 8, 8])\n",
    "\n",
    "ex5: torch.Size([1000, 20, 4, 4])\n",
    "\n",
    "### <a name=\"_qpmw4fcthm94\"></a> **// Из лекции макрушина (взять если нужно налить в ответ еще воды или разобраться в теме)** \n",
    "\n",
    "Сверточные слои:\n",
    "\n",
    "- изучают **локальные шаблоны** (в случае с изображениями — шаблоны в **небольших двумерных окнах** во входных данных)\n",
    "- изучают шаблоны **инвариантные в отношениии переноса** (шаблон будет с одинаковым качеством выявлен как в центре изображения, так и в левом нижнем углу, для полносвязной сети эти две задачи выглядели бы как совершенно разные задачи) \t\t\t\t\t\t\n",
    "- Сверточный слой выделяет признаки в каждом окне небольшой нейронной сетью. В каждом окне выделяются одни и те же признаки, т.е. используется одна и та же маленькая нейронная сеть. Например, если окно 3 \\* 3 пикселя, то входов у нее будет всего 9 и для каждого окна, в котором она будет применена, будет получен отдельный выход. \t\t\t\t\t\t\n",
    "- Свертка — линейное преобразование входных данных особого вида. Если x1  — карта признаков в слое под номером l, то результат двумерной свертки с ядром размера 2d +1 и матрицей весов W размера (2d + 1) x (2d + 1)  на следующем слое будет таким:![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.039.png), где![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.040.png) - результат свертки на уровне l, а![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.041.png) — ее вход, то есть выход всего предыдущего слоя. \t\t\t\t\t\t\n",
    "- Почти всегда после свертки в нейронной сети следует нелинейность, которую можно записать так: ![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.042.png). В качестве функции может использоваться любая функция активации, в глубоких сетях обычно предпочитают функцию ReLU, но и классические функции сигмоиды и tanh тоже встречаются. \t\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.043.png)\t\t\t\t\n",
    "\n",
    "**Применение одного слоя свертки к одному слою входных данных**\n",
    "\n",
    "1. Свертка работает **методом скользящего окна**: она двигает окно с размером ядра (например 3 \\* 3) по трехмерной входной карте признаков, останавливается в каждой возможной позиции и извлекает трехмерный шаблон окружающих признаков (с формой *[ высота\\_окна, ширина\\_окна, глубина\\_входа ]* ).\n",
    "1. Затем каждый **трехмерный шаблон преобразуется** (путем умножения тензора на матрицу весов, получаемую в ходе обучения, которая называется ядром свертки) в одномерный вектор с формой *[выходная глубина]*.\n",
    "1. Затем все эти векторы **собираются в трехмерную выходную карту** с формой *[высота\\_окна, ширина\\_окна, выходная\\_глубина]* \\* Каждое пространственное местоположение в выходной карте признаков соответствует тому же местоположению во входной карте признаков (например, правый нижний угол выхода содержит информацию о правом нижнем углу входа).\n",
    "1. Размерность тензора сверточных весов определяется **размерами ядра свертки и числом каналов как на входе, так и на выходе** (число каналов на входе и на выходе может не совпадать!). Таким обазом для двухмерного изображения тензор ядра свертки четырехмерный соследующими размерностями: *[высота\\_ядра, ширина\\_ядра, входные\\_каналы, выходные\\_каналы]*. \n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.044.png)\n",
    "\n",
    "**Изменение размеров карты признаков**\t\t\t\t\t\t\n",
    "\n",
    "Выходные ширина и высота карты признаков могут отличаться от входных из-за:\n",
    "\n",
    "- эффекта границ, который, при необходимости может устраняться дополнением входной карты признаков;\n",
    "- использования шага свертки. Изменения размеров карты признаков обычно не является проблемой, зачастую уменьшение размеров карты является даже желательным эффектом.\t\t\t\t\t\t\n",
    "\n",
    "**Эффект границ**\n",
    "\n",
    "Рассмотрим карту признаков 5 × 5 (всего 25 клеток). Существует всего 9 клеток, в которых может находиться центр окна 3 × 3, образующих сетку 3 × 3. Следовательно, карта выходных признаков будет иметь размер 3 × 3. Она получилась немного сжатой: ровно на две клетки вдоль каждого измерения.\t\t\t\t\t\t\n",
    "\n",
    "Чтобы получить выходную карту признаков с теми же пространственными размерами, что и входная карта, можно использовать дополнение (padding). Дополнение заключается в добавлении соответствующего количества строк и столбцов с каждой стороны входной карты признаков, чтобы можно было поместить центр окна свертки в каждую входную клетку. \n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.045.png)\n",
    "\n",
    "В слое Conv2D дополнение настраивается аргумента *padding* :\n",
    "\n",
    "- значенияе *\"valid\"* (по умолчанию) - отсутствие дополнения (будут использоваться только допустимые местоположения окна),\n",
    "- значенияе *\"same\"* - карта дополняется так, чтобы выходная карта признаков имела ту же ширину и высоту, что и входная». \n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.046.png)\n",
    "\n",
    "## <a name=\"_26s9kwio6sqp\"></a>**39.  Слои функций потерь (Loss Functions).**\n",
    "\n",
    "Слои функций потерь играют важную роль в обучении нейронных сетей, так как они определяют, насколько хорошо модель справляется с поставленной задачей и позволяют оптимизировать параметры модели в процессе обучения.\n",
    "\n",
    "Функция потерь (или функция ошибки) измеряет расхождение между предсказаниями модели и истинными значениями целевой переменной. Цель обучения нейронной сети - минимизировать значение функции потерь.\n",
    "\n",
    "В зависимости от типа задачи (классификация, регрессия, сегментация и т. д.) и свойств данных, применяются различные функции потерь. Некоторые распространенные функции потерь включают среднеквадратичную ошибку (MSE) для регрессии, перекрестную энтропию (cross-entropy) для классификации и дискриминативную функцию потерь (discriminative loss) для сегментации.\n",
    "\n",
    "Выбор подходящей функции потерь зависит от конкретной задачи и требует тщательного анализа данных и целей модели. Наиболее часто используемые функции потерь: \n",
    "\n",
    "1. **Среднеквадратичная ошибка (MSE)**: эта функция потерь измеряет среднеквадратичное отклонение между истинными и предсказанными значениями. Это стандартная функция потерь для задач регрессии. В контексте нейронных сетей, MSE воздействует на модель таким образом, чтобы она уменьшала разницу между предсказаниями и истинными значениями\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\\# инициализация функции потерь\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\\# предсказанные значения (предположим, что мы получили их от нашей модели)\n",
    "\n",
    "predictions = torch.randn(3, 5, requires\\_grad=True)\n",
    "\n",
    "\\# истинные значения\n",
    "\n",
    "targets = torch.randn(3, 5)\n",
    "\n",
    "\\# вычисление функции потерь\n",
    "\n",
    "loss = criterion(predictions, targets)\n",
    "\n",
    "\\# обратное распространение ошибки\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "1. **Перекрестная энтропия (Cross Entropy)**: эта функция потерь обычно используется в задачах классификации. Перекрестная энтропия измеряет разницу между двумя вероятностными распределениями: распределением, предсказанным моделью, и истинным распределением меток. В контексте классификации модель обучается минимизировать перекрестную энтропию, что делает предсказанные вероятности ближе к истинным меткам.\n",
    "\n",
    "\\# инициализация функции потерь\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\\# предсказанные значения (предположим, что мы получили их от нашей модели)\n",
    "\n",
    "predictions = torch.randn(3, 5, requires\\_grad=True)\n",
    "\n",
    "\\# истинные значения (индексы классов)\n",
    "\n",
    "targets = torch.empty(3, dtype=torch.long).random\\_(5)\n",
    "\n",
    "\\# вычисление функции потерь\n",
    "\n",
    "loss = criterion(predictions, targets)\n",
    "\n",
    "\\# обратное распространение ошибки\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "1. **Бинарная кросс-энтропия (Binary Cross Entropy)**: это специализированная версия перекрестной энтропии, которая применяется к бинарным классификационным задачам. Она измеряет расхождение между истинными метками (которые могут быть либо 0, либо 1) и предсказанными вероятностями модели.\n",
    "\n",
    "\\# инициализация функции потерь\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\\# предсказанные значения (предположим, что мы получили их от нашей модели)\n",
    "\n",
    "predictions = torch.sigmoid(torch.randn(3, 5, requires\\_grad=True))\n",
    "\n",
    "\\# истинные значения\n",
    "\n",
    "targets = torch.empty(3, 5).random\\_(2)\n",
    "\n",
    "\\# вычисление функции потерь\n",
    "\n",
    "loss = criterion(predictions, targets)\n",
    "\n",
    "\\# обратное распространение ошибки\n",
    "\n",
    "loss.backward()\n",
    "## <a name=\"_1n63h6eqv0b5\"></a>**40.  Слои эмбеддингов nn.Embedding и их применение.**\n",
    "\n",
    "Слой эмбеддингов nn.Embedding является инструментом для обработки категориальных (дискретных) данных в нейронных сетях. Он позволяет представить категориальные признаки в виде непрерывных векторных представлений, называемых эмбеддингами.\n",
    "\n",
    "Слой nn.Embedding принимает индексы категориальных признаков и возвращает соответствующие эмбеддинги для каждого индекса. Эти эмбеддинги обычно инициализируются случайно, а затем обучаются вместе с остальными параметрами модели в процессе обратного распространения ошибки.\n",
    "\n",
    "Применение слоя эмбеддингов особенно полезно в задачах, где важна семантическая связь между категориями, например, в обработке естественного языка (Natural Language Processing, NLP). С помощью эмбеддингов можно представить слова, символы или другие дискретные единицы текста в виде плотных векторов, учитывая их семантическую схожесть и контекстуальные отношения.\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.047.png)\n",
    "\n",
    "**// Перед непосредственно эмбеддингами я бы рассказала про векторное представление и one-hot кодировку**\n",
    "\n",
    "**Векторное представление слов** - это способ кодирования слов или фраз в машинно-читаемые векторы чисел. Это необходимо, потому что, хотя слова имеют значение для нас, машины не могут напрямую обрабатывать текстовые данные. Вместо этого нам нужно конвертировать эти текстовые данные в числовые форматы, которые машины могут обрабатывать.\n",
    "\n",
    "**One-hot представление** - это метод кодирования категориальных данных в бинарный вектор. Для каждого уникального слова в словаре создается вектор, длиной равный общему количеству уникальных слов в словаре. Все значения в векторе устанавливаются в 0, за исключением одного, который устанавливается в 1, чтобы обозначить наличие этого слова.\n",
    "\n",
    "Пример: представим, что у нас есть словарь из трех слов: {'cat', 'dog', 'bird'}. One-hot представление для слова 'cat' будет [1, 0, 0], для слова 'dog' будет [0, 1, 0], и для слова 'bird' будет [0, 0, 1].\n",
    "\n",
    "Проблема с one-hot представлением состоит в том, что оно не учитывает семантическую близость слов и может быть неэффективным для больших словарей, поскольку большинство элементов в векторах будут равны нулю (это называется \"разреженностью\" данных).\n",
    "\n",
    "**Слой эмбеддинга (Embedding layer)**, такой как **nn.Embedding** в PyTorch, используется для преобразования one-hot векторов в плотные векторы фиксированной длины. Эти плотные векторы обучаются вместе с другими параметрами в нейронной сети. В результате слова с похожими значениями будут иметь более близкие векторы, что улучшает обработку естественного языка для многих задач, таких как классификация текстов, генерация текстов, анализ тональности и многое другое.\n",
    "\n",
    "torch.nn.Embedding(*num\\_embeddings*, *embedding\\_dim*, *padding\\_idx=None*, *max\\_norm=None*, *norm\\_type=2.0*, *scale\\_grad\\_by\\_freq=False*, *sparse=False*, *\\_weight=None*, *\\_freeze=False*, *device=None*, *dtype=None*)\n",
    "\n",
    "Parameters\n",
    "\n",
    "- num\\_embeddings ( [int](https://docs.python.org/3/library/functions.html#int) ) — размер словаря вложений\n",
    "- embedding\\_dim ( [int](https://docs.python.org/3/library/functions.html#int) ) — размер каждого вектора встраивания\n",
    "- padding\\_idx ( [int ](https://docs.python.org/3/library/functions.html#int), необязательный ) — если указано, дополняет вывод вектором внедрения в padding\\_idx (инициализируется нулями) всякий раз, когда встречается индекс.\n",
    "- max\\_norm ( [float ](https://docs.python.org/3/library/functions.html#float), необязательный ) — если указано, каждый вектор вложения с нормой больше max\\_norm перенормируется, чтобы иметь норму max\\_norm .\n",
    "- norm\\_type ( [float ](https://docs.python.org/3/library/functions.html#float), необязательный ) – p p-нормы для вычисления для опции max\\_norm . По умолчанию 2 .\n",
    "- scale\\_grad\\_by\\_freq ( логическое значение , необязательный ) — если задано, это будет масштабировать градиенты на величину, обратную частоте слов в мини-пакете. По умолчанию False .\n",
    "- разреженный ( [bool ](https://docs.python.org/3/library/functions.html#bool), необязательный ) — если True , градиент относительно матрицы weight будет разреженным тензором. Дополнительные сведения о разреженных градиентах см. в разделе «Примечания».\n",
    "\n",
    "Variables\n",
    "\n",
    "~ Embedding.weight ( [Tensor](https://runebook.dev/ru/docs/pytorch/tensors#torch.Tensor) ) — обучаемые веса модуля формы (num\\_embeddings, embedding\\_dim), инициализированные из N(0,1)\n",
    "\n",
    "Shape:\n",
    "\n",
    "- Input:(∗) , IntTensor или LongTensor произвольной формы, содержащие индексы для извлечения\n",
    "- Output:(∗, Н) , где \\* - входная форма, аН=embedding\\_dim\n",
    "\n",
    "Вот пример использования слоя nn.Embedding:\n",
    "\n",
    "**>>>** *# an Embedding module containing 10 tensors of size 3*\n",
    "\n",
    "**>>> embedding** **=** **nn.Embedding(**10**,** 3**)**\n",
    "\n",
    "**>>>** *# a batch of 2 samples of 4 indices each*\n",
    "\n",
    "**>>>** input **=** **torch.LongTensor([[**1**,** 2**,** 4**,** 5**],** **[**4**,** 3**,** 2**,** 9**]])**\n",
    "\n",
    "**>>> embedding(**input**)**\n",
    "\n",
    "tensor([[[-0.0251, -1.6902,  0.7172],\n",
    "\n",
    "`         `[-0.6431,  0.0748,  0.6969],\n",
    "\n",
    "`         `[ 1.4970,  1.3448, -0.9685],\n",
    "\n",
    "`         `[-0.3677, -2.7265, -0.1685]],\n",
    "\n",
    "`        `[[ 1.4970,  1.3448, -0.9685],\n",
    "\n",
    "`         `[ 0.4362, -0.4004,  0.9400],\n",
    "\n",
    "`         `[-0.6431,  0.0748,  0.6969],\n",
    "\n",
    "`         `[ 0.9124, -2.3616,  1.1151]]])\n",
    "\n",
    "\n",
    "В этом примере каждое уникальное слово в словаре представлено вектором размерностью 5. Эмбеддинги инициализируются случайными числами и обновляются в процессе обучения сети с использованием методов оптимизации, таких как стохастический градиентный спуск.\n",
    "\n",
    "## <a name=\"_1nzci3hj79ax\"></a>**41.  Класс torch.nn.LSTM и torch.nn.GRU.**\n",
    "\n",
    "Классы torch.nn.LSTM и torch.nn.GRU являются реализациями рекуррентных нейронных сетей (Recurrent Neural Networks, RNN) в фреймворке PyTorch.\n",
    "\n",
    "LSTM (Long Short-Term Memory) и GRU (Gated Recurrent Unit) - это две популярные архитектуры RNN, которые преодолевают проблему затухания и взрыва градиентов, характерную для простых RNN. Они способны моделировать долгосрочные зависимости в последовательных данных и позволяют передавать информацию через длительные временные интервалы.\n",
    "\n",
    "Классы torch.nn.LSTM и torch.nn.GRU предоставляют удобные интерфейсы для создания и обучения моделей LSTM и GRU. Они принимают входные данные с последовательным форматом (например, временные ряды, текстовые данные) и обрабатывают их с учетом внутренних состояний и входного потока.\n",
    "\n",
    "LSTM и GRU нашли широкое применение в различных областях, включая обработку естественного языка, машинный перевод, распознавание речи и генерацию текста. Они предоставляют мощный инструментарий для работы с последовательными данными и моделирования контекстуальных зависимостей.\n",
    "\n",
    "// (см вопрос 25, там полностью лекция макрушина): \n",
    "\n",
    "LSTM (Long Short-Term Memory)\n",
    "\n",
    "- обычные рекуррентные сети очень плохо справляются с ситуациями, когда нужно что-то «запомнить» надолго: влияние скрытого состояния или входа с шага t на последующие состояния рекуррентной сети экспоненциально затухает\n",
    "- LSTM хорошо приспособлена к обучению на задачах классификации, обработки и прогнозирования временных рядов в случаях, когда важные события разделены временными лагами с неопределённой продолжительностью и границами вместо одного-единственного числа, на которое влияют все последующие состояния, используется специального вида ячейка моделирующая \"долгую память\"\n",
    "- LSTM моделирует процессы записи и чтения из этой \"ячейки памяти\"\n",
    "- у ячейки не один набор весов, как у обычного нейрона, а сразу несколько\n",
    "\n",
    "В LSTM есть три основных вида узлов, которые называются гейтами:\n",
    "\n",
    "- входной (input gate)\n",
    "- забывающий (forget gate)\n",
    "- выходной (output gate)\n",
    "- рекуррентная ячейка со скрытым состоянием\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.048.png)\n",
    "\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.026.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.027.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.028.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.049.png)\n",
    "\n",
    "![](./img/Aspose.Words.57c8d798-c557-4ace-abc5-bafd2a7296cd.030.png)\n",
    "\n",
    "Модель:\n",
    "\n",
    "torch.nn.LSTM(\\*args, \\*\\*kwargs)\n",
    "\n",
    "пример использования:\n",
    "class RNNModule(nn.Module):\n",
    "\n",
    "def \\_\\_init\\_\\_(self, n\\_vocab, seq\\_size, embedding\\_size, lstm\\_size):\n",
    "\n",
    "super(RNNModule, self).\\_\\_init\\_\\_()\n",
    "\n",
    "self.seq\\_size = seq\\_size\n",
    "\n",
    "self.lstm\\_size = lstm\\_size\n",
    "\n",
    "self.embedding = nn.Embedding(n\\_vocab, embedding\\_size)\n",
    "\n",
    "self.lstm = nn.LSTM(embedding\\_size, lstm\\_size, batch\\_first=True)\n",
    "\n",
    "self.dense = nn.Linear(lstm\\_size, n\\_vocab)\n",
    "\n",
    "def forward(self, x, prev\\_state):\n",
    "\n",
    "embed = self.embedding(x)\n",
    "\n",
    "output, state = self.lstm(embed, prev\\_state)\n",
    "\n",
    "logits = self.dense(output)\n",
    "\n",
    "return logits, state\n",
    "\n",
    "def zero\\_state(self, batch\\_size):\n",
    "\n",
    "return (torch.zeros(1, batch\\_size, self.lstm\\_size), torch.zeros(1, batch\\_size, self.lstm\\_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
