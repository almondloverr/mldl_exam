{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 1: Введение в искусственные нейронные сети (artificial neural networks) и глубокое обучение (deep learning)\n",
    "\n",
    "__Автор: Сергей Вячеславович Макрушин__ e-mail: SVMakrushin@fa.ru \n",
    "\n",
    "Финансовый универсиет, 2021 г. \n",
    "\n",
    "При подготовке лекции использованы материалы:\n",
    "* ...\n",
    "\n",
    "V 0.3 04.02.2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделы: <a class=\"anchor\" id=\"разделы\"></a>\n",
    "* [Серии (Series) - одномерные массивы в Pandas](#серии)\n",
    "* [Датафрэйм (DataFrame) - двумерные массивы в Pandas](#датафрэйм)\n",
    "    * [Введение](#датафрэйм-введение)\n",
    "    * [Индексация](#датафрэйм-индексация)    \n",
    "* [Обработка данных в библиотеке Pandas](#обработка-данных)\n",
    "    * [Универсальные функции и выравнивание](#обработка-данных-универсальные)\n",
    "    * [Работа с пустыми значениями](#обработка-данных-пустрые-значения)\n",
    "    * [Агрегирование и группировка](#обработка-данных-агрегирование)    \n",
    "* [Обработка нескольких наборов данных](#обработка-нескольких)\n",
    "    * [Объединение наборов данных](#обработка-нескольких-объединение)\n",
    "    * [GroupBy: разбиение, применение, объединение](#обработка-нескольких-групбай)\n",
    " \n",
    "-\n",
    "\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "﻿<style>\r\n",
       "\r\n",
       "\r\n",
       "b.n {\r\n",
       "    font-weight: normal;        \r\n",
       "}\r\n",
       "\r\n",
       "b.grbg {\r\n",
       "    background-color: #a0a0a0;      \r\n",
       "}\r\n",
       "\r\n",
       "b.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "b.b {    \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "b.g {\r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "// add your CSS styling here\r\n",
       "\r\n",
       "list-style: none;\r\n",
       "\r\n",
       "ul.s {\r\n",
       "//    list-style-type: none;\r\n",
       "    list-style: none;\r\n",
       "//    background-color: #ff0000;  \r\n",
       "//    color: #ffff00;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;\r\n",
       "}\r\n",
       "\r\n",
       "li.t {\r\n",
       "    list-style: none;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "*.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "li.t:before {\r\n",
       "    content: \"\\21D2\";    \r\n",
       "//    content: \"►\";\r\n",
       "//    padding-left: -1.2em;    \r\n",
       "    text-indent: -1.2em;    \r\n",
       "    display: block;\r\n",
       "    float: left;\r\n",
       "    \r\n",
       "    \r\n",
       "//    width: 1.2em;\r\n",
       "//    color: #ff0000;\r\n",
       "}\r\n",
       "\r\n",
       "i.m:before {\r\n",
       "    font-style: normal;    \r\n",
       "    content: \"\\21D2\";  \r\n",
       "}\r\n",
       "i.m {\r\n",
       "    font-style: normal; \r\n",
       "}    \r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "/* em {\r\n",
       "    font-style: normal; \r\n",
       "} */\r\n",
       "\r\n",
       "\r\n",
       "em.bl {\r\n",
       "    font-style: normal;     \r\n",
       "    font-weight: bold;        \r\n",
       "}\r\n",
       "\r\n",
       "/* em.grbg {\r\n",
       "    font-style: normal;         \r\n",
       "    background-color: #a0a0a0;      \r\n",
       "} */\r\n",
       "\r\n",
       "em.cr {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cb {    \r\n",
       "    font-style: normal;         \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cg {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "\r\n",
       "em.qs {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.qs::before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #ff0000;    \r\n",
       "    content: \"Q:\";  \r\n",
       "}\r\n",
       "\r\n",
       "em.an {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.an:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"A:\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.nt {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.nt:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Note:\";  \r\n",
       "}    \r\n",
       "    \r\n",
       "em.ex {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.ex:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #00ff00;    \r\n",
       "    content: \"Ex:\";  \r\n",
       "} \r\n",
       "    \r\n",
       "em.df {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.df:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Def:\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.pl {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.pl:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"+\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.mn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.mn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"-\";  \r\n",
       "}        \r\n",
       "\r\n",
       "em.plmn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.plmn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\00B1\";\\\\\"&plusmn;\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.hn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.hn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\21D2\";\\\\\"&rArr;\";  \r\n",
       "}     \r\n",
       "    \r\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем стиль для оформления презентации\n",
    "from IPython.display import HTML\n",
    "from urllib.request import urlopen\n",
    "html = urlopen(\"file:./lec_v1.css\")\n",
    "HTML(html.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em class=\"df\"></em> __Искусственная нейронная сеть__ (ИНС, ANN) - математическая модель, а также её программное или аппаратное воплощение, разработанная под влиянием изучения организации и функционирования биологических нейронных сетей - сетей нервных клеток живого организма.\n",
    "\n",
    "ИНС представляет собой систему (сеть) соединённых и взаимодействующих между собой простых вычислительных элементов (искусственных нейронов), которые, в общем случае, умеют:\n",
    "* реагировать на входной сигнал, возвращая реакцию на него\n",
    "* хранить некоторые параметры, обеспечивающие вариативность реакции на входной сигнал\n",
    "* обучаться - определенным образом менять свои параметры в ходе выполнения операции обучения\n",
    "\n",
    "Каждый искуственный нейрон обычно достаточно просто устроен и явлется узлом в искуственной нейронной сети. В сети он имеет дело только с сигналами, которые он периодически получает, и сигналами, которые он периодически посылает другим нейронам. Несмотря на простоту устройства искуственные нейроны будучи соединёнными в достаточно большую сеть с управляемым взаимодействием способны решать сложные задачи, многие из которых, до использования ИНС решать не удавалось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>     \n",
    "    <img src=\"./img01/ann_1.png\" alt=\"Принципиальная схема устройства нейрона в живых организмах\" style=\"width: 500px;\"/>\n",
    "    <strong>Принципиальная схема устройства нейрона в живых организмах</strong>\n",
    "</center>\n",
    "\n",
    "* __Модели нейронов, используемые в современных ИНС, нацеленных на решение задач машинного обучения, в большинстве аспектов очень сильно отличаются от нейронов и их принципов работы в живых организмах!__ \n",
    "* Существет совершенно отдельное направление исследований, нацеленное на моделирование работы нейронов в живых организмах, далее мы об этом направлении говорить не будем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Очень краткая история области исследований__\n",
    "\n",
    "* 1943 - Уоренн Маккалок и Уолтер Питтс формализуют __понятие нейронной сети__.\n",
    "* 1949 - Дональд Хебб предлагает первый алгоритм, который может использоваться для __обучения искуственных нейронных сетей__.\n",
    "\n",
    "<center>     \n",
    "    <img src=\"./img01/ml_1.png\" alt=\"Машинное обучение: альтернативная парадигма программирования\" style=\"width: 400px;\"/>\n",
    "    <strong>Машинное обучение: альтернативная парадигма программирования</strong>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1958 - Фрэнк Розенблатт изобретает __однослойный перцептрон__ и демонстрирует его способность __решать задачи классификации__. \n",
    "* 1960 год - Бернард Уидроу c Тедом Хоффом разработали __Адалин__ (ADALINE - Adaptive Linear Neuron, позже расшифровывался как Adaptive Linear Element), новый тип одноуровневой ИНС, отличавшийся от перспторна способом обучения. Адалин был построен на базе принципиально новых физических вычислительных элементов - мемисторах (разработан Уидроу и Хоффом). Сейчас Адалин (адаптивный сумматор) является стандартным элементом многих систем обработки сигналов.\n",
    "\n",
    "\n",
    "<center>     \n",
    "    <img src=\"./img01/ann_2.png\" alt=\"Схема работы Перцептрона\" style=\"width: 500px;\"/>\n",
    "    <strong>Схема работы Перцептрона</strong>\n",
    "</center>\n",
    "\n",
    "Основной инновацией Розенблатта была разработка __алгоритма обучения перцептрона__:\n",
    "* изначально веса инициализируются случайным образом\n",
    "* поочередно берется один обучающий пример, включающий набор входов $x_i$ и верное значение $y$\n",
    "* для ошибочных предсказаний $\\hat{y}$:\n",
    "    * веса увеличиваюстя, если $\\hat{y}=0$, а $y=1$\n",
    "    * веса уменьшаются, если $\\hat{y}=1$, а $y=0$\n",
    "* процедура повторяется до исчезновения ошибок\n",
    "\n",
    "Для решения более сложных задач из перцептронов создается нейронная сеть:\n",
    "* для получения нескольких результатов __нейроны организуются в слой__ (layer) содержащий столькок перцептронов, сколько требуется выходов\n",
    "* выходы одного слоя могут использоваться в качестве входнов следующего слоя - многослойные нейронные сети\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/ann_4.png\" alt=\"Слой нейронной сети\" style=\"width: 300px;\"/>\n",
    "    <strong>Слой нейронной сети</strong>    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Перцептрон и проблема линейно неразделимых множеств__\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/ann_5.png\" alt=\"Пример линейно разделимых множества объектов\" style=\"width: 300px;\"/>\n",
    "    <strong>Пример линейно разделимых множеств объектов</strong>        \n",
    "</center>\n",
    "\n",
    "Общий вид перцептрона:\n",
    "$$\\hat{y} = f(w_0 + w_1 x_1 + \\ldots + w_n x_n) = f (\\pmb{w}^T \\pmb{x})$$, \n",
    "где $\\pmb{x}=(1, x_1, \\ldots, x_n)$\n",
    "\n",
    "В качестве фунции активации $f$ могут использоваться функции:\n",
    "* Сигмоид (логистическая функция): $\\sigma(z)=\\frac{e^z}{1+e^z}$\n",
    "* Гиперболический тангенс: $tanh(z)=\\frac{e^z-e^{-z}}{e^z+e^{-z}}$\n",
    "* Единичная ступенчатая функция (функция Хевисайда): $step(z) = \\begin{cases} \\ \\ 1 \\text{ , if } x > 0 \\\\ \\ \\ 0 \\text{ , if } x \\le 0 \\end{cases}$\n",
    "* Rectified linear unit (вентиль): $ReLU(z)=\\begin{cases} z \\text{ , if } z > 0 \\\\ 0 \\text{ , if } otherwise \\\\ \\end{cases}$\n",
    "* $sign(z) = \\begin{cases} \\ \\ 1 \\text{ , if } x > 0 \\\\ \\ \\ 0 \\text{ , if } x = 0 \\\\ -1 \\text{ , if }  x < 0 \\end{cases}$\n",
    "\n",
    "Большая коллекция функций активации: https://en.wikipedia.org/wiki/Activation_function\n",
    "\n",
    "Требования к функциям активации:\n",
    "* функция должна быть монотонной (обычно монотонно не убывающая)\n",
    "* иметь первую производную почти всюду (необходимо для обратного распространения ошибки при обучении нейронной сети)\n",
    "\n",
    "<center>\n",
    "    <img src=\"./img01/ann_6.png\" alt=\"Графиики функций активации\" style=\"width: 600px;\"/>\n",
    "    <strong>Графиики функций активации</strong>            \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <img src=\"./img01/ann_7.png\" alt=\"Пример линейно разделимых множества объектов\" style=\"width: 600px;\"/>\n",
    "    <strong>Пример поиска границы разделяющей два класса с помощью перцептрона с $f=\\sigma$</strong>                \n",
    "</center>\n",
    "\n",
    "Один перцептрон (с любой функцией активации) может научиться классифицировать только линейно раздлемые множества объектов.\n",
    "\n",
    "Предположим мы имеем два признака (features) на входе перцептрона: $𝑥_1 \\text{, } 𝑥_2 \\in \\{0, 1\\}$, т.е. имеем четрые точки:\n",
    "<table>\n",
    "<colgroup>\n",
    "<col width=\"33%\">\n",
    "<col width=\"33%\">\n",
    "<col width=\"34%\">\n",
    "</colgroup>\n",
    "<thead valign=\"bottom\">\n",
    "<tr class=\"row-odd\"><th class=\"head\">$x_1$</th>\n",
    "<th class=\"head\">$x_2$</th>\n",
    "<th class=\"head\">$y$</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody valign=\"top\">\n",
    "<tr class=\"row-even\"><td>0</td>\n",
    "<td>0</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>1</td>\n",
    "<td>1</td>\n",
    "<td>...</td>\n",
    "</tr>    \n",
    "<tbody valign=\"top\">\n",
    "<tr class=\"row-even\"><td>0</td>\n",
    "<td>1</td>\n",
    "<td>...</td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td>1</td>\n",
    "<td>0</td>\n",
    "<td>...</td>\n",
    "</tr>     \n",
    "</tbody>    \n",
    "</table>    \n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/ann_8.png\" alt=\"Пример классификации перцептроном логических функций\" style=\"width: 600px;\"/>\n",
    "    <strong>Пример классификации перцептроном логических функций</strong>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* 1969 год - Марвин Мински публикует формальное __доказательство ограниченности перцептрона__ и показывает, что он неспособен решать некоторые задачи (проблема «чётности» и «один в блоке»), связанные с инвариантностью представлений. В частности, __один перцептрон не может реализовать функцию XOR__ (исключающее или).\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/ann_9.png\" alt=\"Проблема классификации перцептроном логическоц функции XOR\" style=\"width: 250px;\"/>\n",
    "    <strong>Проблема классификации перцептроном логической функции XOR</strong>    \n",
    "</center>\n",
    "\n",
    "Сам М. Мински показал, что __XOR может быть реализован многослойной нейронной сетью из перцептронов__. Нелинейная функция активации является кртичиески важным элментом перцептрона, без нее линейная комбинация перцептронов позволяла бы строить только линейные разделяющие поверхности. \n",
    " \n",
    "<center> \n",
    "    <img src=\"./img01/ann_10.png\" alt=\"Классификации логическоц функции XOR многослойным перцептроном\" style=\"width: 600px;\"/>\n",
    "    <strong>Классификации логическоц функции XOR многослойным перцептроном</strong>        \n",
    "</center>\n",
    "\n",
    "\n",
    "Несмотря на возможность работы многослойных перцптронов о __механизм обучения, предложенный Розенблаттом, не позволяет обучить необходимую многослойную сеть__. После данных результатов интерес к нейронным сетям резко спадает, наступает период, позже называнный __\"Первой зимой искуственного интеллекта\"__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Современные методы обучения нейронной сети и обратное распространение ошибки\n",
    "\n",
    "__Обратное распространение ошибки (backpropagation)__ - алгоритм, позволяющий производить обучение многослойных нейронных сетей. \n",
    "\n",
    "* 1974 - Пол Дж. Вербос __изобретает алгоритм обратного распространения ошибки__ для обучения многослойных перцептронов. Изобретение не привлекло особого внимания.\n",
    "* 1982 - после периода забвения, интерес к нейросетям вновь возрастает (__\"весна искуственного интеллекта\"__). Дж. Хопфилд показал, что нейронная сеть с обратными связями может представлять собой систему, минимизирующую энергию (так называемая сеть Хопфилда). Кохоненом представлены модели сети, обучающейся без учителя (нейронная сеть Кохонена), решающей задачи кластеризации, визуализации данных (самоорганизующаяся карта Кохонена) и другие задачи предварительного анализа данных.\n",
    "* 1986 - Дэвидом И. Румельхартом, Дж. Е. Хинтоном и Рональдом Дж. Вильямсом переоткрыт и существенно развит __метод обратного распространения ошибки__. Начался взрыв интереса к обучаемым нейронным сетям.\n",
    "\n",
    "Использованием алгоритма обратного распространение ошибки позволяет:\n",
    "* __реализовывать__ функцию XOR и другие более __сложные функции__ с помощью многослойных нейронных сетей\n",
    "* эффективно обрабатывать __большое количество обучающих примеров__\n",
    "* обучать __сложные архитектуры нейронных сетей__\n",
    "Данный алгоритм до сих пор является одним из ключевых решений в технологиях искуственный нейронных сетей./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Приниципиальная логика обучения нейронной сети__\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/ann_11.png\" alt=\"Пример многослойного перцептрона \" style=\"width: 500px;\"/>\n",
    "    <strong>Пример многослойного перцептрона (с двумя скрытыми слоями)</strong>\n",
    "</center>\n",
    "\n",
    "* У нас есть набор данных $D$, состоящий из пар $(\\pmb{x}, \\pmb{y})$, где $\\pmb{x}$ - признаки, а $\\pmb{y}$ - правильный ответ. \n",
    "* Модель сети $f_L$, имеющей $L$ слоев с весами $\\pmb{\\theta}$ (совокупность весов нейронов из всех слоев) на этих данных делает некоторые предсказания $\\hat{\\pmb{y}} = f_L(\\pmb{x}, \\pmb{\\theta})$\n",
    "* Задана функция ошибки $E$, которую можно подсчитать на каждом примере: $E(f_L(\\pmb{x}, \\pmb{\\theta}), \\pmb{y})$ (например, это может быть квадрат или модуль отклонения $\\hat{\\pmb{y}}$ от $\\pmb{y}$ в случае регрессии или перекрестная энтропия в случае классификации)\n",
    "* Тогда суммарная ошибка на наборе данных $D$ будет функцией от параметров модели: $E(\\pmb{\\theta})$ и определяется как $E(\\pmb{\\theta})=\\sum_{(\\pmb{x}, \\pmb{y}) \\in D} E(f_L(\\pmb{x}, \\pmb{\\theta}), \\pmb{y})$\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/main_cycle_p1_v1.png\" alt=\"Приниципиальная логика обучения нейронной сети\" style=\"width: 600px;\"/>\n",
    "    <strong>Приниципиальная логика обучения нейронной сети</strong>    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Проблема обучения модели нейронной сети__\n",
    "\n",
    "* <em class=\"nt\"></em> __основная проблема__ это не применение модели к входным данным $\\pmb{x}$ и оцнка ошибки на правильных ответах $\\pmb{y}$, а __обучение модели__ (опредление наилучших параметров модели $\\pmb{\\theta}$). \n",
    "     * В случае нейронной сети обучение сводится к поиску весов слоев сети $\\pmb{\\theta}=(\\pmb{w}_1, \\ldots, \\pmb{w}_L)$, которые в совокупности являются параметрами модели $\\pmb{\\theta}$.\n",
    "\n",
    "* Формально: цель обучения - найти оптимальное значение параметров $\\theta^{*}$, минимизирующих ошибку на обучающией выборке $D$: \n",
    "$$\\theta^{*} = \\arg \\underset{\\pmb{\\theta}}{\\min} \\ E(\\pmb{\\theta}) = \\arg \\underset{\\pmb{\\theta}}{\\min} \\ \\sum_{(\\pmb{x}, \\pmb{y}) \\in D} E(f_L(\\pmb{x}, \\pmb{\\theta}), \\pmb{y})$$\n",
    "* Т.е. задача обучения сводится к задаче оптимизации.\n",
    "    * <em class=\"nt\"></em> На самом деле __все сложнее__: хороший результат на $D$ может плохо обобщаться (модель может давать низкое качество на другой выборке из той же генеральной совокупности) - __проблема переобучения__.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задача оптимизации__\n",
    "\n",
    "* Задача: корректировка весов сети (параметров модели $\\pmb{\\theta}$) на основе информации об ошибке на обучающих примерах $E(\\hat{\\pmb{y}}, \\pmb{y})$.\n",
    "    * Решение: использовать методы оптимизации, основанные на __методе градиентного спуска__.\n",
    "    \n",
    "\n",
    "* __Метод градиентныого спуска__ - метод нахождения локального экстремума (минимума или максимума) функции с помощью движения вдоль градиента. В нашем случае шаг метода градиентного спуска выглядит следующим образом:\n",
    "$$\\pmb{\\theta}_t = \\pmb{\\theta}_{t-1}-\\gamma\\nabla_\\theta E(\\pmb{\\theta}_{t-1}) = \\pmb{\\theta}_{t-1}-\\gamma \\sum_{(\\pmb{x}, \\pmb{y}) \\in D} \\nabla_\\theta E(f_L(\\pmb{x}, \\pmb{\\theta}), \\pmb{y})$$\n",
    "\n",
    "* <em class=\"nt\"></em> Выполнение на каждом шаге градиентого спуска суммирование по всем $(\\pmb{x}, \\pmb{y}) \\in D$ __обычно слшиком неэффективно__\n",
    "\n",
    "\n",
    "* Для выпуклых функций __задача локальной оптимизации__ - найти локальный минимум (максимум) автоматически превращается в __задачу глобальной оптимизации__ - найти точку, в которой достигается наименьшее (наибольшее) значение функции, то есть самую низкую (высокую) точку среди всех.\n",
    "* Оптимизировать веса одного перцептрона - выпуклая задача, но __для большой нейронной сети  целевая функция не является выпуклой__.\n",
    "\n",
    "<center> \n",
    "<img src=\"./img01/ann_15.png\" alt=\"Прямой проход и оценка ошибки\" style=\"width: 500px;\"/><br/>\n",
    "    <b>Пример работы градиентного спуска для функции двух переменных</b>    \n",
    "</center>\n",
    "\n",
    "* У нейронных сетей функция ошибки может задавать __очень сложный ландшафт__ с огромным числом локальных максимумов и минимумов. Это свойство необходимо для обеспечения выразительности нейронных сетей, позволяющей им решать так много разных задач.\n",
    "\n",
    "\n",
    "* <em class=\"nt\"></em> для использования методов, основанных на методе градиентного спуска __необходимо знать градиент функции потерь по параметрам модели__: $\\nabla_\\theta E(f_L(\\pmb{x}, \\pmb{\\theta}), \\pmb{y})$. Этот градиент определяет вектор (\"направление\") изменения параметров.\n",
    "\n",
    "\n",
    "Прямой проход (forward pass): входящая информация (вектор $\\pmb{x}$) распространяется через сеть с учетом весов связей, расчитывается выходной вектор $\\hat{\\pmb{y}}$\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/ann_12.png\" alt=\"Пример прямого прохода\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример прямого прохода</strong>    \n",
    "</center>\n",
    "\n",
    "\n",
    "Обратное распространение ошибки (backpropagation):\n",
    "* расчитывается ошибка между выходным вектором сети $\\hat{\\pmb{y}}$ и правильным ответом обучающего примера $\\pmb{y}$\n",
    "* ошибка распростаняется от результата к источнику (в обратную сторону) для корректировки весов\n",
    "\n",
    "<center>\n",
    "    <img src=\"./img01/ann_13.png\" alt=\"Пример прямого прохода\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример обратного распространения ошибки</strong>    \n",
    "</center>\n",
    "\n",
    "В результате мы рассчитываем градиент функции потерь по параметрам модели: $\\nabla_\\theta E(f_L(\\pmb{x}, \\pmb{\\theta}), \\pmb{y})$ и с его помощью проводим обучаение (оптимизацию) весов сети $\\pmb{\\theta}$ на основе полученных ошибок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Метод обратного распространения ошибки__ позволяет обучать многослойные сети, что позволяет решать сложные задачи.\n",
    "<center>   \n",
    "    <img src=\"./img01/db_1.png\" alt=\"Пример\" style=\"width: 750px;\"/>\n",
    "    <img src=\"./img01/db_2.png\" alt=\"Пример\" style=\"width: 550px;\"/>\n",
    "    <img src=\"./img01/db_3.png\" alt=\"Пример\" style=\"width: 550px;\"/>\n",
    "    <img src=\"./img01/db_4.png\" alt=\"Пример\" style=\"width: 700px;\"/>\n",
    "    <strong>Пример: решение задачи двухклассовой классификации сетями с разными праметрами слоев</strong>        \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Вторая весна ИИ и глубокое обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "__Вторая зима ИИ__\n",
    "\n",
    "* До 1998 были предложены некоторые  очень эффективные методы в облести ИНС:\n",
    "    * Обратное распространение ошибки (backpropagation)\n",
    "    * Recurrent Long-Short Term Memory Networks (LSTM)\n",
    "    * Распрознавание символов с помощью Convolutional Neural Networks (CNN)\n",
    "\n",
    "* Однако, в это время стали очень популярны некоторые альтернативные мотоды машинного обучения (в частности, SVM и т.д.) \n",
    "    * они обеспечивали аналогичное качество на тех же задачха\n",
    "    * не удавалось строить ИНС глубже нескольких слоев\n",
    "    * Kernel Machines использовали намного меньше эвристики и имели отличные математические доказательства обобщающией способности \n",
    "* В результате сообщество специалистов из области AI снова отвернулось от ИНС.\n",
    "\n",
    "Neural Network and Deep Learning problems:\n",
    "* Lack of processing power\n",
    "    * No GPUs at the time\n",
    "* Lack of data\n",
    "    * No big, annotated datasets at the time\n",
    "* Overfitting\n",
    "    * Because of the above, models could not generalize all that well\n",
    "* Vanishing gradient\n",
    "    * While learning with NN, you need to multiply several numbers 𝑎1 ∙ 𝑎2 ∙ ⋯ ∙ 𝑎𝑛.\n",
    "    * If all are equal to 0.1, for 𝑛 = 10 the result is 0.0000000001, too small for any learning\n",
    "* Experimentally, training multi-layer perceptrons was not that useful\n",
    "    * Accuracy didn’t improve with more layers\n",
    "* The inevitable question\n",
    "    * Are 1-2 hidden layers the best neural networks can do?\n",
    "    * Or is it that the learning algorithm is not really mature yet\n",
    "    \n",
    "... Deep Learning arrives    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 1990е и 2000е годы альтернативные методы поверхностного обучения в большинстве задач превосходили методы, основанные на нейронных сетях.\n",
    "\n",
    "Альтернативы нейронным сетям:\n",
    "* __Ядерные методы__ — это группа алгоритмов классификации, из которых наибольшую известность получил __метод опорных векторов__ (Support Vector Machine, SVM).\n",
    "* __Деревья решений__ и __случайные леса__ \n",
    "* __Градиентный бустинг__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Метод опорных векторов__\n",
    "\n",
    "Метод опорных векторов предназначен для решения задач классификации путем поиска хороших решающих границ, разделяющих два набора точек, принадлежащих разным категориям. Поиск таких границ в методе осуществляется в два этапа:\n",
    "\n",
    "1. Данные отображаются в новое пространство более высокой размерности, где граница может быть представлена как гиперплоскость.\n",
    "2. Хорошая решающая граница (разделяющая гиперплоскость) вычисляется путем максимизации расстояния от гиперплоскости до ближайших точек каждого класса, этот этап называют максимизацией зазора. Это позволяет обобщить классификацию новых образцов, не принадлежащих обучающему набору данных.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/alt_met1.png\" alt=\"Принципиальная схема работы SVM\" style=\"width: 500px;\"/>\n",
    "    <strong>Принципиальная схема работы SVM</strong>     \n",
    "</center>\n",
    "\n",
    "На момент разработки метод опорных векторов:\n",
    "* демонстрировал лучшую производительность на простых задачах классификации\n",
    "* был одним из немногих методов машинного обучения, обладающих обширной теоретической базой и поддающихся серьезному математическому анализу\n",
    "* был хорошо понятным и легко интерпретируемым\n",
    "\n",
    "Но:\n",
    "* метод оказался трудно применимым к большим наборам данных\n",
    "* не дал хороших результатов для таких задач, как классификация изображений\n",
    "\n",
    "Так как SVM является поверхностным методом, для его применения к задачам распознавания требуется сначала вручную выделить представительную выборку (этот шаг называется конструированием признаков), что сопряжено со сложностями и чревато ошибками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Деревья решений__\n",
    "\n",
    "Деревья решений — это иерархические структуры, которые позволяют классифицировать входные данные или предсказывать выходные значения по заданным исходным значениям. Они легко визуализируются и интерпретируются. \n",
    "\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/alt_met2_.png\" alt=\"Принципиальная схема работы дерева решений\" style=\"width: 500px;\"/>\n",
    "    <strong>Принципиальная схема работы дерева решений</strong>     \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм \"случайный лес\" (Random Forest) предложил надежный и практичный подход к обучению на основе деревьев решений, включающий в себя создание большого количества специализированных деревьев решений с последующим объединение выдаваемых ими результатов.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/alt_met3.png\" alt=\"Принципиальная схема работы алгоритма &quot;случайного леса&quot;\" style=\"width: 500px;\"/>\n",
    "    <strong>Принципиальная схема работы алгоритма \"случайного леса\"</strong>     \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод __градиентного бустинга__, во многом напоминает случайный лес, он основан на объединении слабых моделей прогнозирования, обычно — деревьев решений. Он использует градиентный бустинг, способ улучшения любой модели машинного обучения путем итеративного обучения новых моделей, специализированных для устранения слабых мест в предыдущих моделях. \n",
    "\n",
    "Применительно к деревьям решений градиентный бустинг позволяет получить модели, которые в большинстве случаев \n",
    "превосходят случайные леса при сохранении аналогичных свойств.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/alt_met4.png\" alt=\"Принципиальная схема работы алгоритма градиентного бустинга\" style=\"width: 500px;\"/>\n",
    "    <strong>Принципиальная схема работы алгоритма градиентного бустинга</strong>     \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* К 2010 году __практически потерян интерес к искуственным нейронным сетям__ со стороны научного сообщества, работают небольшие группы энтузиастов (__2я зима искусственного интеллекта__)\n",
    "* Начиная с 2010 года появляются важные успехи в области применения искуственных нейронных стеей, связанные со следующими научными группами:\n",
    "    * Джеффри Хинтон (Geoffrey Hinton) из университета в Торонто\n",
    "    * Йошуа Бенгио (Yoshua Bengio) из университета в Монреале\n",
    "    * Ян Лекун (Yann LeCun) из университета в Нью-Йорке\n",
    "    * исследователи из научно-исследовательском институте искусственного интеллекта IDSIA в Швейцарии\n",
    "* В 2011 году Ден Киресан (Dan Ciresan) из IDSIA выиграл конкурс по классификации изображений с применением глубоких нейронных сетей, обучаемых на GPU: первый практический успех современного глубокого обучения\n",
    "* __Соревнование ImageNet__ - крупномасштабное распознавание образов. Классификации цветных изображений с высоким разрешением на 1000 разных категорий после обучения по выборке, включающей в себя 1,4 миллиона изображений. Для начала 2010х годов - очень сложная задача машинного обучения. В 2011 году модель-победитель, основанная на классических подходах к распознаванию образов, показала __точность лишь 74,3%__ .\n",
    "* В 2012 году команда Алекса Крижевски (Alex Krizhevsky), советником в которой был Джеффри Хинтон (Geoffrey Hinton), достигла __точности в 83,6%__ — значительный прорыв методов глубокого обучения.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_1_.png\" alt=\"Уровень ошибки в соревновании ImageNet по годам\" style=\"width: 900px;\"/>\n",
    "    <strong>Уровень ошибки в соревновании ImageNet по годам</strong>     \n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <img src=\"./img01/ann_21.png\" alt=\"Пример\" style=\"width: 700px;\"/>\n",
    "    <strong>Вторая весна ИИ</strong>        \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой ступени развития достигло глубокое обучение:\n",
    "\n",
    "* классификация изображений на уровне человека;\n",
    "* распознавание речи на уровне человека;\n",
    "* распознавание рукописного текста на уровне человека;\n",
    "* улучшение качества машинного перевода с одного языка на другой;\n",
    "* улучшение качества машинного чтения текста вслух;\n",
    "* появление цифровых помощников, таких как Google Now и Amazon Alexa;\n",
    "* управление автомобилем на уровне человека;\n",
    "* повышение точности целевой рекламы, используемой компаниями Google, Baidu и Bing;\n",
    "* повышение релевантности поиска в интернете;\n",
    "* появление возможности отвечать на вопросы, заданные вслух;\n",
    "* игра в Го сильнее человека.\n",
    "\n",
    "Но, скорее всего, еще долгое время будут оставаться недостижимым решение таких задач, как:\n",
    "* перевод между произвольными языками на уровне человека;\n",
    "* понимание естественного языка на уровне человека\n",
    "\n",
    "Не стоит всерьез воспринимать разговоры об интеллекте на уровне человека"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Глубокое обучение__ — это особый раздел машинного обучения: новый подход к поиску представления данных, делающий упор на изучение последовательных слоев (или уровней) все более значимых представлений. \n",
    "\n",
    "* Под __глубиной__ в глубоком обучении не подразумевается __многослойное представление данных__. \n",
    "    * __Количество слоев__, на которые делится модель данных, называют __глубиной модели__.\n",
    "    * Другими подходящими названиями для этой области машинного обучения могли бы служить: многослойное обучение и иерархическое обучение.\n",
    "    * Под глубиной в глубоком обучении не подразумевается более глубокое понимание, достигаемое этим подходом.\n",
    "\n",
    "* Современное глубокое обучение часто вовлекает в процесс __десятки и даже сотни последовательных слоев__ представления.\n",
    "    * Все они __автоматически определяются под воздействием обучающих данных__. \n",
    "    * Другие подходы к машинному обучению __ориентированы на изучении одного-двух слоев представления данных__, по этой причине их иногда называют __поверхностным обучением__.\n",
    "    \n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_2.png\" alt=\"Увеличение глубины нейронных сетей\" style=\"width: 500px;\"/>\n",
    "    <strong>Увеличение глубины нейронных сетей</strong>     \n",
    "</center>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличительные черты глубокого обучения\n",
    "\n",
    "Основные причины быстрого взлета глубокого обучения:\n",
    "* лучшая производительность во многих задачах\n",
    "* упрощение решения проблем, за счет полной автоматизации важнейшего шаг в машинном обучении: конструирования признаков (раньше он выполнялся вручную)\n",
    "    * Методы поверхностного обучения — включали в себя преобразование входных данных только в одно или два последовательных пространства, обычно посредством простых преобразований.\n",
    "    * Однако точные представления, необходимые для решения сложных задач, обычно нельзя получить такими способами. Приходилось прилагать большие усилия, чтобы привести исходные данные к виду, более пригодному для обработки этими методами: приходилось __вручную улучшать слой представления своих данных__. Это называется __конструированием признаков__.\n",
    "    * Глубокое обучение, напротив, полностью автоматизирует этот шаг: с применением методов глубокого обучения все признаки извлекаются за один проход, без необходимости конструировать их вручную.\n",
    "* возможность эффективно использовать специализированное высокопроизводительное оборудование (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение задачи конструирования признаков\n",
    "\n",
    "* Методы поверхностного обучения используют преобразование входных данных только в одно или два последовательных пространства, обычно посредством простых преобразований.\n",
    "* Однако точные представления, необходимые для решения сложных задач, обычно нельзя получить такими способами. Приходилось __вручную улучшать слой представления своих данных__ - прилагать большие усилия, чтобы привести исходные данные к виду, более пригодному для обработки этими методами. Это называется __конструированием признаков__ (feature engineering).\n",
    "----\n",
    "* Глубокое обучение полностью автоматизирует процесс конструированием признаков: все признаки извлекаются за один проход, без необходимости конструировать их вручную.\n",
    "* Можно ли многократно применить методы поверхностного обучения для имитации эффекта глубокого обучения? \n",
    "    * Проблема: оптимальный слой первого представления в трехслойной модели не является оптимальным первым слоем в однослойной или двухслойной модели\n",
    "    * В глубоком обучении модель может __исследовать все слои представления вместе и одновременно__, а не последовательно (последовательное исследование также называют «жадным»). Когда модель корректирует один из своих внутренних признаков, все прочие признаки, зависящие от него, автоматически корректируются в соответствии с изменениями, без вмешательства человека. Все контролируется единственным сигналом обратной связи.\n",
    "* Методика глубокого обучения обладает двумя важными характеристиками: \n",
    "    * она поэтапно, послойно конструирует все более сложные представления \n",
    "    * совместно исследует промежуточные представления, благодаря чему каждый слой обновляется в соответствии с потребностями представления слоя выше и потребностями слоя ниже. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Почему глубокое обучение начало приносить плоды и активно использоваться только после 2010 г?__\n",
    "\n",
    "* Еще в 1989 году были известны две ключевые идеи глубокого обучения:\n",
    "    * алгоритм обратного распространения ошибки\n",
    "    * сверточные нейронные сети\n",
    "    * в 1997 г. был предложен алгоритм долгой краткосрочной памяти (Long Short-Term Memory, LSTM)\n",
    "    \n",
    "В целом, прогресс глубокого обучения объясняется тремя основными факторами:\n",
    "* __производительность оборудования__\n",
    "* __доступность наборов данных и тестов__\n",
    "* __алгоритмические достижения__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Производительность оборудования__\n",
    "\n",
    "* Между 1990 и 2010 годами быстродействие стандартных процессоров выросло примерно в 5000 раз (закон Мура).\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_3_2.png\" alt=\"Закон Мура\" style=\"width: 500px;\"/>\n",
    "    <strong>Закон Мура</strong>     \n",
    "</center> \n",
    "\n",
    "* Но: мощности соврменного ноутбука недостаточно, чтобы обучить типичные модели глубокого обучения, используемые для распознавания образов или речи, они требуют на порядки больше вычислительной мощности.\n",
    "* В течение 2000х такие компании, как NVIDIA и AMD, вложили миллионы долларов в разработку быстрых процессоров с массовым параллелизмом: __графических процессоров - Graphical Processing Unit (GPU)__ для поддержки графики все более реалистичных видеоигр\n",
    "* В 2007 году компания NVIDIA выпустила __CUDA__ (Compute Unified Device Architecture) - программный интерфейс для линейки своих GPU, позволяющий использовать их для вычислений общего назначения, а не только для специализированных задач компьютерной графики GPGPU (General-Purpose computing on Graphics Processing Units).\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_3.png\" alt=\"Различия в архитектурах CPU и GPU\" style=\"width: 500px;\"/>\n",
    "    <strong>Различия в архитектурах CPU и GPU</strong>     \n",
    "</center> \n",
    "\n",
    "* Теперь в различных задачах, допускающих возможность массового распараллеливания вычислений несколько GPU могут заменить мощные кластеры на обычных процессорах. Современный графический процессор NVIDIA TITAN X, (стоимостью ~ 1000 USD) имеет пиковую   роизводительность по выполнению операций с числами типа float32 __почти в 350 раз больше__ производительности современного ноутбука.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_3_3.png\" alt=\"Различия в производительности CPU и GPU\" style=\"width: 500px;\"/>\n",
    "    <strong>Различия в производительности CPU и GPU</strong>     \n",
    "</center> \n",
    "\n",
    "\n",
    "* __Глубокие нейронные сети допускают высокую степень распараллеливания__ т.к. выполняют в основном умножение множества маленьких матриц. \n",
    "* Ведется разработка __специализированных процессоров для решения задач глубокого обучения__, частного случая ASIC ( application-specific integrated circuit - «интегральная схема специального назначения»). Компания Google разработала и использует несколько поколений специализированных тензорных процессоров (Tensor Processing Unit, TPU), ориентированных на решение задач глубокого обучения: процессор с новой архитектурой, предназначенный для использования в глубоких нейронных сетях, который примерно в 10 раз  производительнее и энергоэффективнее чем топовые модели GPU.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_3_4.png\" alt=\"Google tensor processing unit (TPU)\" style=\"width: 500px;\"/>\n",
    "    <strong>Google tensor processing unit (TPU)</strong>     \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Доступность наборов данных и тестов__\n",
    "\n",
    "* Алгоритмы машинного обучения используют данные (в частности: обучающие наборы данных) для собственной настройки (обучения) и повышения качества работы. \n",
    "* Обучение решнию сложных задач требует очень больших объемов обучающих наборов данных.\n",
    "\n",
    "---\n",
    "Накоплению больших объемов обучающих выборок в последние десятилетия способствовали следующие факторы:\n",
    "* Экспоненциальный рост емкости устройств хранения информации, наблюдавшемуся в последние 20 лет (согласно закону Мура)\n",
    "* Бурный рост интернета, благодаря которому появилась возможность работать с очень большими объамами данных, в частности:\n",
    "    * собирать и накапливать данные\n",
    "    * распространять данные \n",
    "    * совместно обрабатывать (вручную и автоматически) данные \n",
    "\n",
    "Примеры публично доступных массивов данных:\n",
    "* База данных ImageNet — проект по созданию и сопровождению массивной базы данных аннотированных изображений, предназначенная для отработки и тестирования методов распознавания образов и машинного зрения. По состоянию на 2016 год в базу данных было записано около десяти миллионов URL с изображениями, которые прошли ручную аннотацию для ImageNet, в аннотациях перечислялись объекты, попавшие на изображение, и прямоугольники с их координатами.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_4.png\" alt=\"ImageNet\" style=\"width: 500px;\"/>\n",
    "    <strong>ImageNet</strong>     \n",
    "</center> \n",
    "\n",
    "* Википедия\n",
    "\n",
    "<center> \n",
    "<table>\n",
    "<tr>\n",
    "    <td><img src=\"./img01/deepnet_5.png\" alt=\"Динамика количества статей в Википедии\" style=\"width: 500px;\"/></td>\n",
    "    <td><img src=\"./img01/deepnet_6.png\" alt=\"Динамика количества статей в Википедии\" style=\"width: 200px;\"/></td>\n",
    "</tr>\n",
    "</table>\n",
    "    <strong>Динамика количества статей в Википедии (в разрезе языковых разделов)</strong>         \n",
    "</center>     \n",
    "    \n",
    "* Социальные сети    \n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_7.png\" alt=\"Динамика количества пользователей Facebook\" style=\"width: 500px;\"/>\n",
    "    <strong>Динамика количества пользователей Facebook</strong>     \n",
    "</center> \n",
    "\n",
    "* И много-много всего...\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_9.png\" alt=\"Каждую минту\" style=\"width: 500px;\"/>\n",
    "    <strong>Каждую минту...</strong>     \n",
    "</center> \n",
    "\n",
    "* Далее: интернет вещей (internet of things, IoT) — концепция вычислительной сети физических предметов (\"вещей\"), оснащённых встроенными технологиями для взаимодействия друг с другом или с внешней средой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Алгоритмические достижения в области глубокого обучения__\n",
    "\n",
    "Кроме оборудования и данных, до конца 2000-х нам не хватало надежного способа обучения очень глубоких нейронных сетей, как результат:\n",
    "* нейронные сети оставались очень неглубокими, имеющими один или два слоя представления; \n",
    "* <em class=\"hn\"></em> они не могли противостоять более совершенным поверхностным методам (методу опорных векторов и случайные леса). Основная __проблема__ заключалась в __распространении градиента через глубокие пакеты слоев__. Сигнал обратной связи, используемый для обучения нейронных сетей, __затухает по мере увеличения количества слоев__.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/ann_14.png\" alt=\"Приниципиальная логика обучения нейронной сети\" style=\"width: 370px;\"/>\n",
    "    <strong>Приниципиальная логика обучения нейронной сети</strong>     \n",
    "</center>\n",
    "\n",
    "В районе 2010 г. появились некоторые простые, но важных алгоритмические усовершенствования, позволившие улучшить распространение градиента:\n",
    "* __улчшенные подходы к регуляризации__\n",
    "* __улучшенные схемы инициализации весов__\n",
    "* __улучшенные функции активации__\n",
    "* __улучшенные схемы оптимизации__ (такие как RMSProp и Adam)\n",
    "\n",
    "В последнее время были открыты еще более совершенные способы распространения градиента, с применением которых появилась возможность обучать с нуля модели с тысячами слоев в глубину. В частонсти:\n",
    "* пакетная нормализация\n",
    "* обходные связи \n",
    "* отделимые свертки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Улчшенные подходы к регуляризации\n",
    "\n",
    "__Регуляризация в нейронных сетях__\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_10.png\" alt=\"Проблема переобучения модели\" style=\"width: 500px;\"/>\n",
    "    <strong>Проблема переобучения модели</strong>     \n",
    "</center>\n",
    "\n",
    "* модель, у которой слишком много свободных параметров, __плохо обобщается__: то есть слишком близко «облизывает» точки из тренировочного множества и в результате недостаточно хорошо предсказывает нужные значения в новых точках. \n",
    "* В современных нейронных сетях огромное число параметров (даже не самая сложная архитектура может содержать миллионы весов) <em class=\"hn\"></em> __надо регуляризовать параметры__!\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_11.png\" alt=\"Принцип регуляризации 1\" style=\"width: 500px;\"/>\n",
    "    <img src=\"./img01/deepnet_12.png\" alt=\"Принцип регуляризации 2\" style=\"width: 500px;\"/>\n",
    "    <strong>Принцип регуляризации параметров модели</strong>     \n",
    "</center>\n",
    "\n",
    "* Наиболее распросранненные регуляризаторы:\n",
    "    * $L_2$-регуляризатор: сумма квадратов весов $\\lambda \\sum_w w^2$\n",
    "    * $L_1$-регуляризатор: сумма модулей весов $\\lambda \\sum_w |w|$\n",
    "* В теории нейронных сетей такая регуляризация называется сокращением весов eight decay), потому что действительно приводит к уменьшению их абсолютных значений.\n",
    "\n",
    "* в Keras есть возможность для каждого слоя добавить регуляризатор на три вида связей:\n",
    "    * ```kernel_regularizer``` — на матрицу весов слоя;\n",
    "    * ```bias_regularizer``` — на вектор свободных членов;\n",
    "    * ```activity_regularizer``` — на вектор выходов.\n",
    "\n",
    "Пример:\n",
    "```python\n",
    "model.add(Dense(256, input_dim=32,\n",
    "kernel_regularizer=regularizers.l1(0.001),\n",
    "bias_regularizer=regularizers.l2(0.1),\n",
    "activity_regularizer=regularizers.l2(0.01)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Регуляризация с помощью ранней остановки__ (early stopping)\n",
    "\n",
    "* Отложим часть тренировочного набора (назовем отложенную часть __валидационным множеством__).\n",
    "* При обучении на тренировочном множестве будем  вычислять ошибку и на валидационном множестве\n",
    "* Можно предположить, что  __ошибка на валидационном множестве будет хорошо оценивать ошибку и на новых точках__ (тестовом множестве), ведь она взята из данных той же природы, но тех, на которых мы не обучались.\n",
    "* Остановить обучение нужно будет не тогда, когда сеть прийдет в локальный оптимум для тренировочного множества, а тогда, __когда начнет ухудшаться ошибка на валидационном множестве__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Регуляризации нейронных сетей с помощью дропаута__\n",
    "\n",
    "* __Регуляризация с помощью дропаута__ (dropout regularization) - один из важнейших методов регуляризации нейронных сетей обеспечивший революцию глубокого обучения\n",
    "\n",
    "Идея метода (очень простая!):\n",
    "* Для каждого нейрона (кроме самого последнего, выходного слоя) установим некоторую вероятность $p$, с которой он будет выброшен из сети.\n",
    "* Алгоритм обучения меняется таким образом: \n",
    "    * на каждом новом тренировочном примере $x$ мы сначала для каждого __разыгрываем вероятность $p$__ и в зависимости от результата либо используем нейрон как обычно, __либо устанавливаем его выход всегда строго равным нулю__ (вероятность этого события $1-p$). \n",
    "    * __Дальше все происходит без изменений__; ноль на выходе приводит к тому, что нейрон фактически выпадает из графа вычислений: и прямое вычисление, и обратное распространение градиента останавливаются на этом нейроне и дальше не идут.\n",
    "    * Для применения обученной сети __используются все нейроны__ в конфигурации, которая была до применения дропаута, но __выход каждого нейрона умножается на вероятность $p$__ (с которой нейрон оставляли при обучении).\n",
    "* Для очень широкого спектра архитектур и приложений замечательно подходит $p = 1/2$    \n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_13.png\" alt=\"Пример дропаута\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример дропаута</strong>     \n",
    "</center>    \n",
    "\n",
    "* Практика обучения нейронных сетей показывает, что дропаут действительно дает очень серьезные улучшения в качестве обученной модели\n",
    "* Дропаут — это метод добиться __усреднения огромного чмсла моделей__  (до $2^N$ возможных моделей, $N$ — число нейронов, которые подвергаются дропауту). Он эквивалентен усреднению всех моделей, которые получались на каждом шаге случайным выбрасыванием отдельных нейронов.\n",
    "\n",
    "Пример использования Dropout в Keras:\n",
    "```python\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "    # Dropout:\n",
    "\tmodel.add(Dropout(0.2, input_shape=(60,)))\n",
    "\tmodel.add(Dense(60, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "\tmodel.add(Dense(30, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tsgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\treturn model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Улучшенные схемы инициализации весов\n",
    "\n",
    "* Обучение сети — сложная задача оптимизации в пространстве очень высокой размерности, которая фактически решается методами локального поиска.\n",
    "* Для таких задач один из ключевых вопросов: __где начинать этот локальный поиск?__\n",
    "    \n",
    "<center> \n",
    "    <img src=\"./img01/ann_15.png\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример работы градиентного спуска для функции двух переменных</strong>     \n",
    "</center>    \n",
    "\n",
    "* Качество начального приближения приниципиально влияет на получаемые в результате локальные оптимумы.\n",
    "* Хорошая инициализация весов может позволить нам обучать глубокие сети:\n",
    "    * лучше (в смысле метрик качества)\n",
    "    * быстрее (в смысле числа требующихся обновлений весов, т.е. числа итераций, т.е. времени обучения)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая идея, которая привела к большим успехам в этом направлении: __предобучение без учителя__ (unsupervised pretraining):\n",
    "* отдельные слои глубокой сети последовательно обучаются без учителя\n",
    "* затем веса полученных слоев считаются начальным приближением и дообучаются уже на размеченном наборе данных\n",
    "\n",
    "* сначала основным инструментом для предобучения без учителя в стали так называемые __ограниченные машины Больцмана__\n",
    "* затем для этого стали использоваться __автокодировщики__\n",
    "\n",
    "Основные приниципы испльзующиеся при предобучении:\n",
    "1. Предобучение слоев происходит последовательно, от нижних к верхним. \n",
    "    * позволяет избежать проблемы затухающих градиентов\n",
    "    * существенно уменьшает объем вычислений на каждом этапе\n",
    "2. Предобучение протекает без учителя, то есть без учета имеющихся размеченных данных.\n",
    "    * это часто позволяет существенно расширить обучающую выборку (например, собрать миллионы изображений из интернета без описания наманого проще, чем собрать даже тысячу правильно размеченных изображений).\n",
    "3. В результате предобучения получается модель, которую затем нужно дообучить на размеченных данных. \n",
    "    * модели, обученные таким образом, в конечном счете стабильно сходятся к существенно лучшим решениям, чем при случайной инициализации.\n",
    "\n",
    "Но:\n",
    "* сейчас на практике предварительное послойное обучение проводится редко, т.к. был найдены более простой и хорошо мотивированный способ инициализации весов, позволяющий существенно ускорить обучение и улучшить качество, его часто называют инициализацией Ксавье (Xavier initialization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Инициализация Ксавье__\n",
    "\n",
    "Общий вид перцептрона:\n",
    "$$\\hat{y} = f(z) = f(w_0 + w_1 x_1 + \\ldots + w_n x_n) = f (\\mathbf{w}^T \\mathbf{x})$$, \n",
    "где $\\mathbf{x}=(1, x_1, \\ldots, x_n)$\n",
    "Т.е. $z=\\mathbf{w}^T \\mathbf{x}$\n",
    "\n",
    "Т.е. дисперсия $\\operatorname{Var}(z)$ не зависит от свободного члена $w_0$b и выражается через дисперсии $\\mathbf{x'}=(x_1, \\ldots, x_n)$ и $\\mathbf{w'}=(w_1, \\ldots, w_n)$. \n",
    "\n",
    "Для $z_i = w_i \\cdot x_i$, в предположении о том, что $w_i$ и $x_i$ независимы (что вполне естественно), мы получим дисперсию:\n",
    "$$\\operatorname{Var}(z_i)= \\operatorname{Var}(w_i \\cdot x_i) = \\mathbb{E} \\left [ x_i^2 w_i^2 \\right ] - \\left ( \\mathbb{E}  [ x_i w_i ] \\right ) ^2  = \\mathbb{E} \\left [ x_i^2 \\right ] \\mathbb{E} \\left [ w_i^2 \\right ] -  \\mathbb{E}  [ w_i ] ^2 \\mathbb{E}  [ w_i ] ^2 = \\left ( \\operatorname{Var}(x_i) + \\mathbb{E}  [ x_i ] ^2  \\right ) \\left ( \\operatorname{Var}(w_i) + \\mathbb{E}  [ w_i ] ^2 \\right ) -  \\mathbb{E}  [ x_i ] ^2 \\mathbb{E}  [ w_i ] ^2 = \\mathbb{E}  [ x_i ] ^2 \\operatorname{Var}(w_i) + \\mathbb{E}  [ w_i ] ^2 \\operatorname{Var}(x_i)  + \\operatorname{Var}(x_i) \\operatorname{Var}(w_i)$$\n",
    "\n",
    "Если мы используем симметричные функции активации и случайно инициализируем веса со средним значением, равным нулю, то первые два члена последнего выражения оказываются тоже равными нулю, а значит:\n",
    "\n",
    "$$\\operatorname{Var}(z_i) = \\operatorname{Var}(x_i) \\operatorname{Var}(w_i)$$\n",
    "\n",
    "Если теперь мы предполагаем, что как $x_i$, так и $w_i$ инициализируются из одного и того же распределения, причем независимо друг от друга (это сильное предположение, но в данном случае вполне естественное), мы получим:\n",
    "\n",
    "$$\\operatorname{Var}(z) = \\operatorname{Var} \\left ( \\sum_{i=1}^{n_{out}} z_i \\right ) = \\sum_{i=1}^{n_{out}} \\operatorname{Var}(x_i w_i) = n_{out} \\operatorname{Var}(x_i) \\operatorname{Var}(w_i)\\text{ ,}$$\n",
    "\n",
    "где $n_{out}$ — число нейронов последнего слоя. Другими словами, дисперсия выходов пропорциональна дисперсии входов с коэффициентом $n_{out} \\operatorname{Var}(w_i)$.\n",
    "\n",
    "Ранее стандартным эвристическим способом случайно инициализировать веса новой сети1 было равномерное распределение следующего вида:\n",
    "\n",
    "$$w_i \\sim U \\left [ -\\frac{1}{\\sqrt{n_{out}}}, \\frac{1}{\\sqrt{n_{out}}} \\right ]$$\n",
    "\n",
    "В этом случае получается, что:\n",
    "\n",
    "$$\\operatorname{Var}(w_i) = \\frac{1}{12} \\left ( \\frac{1}{\\sqrt{n_{out}}} + \\frac{1}{\\sqrt{n_{out}}} \\right ) ^2 = \\frac{1}{3 \\cdot n_{out}}\\text{ ,}$$\n",
    "тогда: $n_{out} \\operatorname{Var}(w_i)=\\frac{1}{3}$.\n",
    "\n",
    "* После нескольких слоев такое преобразование параметров распределения значений между слоями сети фактически __приводит к затуханию сигнала__: дисперсия результата слоя каждый раз уменьшается (фактически делится на 3), а среднее у него было нулевое.\n",
    "\n",
    "* Аналогичная ситуация повторяется и на шаге обратного распространения ошибки при обучении. \n",
    "\n",
    "* Если мы используем симметричную функцию активации с единичной производной в окрестности нуля (например, $\\tanh$), то теперь мы получим коэффициент пропорциональности для дисперсии $n_{in} \\operatorname{Var}(w_i)$, где $n_{in}$ - число нейронов во входном слое, а не на выходе.\n",
    "\n",
    "\n",
    "* Идея инициализации Ксавье заключается в том, что для беспрепятственного распространения значений активации и градиента по сети дисперсия в обоих случаях должна быть примерно равна единице.\n",
    "\n",
    "* Поскольку для неодинаковых размеров слоев невозможно удовлетворить оба условия одновременно, предлагается инициализировать веса очередного слоя сети симметричным распределением с такой дисперсией:\n",
    "$$ \\operatorname{Var}(w_i) = \\frac {2}{n_{in} + n_{out}}$$\n",
    "\n",
    "что для равномерной инициализации приводит к следующему распределению:\n",
    "\n",
    "$$w_i \\sim U \\left [ -\\frac{\\sqrt{6}}{\\sqrt{n_{in}+n_{out}}}, \\frac{\\sqrt{6}}{\\sqrt{n_{in}+n_{out}}} \\right ]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# загрузка исходных данных:\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# правильные ответы заданы в виде цифр, придется перекодировать их в виде векторов:\n",
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь осталось для удобства переведем матрицы X_train и X_test из целочисленных значений на отрезке [0, 255] к вещественным на [0, 1] (нормализовать), а также сделать из квадратных изображений размера 28 × 28 пикселов одномер-\n",
    "ные векторы длины 784; это значит, что сами тензоры X_train и X_test будут иметь\n",
    "размерность (число примеров) × 784:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape([-1, 28*28]) / 255.\n",
    "X_test = X_test.reshape([-1, 28*28]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init):\n",
    "    '''init - екстовый параметр, который интерпретируется как тип инициализации \n",
    "    (для нашего эксперимента это будут значения uniform и glorot_normal)\n",
    "    Функция возвращает функция простую полносвязную модель с четырьмя промежуточными слоями, каждый из 100 нейронов.'''\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(28*28,), init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(Dense(10, init=init, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_model = create_model(\"uniform\")\n",
    "uniform_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "uniform_model.fit(x_train, Y_train, \n",
    "                  batch_size=64, nb_epoch=30, verbose=1, validation_data=(x_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glorot_model = create_model(\"glorot_normal\")\n",
    "glorot_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "glorot_model.fit(x_train, Y_train, \n",
    "                 batch_size=64, nb_epoch=30, verbose=1, validation_data=(x_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <img src=\"./img01/deepnet_14.png\" alt=\"Сравнение инициализаций\" style=\"width: 500px;\"/>\n",
    "    <strong>Сравнение инициализация Ксавьев и случайной инциализации весов</strong>     \n",
    "</center>  \n",
    "\n",
    "* Видно, что при инициализации весов по методу Ксавье модель уже после первой эпохи находит решение с точностью около 90 %, на что модели, чьи веса инициализированы равномерным распределением, требуется около 10 эпох. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормализация по мини-батчам\n",
    "\n",
    "При обучении нейронных сетей один шаг градиентного спуска обычно делается не на одной точке входных данных, а на __мини-батче__, то есть на небольшой коллекции данных, которая обычно выбирается из всего обучающего множества случайно. С точки зрения оптимизации у такого подхода есть сразу несколько преимуществ.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/ann_15.png\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример работы градиентного спуска для функции двух переменных</strong>     \n",
    "</center>\n",
    "\n",
    "__Стохастический градиентный спуск__\n",
    "\n",
    "* Шаг метода градиентного спуска:\n",
    "$$\\mathbf{w}^{t+1} = \\mathbf{w}_{t}-\\gamma\\nabla_{\\mathbf{w}} E(\\mathbf{w}^{t-1}) = \\mathbf{w}_{t}-\\gamma \\sum_{(\\mathbf{x}, \\mathbf{y}) \\in D} \\nabla_\\theta E(f_L(\\mathbf{x}, \\mathbf{w}^{t-1}), \\mathbf{y})$$\n",
    "* Выполнение на каждом шаге градиентого спуска суммирования по всем $(\\mathbf{x}, \\mathbf{y}) \\in D$ происходит слишком долго\n",
    "* Создаем батчи - случайные наборы из фиксированного количества элементов выборки (например $M$ элементов) $D^M$, $D^M \\subset D$ ($|D|=N$):\n",
    "$$\\nabla_{\\mathbf{w}} E(\\mathbf{w}^{t-1}) \\approx \\frac{N}{M}\\sum_{(\\pmb{x}, \\pmb{y}) \\in D^M} \\nabla_\\theta E(f_L(\\mathbf{x}, \\mathbf{w}^{t-1}), \\mathbf{y})$$\n",
    "\n",
    "Это работает, т.к.:\n",
    "* Т.к. обычно поверхность:\n",
    "    * не является квадратичной функцией\n",
    "    * не выпуклая \n",
    "    * имеет очень высокую размерность \n",
    "* Обчно наборы данных слишком большие, чтобы вычислять градиенты полностью\n",
    "* Нет никаких гарантий, что:\n",
    "    * итоговое решение будет хорошим\n",
    "    * решение быстро сходится к итоговому решению\n",
    "    * или, что оно вообще сходится \n",
    "\n",
    "Положительные свойства использования стохастического градиента:\n",
    "* работает намного быстрее чем ГС\n",
    "* на практике точность результата выше чем у ГС\n",
    "* мини-батчи позволяют работать с наборами данных, которые меняются со временем\n",
    "* дисперсия градиента возрастает при убывании размера батча ($\\sim 1/\\sqrt{M}$)\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/ann_20.png\" alt=\"Пример\" style=\"width: 400px;\"/>\n",
    "    <strong>Пример успешной работы стохастического градиентного спуска</strong>     \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Усреднение градиента по нескольким примерам__ представляет собой апроксимацию градиента по всему тренировочному множеству, и чем больше примеров используется в одном мини-батче, тем точнее это приближение. \n",
    "    * Максимальная точность достигается на шаге сразу на всем тренировочном датасете, но это слишком затратно вычислительно. \n",
    "* Глубокие нейронные сети подразумевают большое количество последовательных действий с каждым примером. GPU (и многоядерные CPU) позволяет эту длинную последовательность __рассчитывать параллельно__ для большого количества примеров.\n",
    "\n",
    "__Проблема внутреннего сдвига переменных (internal covariance shift) при глубоком обучении:__. \n",
    "* Если на очередном шаге градиентного спуска меняются веса одного из первых (нижних) слоев\n",
    "* <em class=\"hn\"></em> измененяются распределения активаций выходов этого слоя\n",
    "* <em class=\"hn\"></em> всем последующим слоям надо адаптироваться к новому распределеннию входных данных \n",
    "\n",
    "Пример:\n",
    "\n",
    "Пусть иммеется нейрон первого слоя:\n",
    "$$y = \\tanh (w_0 + w_1 x_1 + w_2 x_2)$$\n",
    "и его веса меняютя со значений $\\mathbf{w} = (w_0, w_1, w_2) = (0, 1/2, 1/2)$ на и значения $\\mathbf{w} = (w_0, w_1, w_2) = (1/2, 9/10, 1/10)$.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_15.png\" alt=\"Пример\" style=\"width: 600px;\"/>\n",
    "    <strong>Пример успешной работы стохастического градиентного спуска</strong>     \n",
    "</center>\n",
    "\n",
    "* а — структура первого слоя сети и входные распределения\n",
    "* б — результат для двух разных векторов весов\n",
    "\n",
    "Ситуация с точки зрения нейронов следующего уровня:\n",
    "* сначала на вход получали одно распределение (серый график) и обучились на нем\n",
    "* потом, когда вектор весов сильно сместился и то, чему обучились нейроны второго уровня, стало почти бесполезным: входы теперь берутся из совершенно новой области, и обучаться надо фактически заново\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сопутствующая проблема: __\"насыщение\" функций активации__\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/ann_17.png\" alt=\"Пример\" style=\"width: 500px;\"/>\n",
    "    <strong>Производные популярных функций активации</strong>     \n",
    "</center>\n",
    "\n",
    "Часто в нейронных сетях используются сигмоидальные функции активации ($f(x) =\\sigma (x)$, $f(x) =\\tanh (x)$), одной из особенностей которых является __\"насыщение\" значений функций активации__:\n",
    "* когда входы получают большие по модулю значения производная $f'(x)$ быстро стремится к 0\n",
    "* отрциательное следствие: при близких к 0 производных обратное распространение ошибки очень сильно затухает на этих градиетнтах\n",
    "* потенциальное решение: замена функций активации на $ReLU$, но это не единственный и не всегда подходящий способ\n",
    "\n",
    "В частности, при внутреннем сдвиге переменных высока вероятность насыщения функций активации и возникновения существенных сложностей при обучении глубоких моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Проблема сдвига переменных не является специфической сугубо для глубоких нейронных сетей. \n",
    "* В классическом машинном обучении распространена аналогичная проблема:\n",
    "    * распределение данных в тестовой выборке существенно отличается от распределения данных в обучающей выборке\n",
    "    \n",
    "* Наиболее распространенный метод решения: __нормализация данных__\n",
    "* Для классических нейронных сетей эта процедура выглядела как «отбелевание» (whitened) входов сети:\n",
    "    * среднее значение входных данных приведится к нулю\n",
    "    * матрица ковариаций приводится к единичной матрице\n",
    "\n",
    "Нормализация входов часто помогает, и прежде чем обучать нейронную сеть, ее желательно делать. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация входов часто помогает, и прежде чем обучать нейронную сеть, ее желательно делать.\n",
    "\n",
    "__(гипотеза):__ нормировать входы очередного слоя внутри сети на каждом шаге обучения:\n",
    "* если не учитывать эту операцию при обучении это приведт к неадекватному изменению весов (например, констант)\n",
    "* <em class=\"hn\"></em> нужно учитывать нормализацию при градиентном спуске\n",
    "\n",
    "Прямолинейнвый подход:\n",
    "\n",
    "Введем слой нормализации:\n",
    "$\\hat{\\mathbf{x}}=Norm(\\mathbf{x}, \\mathcal{X})$\n",
    "\n",
    "где $\\mathbf{x}$ - текущий обучающий пример, а $\\mathcal{X}$ - все примеры из тренировочной выборки (!).\n",
    "* <em class=\"hn\"></em> для шага градиентного спуска нам необходимо вычислить якобианы для $\\dfrac{\\partial Norm}{\\partial \\mathbf{\\mathbf{x}}}$ и $\\dfrac{\\partial Norm}{\\partial \\mathbf{\\mathcal{X}}}$, причем рассчитывать второй якобиан точно прийдется!\n",
    "* для операции «отбеливания» (декорреляции) потребуется вычислить матрицу ковариаций:\n",
    "$$Cov[x] = \\mathbb{E}_{\\mathbf{x} \\in \\mathcal{X}} [\\mathbf{x}\\mathbf{x}^⊤] − \\mathbb{E}[x] \\mathbb{E}[x]^⊤$$\n",
    "затем обратить ее и вычислить из нее квадратный корень, а при градиентном спуске еще и производные такого преобразования.\n",
    "\n",
    "Полноценную декорреляцию для каждого слоя __сделать за разумное время невозможно__, особенно для больших датасетов, поэтому используются __упрощенные варианты__:\n",
    "\n",
    "Вместо декорреляции всех входов совместно, нормализуют каждый элемент входного вектора по отдельности:\n",
    "\n",
    "Представим $\\mathbf{x}=(x_1,\\ldots,x_d)$, тогда нормализация компоненты вектора выглядит так:\n",
    "$$\\hat{x}_k = \\frac{x_k-\\mathbb{E}[x_k]}{\\sqrt{Var(x_k)}}$$\n",
    "\n",
    "Среднее и дисперсию в формуле хотелось нужно вычислять по всему датасету $\\mathcal{X}$, но это совершенно невозможно вычислительно, поэтому применим очередное упрощение: будем рассичитывать эти виличины по текущему мини-батчу. Данный подход называется __нормализацией по мини-батчам__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недостатки нормализации по мини-батчам:\n",
    "\n",
    "* Если используется сигмоидная функция активации (например: $f(x) =\\sigma (x)$, $f(x) =\\tanh (x)$), то после нормализации ее аргумента нелинейность по сути пропадает\n",
    "    * т.к. подавляющее большинство нормализованных значений будут попадать в область, где сигмоид ведет себя очень похоже на линейную функцию, и функция активации фактически станет линейной\n",
    "    \n",
    "<center> \n",
    "    <img src=\"./img01/ann_6.png\" alt=\"Графиики функций активации\" style=\"width: 600px;\"/>\n",
    "    <strong>Графиики функций активации</strong>     \n",
    "</center>    \n",
    "\n",
    "Для исправления этого недостатка, слой нормализации должен иметь возможность \"настроиться\" как тождественная функция. Т.е. при некоторых комбинациях параметров он должен работать как $f(x)=x$.\n",
    "* для этого введем параметры $\\gamma_k$ и $\\beta_k$ для масштабирования и сдвига нормализованной aктивации по каждой компоненте:\n",
    "$$y_k=\\gamma_k \\hat{x}_k + beta_k= \\gamma_k \\frac{x_k-\\mathbb{E}[x_k]}{\\sqrt{Var(x_k)}}+ \\beta_k$$\n",
    "* параметры $\\gamma_k$ и $\\beta_k$ будут обучаться вместе со всеми  параметрами ИНС и позволяют восстановить выразительную способность сети в целом\n",
    "* в частности, при настройке значений $\\gamma_k=\\sqrt{Var(x_k)}$ и $\\beta_k=\\mathbb{E}[x_k]$ слой нормализации может обучиться реализовывать тождественную функцию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резюмируем описание работы слоя нормализации по мини-батчам:\n",
    "1. Слой получает на вход очередной мини-батч $B = \\{\\mathbf{x}_1, \\ldots ,\\mathbf{x}_m\\}$\n",
    "2. Вычисляются базовые статистики по мини-батчу: \n",
    "$$\\mu_B=\\frac{1}{m}\\sum_{i=1}^{m}\\mathbf{x}_i\\text{, }\\sigma_B^2=\\frac{1}{m}\\sum_{i=1}^{m}(\\mathbf{x}_i-\\mu_B)^2$$\n",
    "3. Нормализует выходы:\n",
    "$$\\hat{x}_k = \\gamma_k \\frac{x_k-\\mu_B}{\\sqrt{\\sigma_B^2+\\epsilon}}+ \\beta_k$$\n",
    "небольшая положительная константа $\\epsilon$ необходима для того, чтобы избежать деления на 0\n",
    "4. Рассчитывате результат:\n",
    "$$y_k=\\gamma_k \\hat{x}_k + \\beta_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_16.png\" alt=\"Пример\" style=\"width: 600px;\"/>\n",
    "    <strong>Пример нормализации до и после нелинейности</strong>         \n",
    "</center>\n",
    "* а — графы вычислений\n",
    "* б — соответствующие результаты сэмплирования\n",
    "\n",
    "На данный момент нет устоявшегося мнения по вопросу о том, лучше делать ее после очередного слоя или после линейной\n",
    "части слоя, до нелинейной функции активации. Различные варианты дают разный эффект, в частности:\n",
    "* область значений в варианте нормализации после сигмоидальной нелинейности будет шире\n",
    "* область значений в варианте нормализации после сигмоидальной нелинейности будет уже, т.к. $\\tanh$ или $\\sigma$ снова вернут нормализованные результаты на отрезок [−1,1] или [0,1] соответственно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Документация по слою нормализации в Keras:\n",
    "\n",
    "https://keras.io/layers/normalization/\n",
    "\n",
    "Пример использования слоев нормализации по батчам:\n",
    "\n",
    "https://www.programcreek.com/python/example/100588/keras.layers.normalization.BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Усовершенствованные методы градиентного супска\n",
    "\n",
    "* __Метод градиентныого спуска__ - метод нахождения локального экстремума (минимума или максимума) функции с помощью движения вдоль градиента. В нашем случае шаг метода градиентного спуска выглядит следующим образом:\n",
    "$$\\pmb{\\theta}_t = \\pmb{\\theta}_{t-1}-\\eta\\nabla_\\theta E(\\pmb{\\theta}_{t-1}) = \\pmb{\\theta}_{t-1}-\\eta \\sum_{(\\pmb{x}, \\pmb{y}) \\in D} \\nabla_\\theta E(f_L(\\pmb{x}, \\pmb{\\theta}), \\pmb{y})$$\n",
    "* (!) Выполнение на каждом шаге градиентого спуска суммирование по всем $(\\pmb{x}, \\pmb{y}) \\in D$ обычно слшиком неэффективно\n",
    "\n",
    "* Для выпуклых функций __задача локальной оптимизации__ - найти локальный минимум (максимум) автоматически превращается в __задачу глобальной оптимизации__ - найти точку, в которой достигается наименьшее (наибольшее) значение функции, то есть самую низкую (высокую) точку среди всех.\n",
    "* Оптимизировать веса одного перцептрона - выпуклая задача, но __для большой нейронной сети  целевая функция не является выпуклой__.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/ann_15.png\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример работы градиентного спуска для функции двух переменных</strong>     \n",
    "</center>\n",
    "\n",
    "У нейронных сетей функция ошибки может задавать очень сложный ландшафт с огромным числом локальных максимумов и минимумов. Это свойство необходимо для обеспечения выразительности нейронных сетей, позволяющей им решать так много разных задач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Градиентный спуск с изменяемой скоростью обучения__\n",
    "\n",
    "Параметр метода  градиентного спуска: скорость обучения $\\eta$ показывает, насколько сильно мы сдвигаем параметры\n",
    "в сторону градиента на очередном шаге.\n",
    "\n",
    "Скорость обучения — это чрезвычайно важный параметр. \n",
    "* Если она будет слишком большой: \n",
    "    * алгоритм станет \"прыгать\" по практически случайным точкам пространства и не попадет в минимум, потому что все время будет его \"перепрыгивать\"\n",
    "* Еесли она будет слишком маленькой: \n",
    "    * обучение станет гораздо медленнее\n",
    "    * алгоритм рискует успокоиться и сойтись в первом же локальном минимуме, который скорее всего не окажется самым лучшим.\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_18.png\" alt=\"шаг градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Последствия неверного выбора шага градиентного спуска</strong>     \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простейшая стратегия управления скоростью обучения:\n",
    "* сначала скорость обучения должна быть большой: это позволяет быстрее прийти в правильную область пространства поиска\n",
    "* затем корость обучения должна быть маленькой: это позволяет детально исследовать окрестности точки минимума и в итоге попасть в нее\n",
    "\n",
    "Реализация в виде линейного затухания:\n",
    "$$\\eta=\\eta_0 \\left ( 1- \\frac{t}{T}\\right )$$\n",
    "\n",
    "Реализация в виде экспоненциального затухания:\n",
    "$$\\eta=\\eta_0 e^{-\\frac{t}{T}}$$\n",
    "\n",
    "где $t$ — это время прошедшее с начала обучения время (число мини-батчей или число эпох обучения), а $T$ — параметр, определяющий, как быстро будет уменьшаться $\\eta$.\n",
    "\n",
    "* правильный подбор $\\eta_0$ и $T$ позволяет существенно улчшить градиентный спуск\n",
    "* как правильно подобрать $\\eta_0$ и $T$?\n",
    "Если правильно подобрать параметры $\\eta_0$ и $T$, такая стратегия будет почти наверняка работать лучше, чем градиентный спуск с постоянной скоростью, а если повезет, то и вообще работать будет хорошо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Адаптивные методы градиентного спуска__\n",
    "\n",
    "* Замедление обучения с фиксированными параметрами никак не учитывает характиристики оптимзируемой функции\n",
    "* __Адаптивные методы градиентного спуска__ меняют параметры ГС в зависимости от результатов взаимодействия с оптимизируемой функцией\n",
    "\n",
    "Пример:\n",
    "\n",
    "В местах, где поверхность функции больше наклонена в одном измерении, чем в другом, обычный стохастический градиентный спуск может вести себя некорректно. Например, если минимум находится в сильно вытянутом«овраге»:\n",
    "* шаг градиентного спуска будет направлен от одной близкой и крутой стенки этого оврага к другой\n",
    "* когда точка попадет на другую стенку, градиент станет направлен в противоположную сторону\n",
    "* т.е. в процессе оптимизации текущее решение будет \"прыгать\" между стенками оврага, но к общему минимуму будет продвигаться очень медленно\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_19.png\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример неэффективной работы не адаптивного градиентного спуска</strong>     \n",
    "</center>\n",
    "\n",
    "В этой ситуации можгут помочь адаптивные методы градиентного спуска:\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_17.png\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример работы градиентного спуска для функции двух переменных</strong>     \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Метод импульсов__\n",
    "\n",
    "Идея метода импульс (momentum): точка не просто подчиняется правилам градиентного спуска, а подчиняется законам механики, в первую очередь имеет инерцеию, т.е.:\n",
    "* у точки есть скорость\n",
    "* положение точки на следующем шаге определяется ее текущим положением и скоростью\n",
    "* ускорение (скорость изменения скорости) определяется величиной градиента\n",
    "* на каждом шаге пересчитывается как положение точки, так и ее скорость\n",
    "\n",
    "Т.е. у точки, которая спускается по поверхности, появляется импульс, она движется по\n",
    "инерции и стремится этот импульс сохранить (отсюда и название метода). \n",
    "\n",
    "Формальная запись метода импульсов:\n",
    "$$\\pmb{\\theta}_t = \\pmb{\\theta}_{t-1}-u_t$$\n",
    "$$u_t=\\gamma u_{t-1} + \\eta\\nabla_\\theta E(\\pmb{\\theta}_{t-1})$$\n",
    "\n",
    "здесь:\n",
    "* $u_t$ - скорость точки в момент времени $t$ \n",
    "* $\\gamma$ - параметр метода моментов:\n",
    "    * параметр определяет, какую часть прошлого градиента мы хотим сохранить на текущем шаге\n",
    "    * $\\gamma<1$    \n",
    "\n",
    "* Теперь, когда точка \"катится с горки\", и все больше ускоряется в том направлении, в котором были направлены сразу несколько предыдущих градиентов, но будет двигаться достаточно медленно в тех направлениях, где градиент все время меняется. \n",
    "* <em class=\"hn\"></em> Метод импульсов помогает ускорить градиентный спуск в нужном направлении и уменьшает его колебания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Метод Нестерова__\n",
    "\n",
    "Метод Нестерова улучшает метод импульсов. При расчетах на шаге $t$ для получения $\\pmb{\\theta}_t$ : \n",
    "* вместо расчета градиента значения функции ошибки в точке $\\pmb{\\theta}_{t-1}$ (как было в методе моментов)\n",
    "* метод Нестерова рассчитывает градиента значения функции ошибки в точке $\\pmb{\\theta}_{t-1}-\\gamma u_{t-1}$\n",
    "\n",
    "Т.е. вместо:\n",
    "$$\\pmb{\\theta}_t = \\pmb{\\theta}_{t-1}-u_t=\\pmb{\\theta}_{t-1}-\\gamma u_{t-1} - \\eta\\nabla_\\theta E(\\pmb{\\theta}_{t-1})$$\n",
    "рассматриваем:\n",
    "$$\\pmb{\\theta}_t = \\pmb{\\theta}_{t-1}-u_t=\\pmb{\\theta}_{t-1}-\\gamma u_{t-1} - \\eta\\nabla_\\theta E(\\pmb{\\theta}_{t-1}-\\gamma u_{t-1})$$\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img01/deepnet_20.png\" alt=\"Методы импульсов\" style=\"width: 350px;\"/>\n",
    "    <strong>Визуализация двух вариантов метода импульсов</strong>     \n",
    "</center>\n",
    "\n",
    "Это целесообразно, т.к.:\n",
    "* огласно методу моментов $\\gamma u_{t-1}$ уже точно будет использовано на этом шаге\n",
    "* изменившийся градент разумно считать уже в той точке, куда мы придем после применения момента предыдущего шага"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Метод Adagrad__\n",
    "\n",
    "В рассмотренных выше адаптивных методах\n",
    "* шаг обновления зависел только от текущего градиента и глобальных параметров\n",
    "* шаг обновления не учитывал историю обновлений для каждого отдельного параметра\n",
    "\n",
    "Возможный вариант:\n",
    "* некоторые веса уже близки к своим локальным минимумам <em class=\"hn\"></em> по этим координатам нужно двигаться медленно\n",
    "* другие веса еще находятся \"на крутом склоне\" <em class=\"hn\"></em> их можно менять гораздо быстрее\n",
    "\n",
    "В методах, которые мы обсуждали до сих пор, шаг обновления зависел только от текущего градиента и глобального параметра скорости обучения, но никак не учитывал историю обновлений для каждого отдельного параметра. Однако вполне может так сложиться, что некоторые веса уже близки к своим локальным минимумам, и по этим координатам нужно двигаться медленно и осторожно, а другие веса еще на середине соответствующего склона, и их можно менять гораздо быстрее. К тому же, само по себе регулирование скорости обучения может оказаться довольно затратным делом. Для того чтобы иметь возможность адаптировать скорость обучения для разных параметров автоматически, были созданы адаптивные методы оптимизации.\n",
    "\n",
    "Идея метода __Adagrad__:\n",
    "* шаг изменения должен быть меньше у параметров, которые в большей степени варьируются в данных\n",
    "* шаг изменения должен быть больше у тех, которые менее изменчивы в разных примерах\n",
    "\n",
    "Обозначим через $g_{t,i}$ градиент функции ошибки по параметру $θ_i$ на шаге $t$:\n",
    "$$g_{t,i} = \\nabla_{\\theta_i} E(\\pmb{\\theta}_{t})$$.\n",
    "\n",
    "Тогда обновление параметра $\\theta_i$ на очередном шаге градиентного спуска можно записать так:\n",
    "\n",
    "$$\\theta_{t+1,i}=\\theta_{t,i}-\\frac{\\eta}{\\sqrt{G_{t,ii}+\\epsilon}} \\cdot g_{t,i}$$\n",
    "\n",
    "где $G_{t}$ - диагональная матрица, каждый элемент которой - сумма квадратов градиентов соответствующего параметра за предыдущие шаги:\n",
    "\n",
    "$$G_{t,ii}=G_{t-1,ii}+g_{t,i}^2$$\n",
    "а $\\epsilon$ - сглаживающий параметр, позволяющий избежать деления на ноль.\n",
    "\n",
    "В вектороном виде выражения можно записать (произведение выполняется покомпонентно):\n",
    "$$\\pmb{u_t}=-\\frac{\\eta}{\\sqrt{G_{t-1}+\\epsilon}} \\odot g_{t-1}$$\n",
    "\n",
    "* <em class=\"pl\"></em> Один из плюсов Adagrad является снятие необходимости ручной настройки скорости обучения $\\eta$ т.к. диагональные элементы $G$ по сути являются индивидуальными скоростями обучения для каждого компонента $\\pmb{\\theta}$.\n",
    "* <em class=\"mn\"></em> Т.к. слагаемое $g^2$ всегда положительно <em class=\"hn\"></em> $G$ постоянно увеличивается <em class=\"hn\"></em> скорость оптимизации (обучения) может уменьшаться слишком быстро, что плохо сказывается на обучении глубоких ИНС\n",
    "* <em class=\"mn\"></em> Глобальную скорость обучения в Adagrad нужно выбирать вручную"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adadelta__ -  несложная, но эффективная модификация алгоритма Adagrad, основная цель которой состоит в том, чтобы попытаться исправить два указанных выше недостатка.\n",
    "\n",
    "Первая идея: избавиться от накаплиения суммы квадратов градиентов по всей истории обучения\n",
    "* (I вариант) будем считать суммы квадратов градиентов по некоторому окну\n",
    "* (II вариант) будем считать суммы квадратов градиентов по всей истории, но с экспоненциально затухающими весами\n",
    "\n",
    "Для каждого оптимизируемого параметра введем свой метапараметр $\\rho_i$, тогда экспоненциальное затухание можно записать так:\n",
    "\n",
    "$$G_{t,ii}=\\rho G_{t-1,ii}+(1-\\rho)g_{t,i}^2$$\n",
    "\n",
    "при этом, как и в методе моментов, метапараметр $\\rho_i<1$\n",
    "\n",
    "* Экспоненциальное среднее, в отличие от суммы, будет убывать только тогда, когда убывающими станут градиенты.\n",
    "* Т.е. уменьшение скорости обучения будет происходить только в тот момент, когда изменение целевой функции замедляется, для более тонкой настройки вокруг локального минимума.\n",
    "\n",
    "Вторая идея: исправление размерности в шаге алгоритма\n",
    "\n",
    "* В Adagrad значения обновлений $\\Delta \\theta $ зависят от отношений градиентов, то есть величина обновлений являюется безразмерной. \n",
    "* Правильные \"единицы измерений\" получаются только в методах второго порядка. В частности в методе Ньютона второго порядка обновление параметров: \n",
    "$$\\Delta \\theta \\sim H^{-1}\\nabla_{\\theta}f \\sim \\frac{\\dfrac{\\partial f}{\\partial \\theta}}{\\dfrac{\\partial^2 f}{\\partial \\theta^2}} \\sim размерность \\theta$$\n",
    "\n",
    "* Чтобы привести масштабы этих величин в соответствие, достаточно домножить обновление из Adagrad на еще один новый сомножитель: еще одно экспоненциальное среднее, но теперь уже от квадратов обновлений параметров, а не от градиента.\n",
    "* Поскольку настоящее среднее квадратов обновлений нам неизвестно, то чтобы его узнать, нам нужно как раз сначала выполнить текущий шаг алгоритма, — оно аппроксимируется предыдущими шагами:\n",
    "$$\\mathbb{E} \\left [ \\Delta \\theta^2\\right ]_t=\\rho \\mathbb{E} \\left [ \\Delta \\theta^2\\right ]_{t-1}+(1-\\rho)\\Delta \\theta^2$$\n",
    "С помощью полученного значения получаем поправочных коэффициент:\n",
    "$$\\pmb{u_t}=-\\frac{\\sqrt{\\mathbb{E} \\left [ \\Delta \\theta^2\\right ]_{t-1}+\\epsilon}}{\\sqrt{G_{t-1}+\\epsilon}} \\odot \\pmb{g_{t-1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует близкий аналог Adadelta алгоритм RMSprop оба метода основаны на классической идее применения инерции, только  RMSprop использует ее для оптимизации метапараметра скорости обучения.\n",
    "\n",
    "Основная разница между RMSprop и Adadelta состоит в том, что RMSprop не делает вторую поправку с изменением единиц и хранением истории самих обновлений, а просто использует корень из среднего от квадратов (вот он где, RMS) от\n",
    "градиентов:\n",
    "\n",
    "$$\\pmb{u_t}=-\\frac{\\eta}{\\sqrt{G_{t-1}+\\epsilon}} \\odot g_{t-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "    <img src=\"./img01/opt2.gif\" alt=\"Пример работы градиентного спуска\" style=\"width: 500px;\"/>\n",
    "    <strong>Пример работы различных вариантов градиентного спуска для функции двух переменных</strong>     \n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Спасибо за внимание!\n",
    "\n",
    "---\n",
    "### Технический раздел:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> next <em class=\"qs\"></em> qs line \n",
    "<br/> next <em class=\"an\"></em> an line \n",
    "<br/> next <em class=\"nt\"></em> an line \n",
    "<br/> next <em class=\"df\"></em> df line \n",
    "<br/> next <em class=\"ex\"></em> ex line \n",
    "<br/> next <em class=\"pl\"></em> pl line \n",
    "<br/> next <em class=\"mn\"></em> mn line \n",
    "<br/> next <em class=\"plmn\"></em> plmn line \n",
    "<br/> next <em class=\"hn\"></em> hn line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch_1_5v2",
   "language": "python",
   "name": "pytorch_1_5v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
