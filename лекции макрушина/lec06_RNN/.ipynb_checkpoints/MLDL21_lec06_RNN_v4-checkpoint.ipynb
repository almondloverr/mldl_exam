{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 6: Рекуррентные нейронные сети RNN  (Recurrent Neural Networks)\n",
    "\n",
    "__Автор: Сергей Вячеславович Макрушин__ e-mail: SVMakrushin@fa.ru \n",
    "\n",
    "Финансовый универсиет, 2021 г. \n",
    "\n",
    "При подготовке лекции использованы материалы:\n",
    "* ...\n",
    "\n",
    "v 0.1 15.04.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделы: <a class=\"anchor\" id=\"разделы\"></a>\n",
    "* [раздел 1](#загрузка)\n",
    "* [раздел 2](#нормализация)\n",
    "-\n",
    "\n",
    "* [к оглавлению](#разделы)\n",
    "\n",
    "---\n",
    "## Нормализация <a class=\"anchor\" id=\"нормализация\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "﻿<style>\r\n",
       "\r\n",
       "\r\n",
       "b.n {\r\n",
       "    font-weight: normal;        \r\n",
       "}\r\n",
       "\r\n",
       "b.grbg {\r\n",
       "    background-color: #a0a0a0;      \r\n",
       "}\r\n",
       "\r\n",
       "b.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "b.b {    \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "b.g {\r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "// add your CSS styling here\r\n",
       "\r\n",
       "list-style: none;\r\n",
       "\r\n",
       "ul.s {\r\n",
       "//    list-style-type: none;\r\n",
       "    list-style: none;\r\n",
       "//    background-color: #ff0000;  \r\n",
       "//    color: #ffff00;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;\r\n",
       "}\r\n",
       "\r\n",
       "li.t {\r\n",
       "    list-style: none;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "*.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "li.t:before {\r\n",
       "    content: \"\\21D2\";    \r\n",
       "//    content: \"►\";\r\n",
       "//    padding-left: -1.2em;    \r\n",
       "    text-indent: -1.2em;    \r\n",
       "    display: block;\r\n",
       "    float: left;\r\n",
       "    \r\n",
       "    \r\n",
       "//    width: 1.2em;\r\n",
       "//    color: #ff0000;\r\n",
       "}\r\n",
       "\r\n",
       "i.m:before {\r\n",
       "    font-style: normal;    \r\n",
       "    content: \"\\21D2\";  \r\n",
       "}\r\n",
       "i.m {\r\n",
       "    font-style: normal; \r\n",
       "}    \r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "/* em {\r\n",
       "    font-style: normal; \r\n",
       "} */\r\n",
       "\r\n",
       "\r\n",
       "em.bl {\r\n",
       "    font-style: normal;     \r\n",
       "    font-weight: bold;        \r\n",
       "}\r\n",
       "\r\n",
       "/* em.grbg {\r\n",
       "    font-style: normal;         \r\n",
       "    background-color: #a0a0a0;      \r\n",
       "} */\r\n",
       "\r\n",
       "em.cr {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cb {    \r\n",
       "    font-style: normal;         \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cg {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "\r\n",
       "em.qs {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.qs::before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #ff0000;    \r\n",
       "    content: \"Q:\";  \r\n",
       "}\r\n",
       "\r\n",
       "em.an {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.an:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"A:\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.nt {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.nt:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Note:\";  \r\n",
       "}    \r\n",
       "    \r\n",
       "em.ex {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.ex:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #00ff00;    \r\n",
       "    content: \"Ex:\";  \r\n",
       "} \r\n",
       "    \r\n",
       "em.df {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.df:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Def:\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.pl {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.pl:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"+\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.mn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.mn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"-\";  \r\n",
       "}        \r\n",
       "\r\n",
       "em.plmn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.plmn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\00B1\";\\\\\"&plusmn;\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.hn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.hn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\21D2\";\\\\\"&rArr;\";  \r\n",
       "}     \r\n",
       "    \r\n",
       "\r\n",
       "#cssTableCenter td, th \r\n",
       "{\r\n",
       "    text-align: center; \r\n",
       "    vertical-align: middle;\r\n",
       "}\r\n",
       "\r\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем стиль для оформления презентации\n",
    "from IPython.display import HTML\n",
    "from urllib.request import urlopen\n",
    "html = urlopen(\"file:./lec_v2.css\")\n",
    "HTML(html.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Базовые подходы к RNN <a class=\"anchor\" id=\"установка\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Мотивация для использования рекуррентных нейронных сетей__\n",
    "\n",
    "* Не рекуррентные архитектуры ИНС получают на вход вектор данных и пытаются по нему предсказать тот или иной результат (минимизировать ошибку). \n",
    "* Важно, что входной (и выходной) вектор должен __иметь одну и ту же размерность__. Во многих задачах это не так.\n",
    "\n",
    "<br/>\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_1.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "    <b>Задачи с последовательностями</b> <br/>\n",
    "    Каждый прямоугольник представляет собой вектор, а стрелки представляют функции (например, умножение матриц). Входные векторы показаны красным, выходные векторы - синим, а зеленые векторы содержат состояние RNN.    \n",
    "</center>\n",
    "\n",
    "1. один вход, один выход (классический случай)\n",
    "* один вход, последовательность выходов\n",
    "* последовательность входов, один выход\n",
    "* последовательность входов, затем последовательность выходов\n",
    "* синхронизированные последовательности входов и выходов    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Рекуррентная нейронная сеть (RNN)__\n",
    "\n",
    "<em class=\"df\"></em> __Рекуррентная нейронная сеть (RNN)__ - это класс искусственных нейронных сетей, в которых узел может получать входы не только от других узлов и текущих входных данных но и выходы узлов, полученные при рассмотрении предыдущих входных данных последовательности.\n",
    "* обмен вектором внутреннего сосотояния, полученного на предыдущем шаге, позволяет использовать информацию о предыдущих шагах, которые сеть уже обработала\n",
    "* при рассмотрении всей последовательности веса каждого узла одни и те же при рассмотрении всех входных данных последовательности\n",
    "\n",
    "\n",
    "* Ткая архитектура сети позволяет обрабатывать серии событий во времени или последовательные пространственные цепочки произвольной размерности\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_3.png\" alt=\"\" style=\"width: 700px;\"/>\n",
    "    <b>Принцип устройства узла RNN</b> <br/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трудность рекуррентной сети:\n",
    "* если учитывать каждый шаг времени, то становится необходимым для каждого шага времени (последовательности) создавать свой слой нейронов, что создает серьёзные вычислительные сложности\n",
    "* многослойные реализации вычислительно неустойчивы: в них как правило либо исчезают либо зашкаливают веса\n",
    "* если ограничить расчёт фиксированным временным окном, то полученные модели не будут отражать долгосрочных трендов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>         \n",
    "    <img src=\"./img/rnn_2.png\" alt=\"\" style=\"width: 200px;\"/>\n",
    "    <b>Распространение ошибок в узле RNN</b> <br/>\n",
    "</center>\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_5.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "    <b>Распространение ошибок в узле RNN</b> <br/>\n",
    "</center>\n",
    "\n",
    "* $a_t = b + Ws_{t−1} + Ux_t$\n",
    "* $s_t = f(a_t)$\n",
    "* $o_t=c+Vs_t$\n",
    "* $y_t=h(o_t)$\n",
    "\n",
    "Где:\n",
    "* $f$ — это нелинейность рекуррентной сети (обычно $\\sigma$, $\\tanh$ или $ReLU$)\n",
    "* $h$ — функция, с помощью которой получается ответ (например, $softmax$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Распространение ошибки в архитектуре RNN__\n",
    "\n",
    "* В прямой нейронной сети ошибка на конкретном нейроне вычисляется как функция от ошибок нейронов, которые используют его выходное значение <em class=\"hn\"></em> формируется ациклический графы вычислений:\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/ann_19.png\" alt=\"Прямой и обратный проход \" style=\"width: 300px;\"/>\n",
    "    <b>Прямой и обратный проход процедуры обучения многослойной ИНС </b> <br/>    \n",
    "</center>\n",
    "\n",
    "* В архитектуре RNN нейрон принимает в качестве входа результат вычисления в нем самом (через вектор состояния)\n",
    "    * Важно понимать, что при этом петли в графе вычислений не образуется \n",
    "    * Вычисления, которые делает рекуррентная сеть, можно развернуть обратно до начала обрабатываемой последовательности\n",
    "    * Можно сказать, что на каждом шаге обрабатываемой последовательности сеть создает копии самой себя\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_3.png\" alt=\"\" style=\"width: 700px;\"/>\n",
    "    <b>Принцип устройства узла RNN </b> <br/>\n",
    "</center>\n",
    "\n",
    "* И на каждом последовательности мы фактически обучаем глубокую нейронную сеть, в которой столько слоев, сколько элементов в последовательности на данный момент мы уже видели\n",
    "* Рекуррентная сеть — разворчиватся вдоль элементов последовательности $1 \\dotsc T$ в очень-очень многоуровневую обычную сеть, в которой одни и те же веса переиспользуются на каждом уровне. \n",
    "    * <em class=\"pl\"></em> Для хранения весов достаточно одной матрицы\n",
    "    * <em class=\"pl\"></em> Градиенты по весам не затухают до нуля сразу же (как это бывает в обычных глубких сетях)\n",
    "    * <em class=\"mn\"></em> Если матрица весов меняет норму вектора градиента при проходе через один «слой» обратного распространения, то при проходе через T слоев эта норма изменяется экспоненциально (т.к. веса матрицы одни и те же) это приводит:\n",
    "        * к __\"взрыу градиентов\"__ (exploding gradients), если матрица заметно увеличивает норму вектора градиента\n",
    "        * к экспоненациональному затуханию градиентов (Vanishing gradients), если матрица заметно уменьшает норму вектора градиента\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_4.png\" alt=\"\" style=\"width: 500px;\"/>\n",
    "    <b>Распространение ошибок в узле RNN</b> <br/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Пример реализации RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты:\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Входные данные:\n",
    "\n",
    "text = ['hey how are you','good i am fine','have a nice day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('name2.csv', encoding='cp1251') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)    \n",
    "    text = list(n[0].lower() for n in csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['агафья', 'аглая', 'агния']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодировка символов числами:\n",
    "\n",
    "# Join all the sentences together and extract the unique characters from the combined sentences\n",
    "chars = set(''.join(text)+' ')\n",
    "\n",
    "# Creating a dictionary that maps integers to the characters\n",
    "int2char = dict(enumerate(chars))\n",
    "\n",
    "# Creating another dictionary that maps characters to integers\n",
    "char2int = {char: ind for ind, char in int2char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'л': 0, 'ф': 1, 'ю': 2, 'м': 3, 'к': 4, 'я': 5, 'п': 6, 'а': 7, 'и': 8, 'р': 9, 'е': 10, 'у': 11, 'с': 12, 'ц': 13, 'н': 14, 'д': 15, 'ь': 16, 'ж': 17, 'з': 18, ' ': 19, 'т': 20, 'б': 21, 'в': 22, 'г': 23, 'о': 24, 'ё': 25}\n"
     ]
    }
   ],
   "source": [
    "print(char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest string has 10 characters\n"
     ]
    }
   ],
   "source": [
    "# Выравнивание всех строк до фиксированной (максимальной) длины:\n",
    "\n",
    "maxlen = len(max(text, key=len))\n",
    "print(\"The longest string has {} characters\".format(maxlen))\n",
    "\n",
    "# Padding\n",
    "\n",
    "# A simple loop that loops through the list of sentences and adds a ' ' whitespace until the length of the sentence matches\n",
    "# the length of the longest sentence\n",
    "\n",
    "for i in range(len(text)):\n",
    "    while len(text[i])<maxlen:\n",
    "        text[i] += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence: агафья   \n",
      "Target Sequence: гафья    \n",
      "Input Sequence: аглая    \n",
      "Target Sequence: глая     \n",
      "Input Sequence: агния    \n",
      "Target Sequence: гния     \n",
      "Input Sequence: агриппина\n",
      "Target Sequence: гриппина \n",
      "Input Sequence: акулина  \n",
      "Target Sequence: кулина   \n",
      "Input Sequence: алевтина \n",
      "Target Sequence: левтина  \n",
      "Input Sequence: александр\n",
      "Target Sequence: лександра\n",
      "Input Sequence: алина    \n",
      "Target Sequence: лина     \n",
      "Input Sequence: алла     \n",
      "Target Sequence: лла      \n",
      "Input Sequence: анастасия\n",
      "Target Sequence: настасия \n",
      "Input Sequence: ангелина \n",
      "Target Sequence: нгелина  \n",
      "Input Sequence: анжела   \n",
      "Target Sequence: нжела    \n",
      "Input Sequence: анжелика \n",
      "Target Sequence: нжелика  \n",
      "Input Sequence: анна     \n",
      "Target Sequence: нна      \n",
      "Input Sequence: антонина \n",
      "Target Sequence: нтонина  \n",
      "Input Sequence: анфиса   \n",
      "Target Sequence: нфиса    \n",
      "Input Sequence: валентина\n",
      "Target Sequence: алентина \n",
      "Input Sequence: валерия  \n",
      "Target Sequence: алерия   \n",
      "Input Sequence: варвара  \n",
      "Target Sequence: арвара   \n",
      "Input Sequence: василиса \n",
      "Target Sequence: асилиса  \n",
      "Input Sequence: вера     \n",
      "Target Sequence: ера      \n",
      "Input Sequence: вероника \n",
      "Target Sequence: ероника  \n",
      "Input Sequence: виктория \n",
      "Target Sequence: иктория  \n",
      "Input Sequence: галина   \n",
      "Target Sequence: алина    \n",
      "Input Sequence: глафира  \n",
      "Target Sequence: лафира   \n",
      "Input Sequence: гликерия \n",
      "Target Sequence: ликерия  \n",
      "Input Sequence: дана     \n",
      "Target Sequence: ана      \n",
      "Input Sequence: дарья    \n",
      "Target Sequence: арья     \n",
      "Input Sequence: евгения  \n",
      "Target Sequence: вгения   \n",
      "Input Sequence: евдокия  \n",
      "Target Sequence: вдокия   \n",
      "Input Sequence: евлалия  \n",
      "Target Sequence: влалия   \n",
      "Input Sequence: евлампия \n",
      "Target Sequence: влампия  \n",
      "Input Sequence: евпраксия\n",
      "Target Sequence: впраксия \n",
      "Input Sequence: евфросини\n",
      "Target Sequence: вфросиния\n",
      "Input Sequence: екатерина\n",
      "Target Sequence: катерина \n",
      "Input Sequence: елена    \n",
      "Target Sequence: лена     \n",
      "Input Sequence: елизавета\n",
      "Target Sequence: лизавета \n",
      "Input Sequence: епистима \n",
      "Target Sequence: пистима  \n",
      "Input Sequence: ермиония \n",
      "Target Sequence: рмиония  \n",
      "Input Sequence: жанна    \n",
      "Target Sequence: анна     \n",
      "Input Sequence: зинаида  \n",
      "Target Sequence: инаида   \n",
      "Input Sequence: злата    \n",
      "Target Sequence: лата     \n",
      "Input Sequence: зоя      \n",
      "Target Sequence: оя       \n",
      "Input Sequence: инга     \n",
      "Target Sequence: нга      \n",
      "Input Sequence: инесса   \n",
      "Target Sequence: несса    \n",
      "Input Sequence: инна     \n",
      "Target Sequence: нна      \n",
      "Input Sequence: иоанна   \n",
      "Target Sequence: оанна    \n",
      "Input Sequence: ираида   \n",
      "Target Sequence: раида    \n",
      "Input Sequence: ирина    \n",
      "Target Sequence: рина     \n",
      "Input Sequence: ия       \n",
      "Target Sequence: я        \n",
      "Input Sequence: капитолин\n",
      "Target Sequence: апитолина\n",
      "Input Sequence: карина   \n",
      "Target Sequence: арина    \n",
      "Input Sequence: каролина \n",
      "Target Sequence: аролина  \n",
      "Input Sequence: кира     \n",
      "Target Sequence: ира      \n",
      "Input Sequence: клавдия  \n",
      "Target Sequence: лавдия   \n",
      "Input Sequence: ксения   \n",
      "Target Sequence: сения    \n",
      "Input Sequence: лада     \n",
      "Target Sequence: ада      \n",
      "Input Sequence: лариса   \n",
      "Target Sequence: ариса    \n",
      "Input Sequence: лидия    \n",
      "Target Sequence: идия     \n",
      "Input Sequence: лилия    \n",
      "Target Sequence: илия     \n",
      "Input Sequence: любовь   \n",
      "Target Sequence: юбовь    \n",
      "Input Sequence: людмила  \n",
      "Target Sequence: юдмила   \n",
      "Input Sequence: маргарита\n",
      "Target Sequence: аргарита \n",
      "Input Sequence: марина   \n",
      "Target Sequence: арина    \n",
      "Input Sequence: мария    \n",
      "Target Sequence: ария     \n",
      "Input Sequence: марфа    \n",
      "Target Sequence: арфа     \n",
      "Input Sequence: матрёна  \n",
      "Target Sequence: атрёна   \n",
      "Input Sequence: милица   \n",
      "Target Sequence: илица    \n",
      "Input Sequence: мирослава\n",
      "Target Sequence: ирослава \n",
      "Input Sequence: надежда  \n",
      "Target Sequence: адежда   \n",
      "Input Sequence: наталья  \n",
      "Target Sequence: аталья   \n",
      "Input Sequence: нина     \n",
      "Target Sequence: ина      \n",
      "Input Sequence: нонна    \n",
      "Target Sequence: онна     \n",
      "Input Sequence: оксана   \n",
      "Target Sequence: ксана    \n",
      "Input Sequence: октябрина\n",
      "Target Sequence: ктябрина \n",
      "Input Sequence: олимпиада\n",
      "Target Sequence: лимпиада \n",
      "Input Sequence: ольга    \n",
      "Target Sequence: льга     \n",
      "Input Sequence: павлина  \n",
      "Target Sequence: авлина   \n",
      "Input Sequence: пелагея  \n",
      "Target Sequence: елагея   \n",
      "Input Sequence: пинна    \n",
      "Target Sequence: инна     \n",
      "Input Sequence: полина   \n",
      "Target Sequence: олина    \n",
      "Input Sequence: прасковья\n",
      "Target Sequence: расковья \n",
      "Input Sequence: рада     \n",
      "Target Sequence: ада      \n",
      "Input Sequence: раиса    \n",
      "Target Sequence: аиса     \n",
      "Input Sequence: римма    \n",
      "Target Sequence: имма     \n",
      "Input Sequence: светлана \n",
      "Target Sequence: ветлана  \n",
      "Input Sequence: серафима \n",
      "Target Sequence: ерафима  \n",
      "Input Sequence: снежана  \n",
      "Target Sequence: нежана   \n",
      "Input Sequence: софия    \n",
      "Target Sequence: офия     \n",
      "Input Sequence: таисия   \n",
      "Target Sequence: аисия    \n",
      "Input Sequence: тамара   \n",
      "Target Sequence: амара    \n",
      "Input Sequence: татьяна  \n",
      "Target Sequence: атьяна   \n",
      "Input Sequence: улита    \n",
      "Target Sequence: лита     \n",
      "Input Sequence: ульяна   \n",
      "Target Sequence: льяна    \n",
      "Input Sequence: урсула   \n",
      "Target Sequence: рсула    \n",
      "Input Sequence: фаина    \n",
      "Target Sequence: аина     \n",
      "Input Sequence: феврония \n",
      "Target Sequence: еврония  \n",
      "Input Sequence: фёкла    \n",
      "Target Sequence: ёкла     \n",
      "Input Sequence: феодора  \n",
      "Target Sequence: еодора   \n",
      "Input Sequence: целестина\n",
      "Target Sequence: елестина \n",
      "Input Sequence: юлия     \n",
      "Target Sequence: лия      \n",
      "Input Sequence: яна      \n",
      "Target Sequence: на       \n",
      "Input Sequence: ярослава \n",
      "Target Sequence: рослава  \n"
     ]
    }
   ],
   "source": [
    "# Подготовка входных и выходных последовательностей:\n",
    "\n",
    "input_seq = [] # исходная последовательность\n",
    "target_seq = [] # последовательность, смещенная на 1 (без первого символа)\n",
    "\n",
    "for i in range(len(text)):\n",
    "    # Remove last character for input sequence\n",
    "    input_seq.append(text[i][:-1])\n",
    "    \n",
    "    # Remove firsts character for target sequence\n",
    "    target_seq.append(text[i][1:])\n",
    "    \n",
    "    print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot энкодер (для батча примеров фиксированной длины)\n",
    "\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "    \n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(input_seq, dict_size, seq_len, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение входного и выходного тензора:\n",
    "# batch_size x seq_len x dict_size ; seq_len = maxlen - 1\n",
    "\n",
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = len(text)\n",
    "\n",
    "# Symbol seq to int seq:\n",
    "for i in range(len(text)):\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
    "\n",
    "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
    "input_seq = torch.from_numpy(input_seq)\n",
    "# print(f\"Input shape: {input_seq.shape} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\", input_seq)\n",
    "\n",
    "# --- --- --- ---\n",
    "# target_seq = one_hot_encode(target_seq, dict_size, seq_len, batch_size)\n",
    "target_seq = torch.Tensor(target_seq) # from list; without one-hot encoding\n",
    "\n",
    "# print(f\"Target shape: {input_seq.shape} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\", target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = False # torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Модель__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn.RNN(*args, **kwargs)`\n",
    "\n",
    "For each element in the input sequence, each layer computes the following function:\n",
    "\n",
    "$$ h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh}) $$\n",
    "\n",
    "Shape:\n",
    "\n",
    "_Input:_\n",
    "\n",
    "* __input__ of shape (seq_len, batch, input_size): tensor containing the features of the input sequence. The input can also be a packed variable length sequence.\n",
    "* __h_0__ of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. If the RNN is bidirectional, num_directions should be 2, else it should be 1.\n",
    "\n",
    "_Output:_\n",
    "* __output__ of shape (seq_len, batch, num_directions * hidden_size): tensor containing the output features (h_t) from the last layer of the RNN, for each t.\n",
    "* __h_n__ of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
    "\n",
    "Parameters:\n",
    "* `input_size` -  The number of expected features in the input `x`\n",
    "* `hidden_size` - The number of features in the hidden state `h`\n",
    "* `num_layers` - Number of recurrent layers. E.g., setting ``num_layers=2`` would mean stacking two RNNs together to form a `stacked RNN`, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
    "* `nonlinearity` - The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n",
    "* `bias` - If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`. Default: ``True``\n",
    "* `batch_first` - If ``True``, then the input and output tensors are provided as `(batch, seq, feature)`. Default: ``False``\n",
    "* `dropout` - If non-zero, introduces a `Dropout` layer on the outputs of each RNN layer except the last layer, with dropout probability equal to `dropout`. Default: 0\n",
    "* `bidirectional` - If ``True``, becomes a bidirectional RNN. Default: ``False``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "#         print('d1: ', out.size())\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "#         print('d2: ', out.size())\n",
    "        out = self.fc(out)\n",
    "#         print('d3: ', out.size())\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем инстанс модели с установленными гиперпараметрами\n",
    "\n",
    "model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = model(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([23.,  7.,  1., 16.,  5., 19., 19., 19., 19., 23.,  0.,  7.,  5., 19.,\n",
       "         19., 19., 19., 19., 23., 14.,  8.,  5., 19., 19., 19., 19., 19., 23.,\n",
       "          9.,  8.,  6.,  6.,  8., 14.,  7., 19.,  4., 11.,  0.,  8., 14.,  7.,\n",
       "         19., 19., 19.,  0., 10., 22., 20.,  8., 14.,  7., 19., 19.,  0., 10.,\n",
       "          4., 12.,  7., 14., 15.,  9.,  7.,  0.,  8., 14.,  7., 19., 19., 19.,\n",
       "         19., 19.,  0.,  0.,  7., 19., 19., 19., 19., 19., 19., 14.,  7., 12.,\n",
       "         20.,  7., 12.,  8.,  5., 19., 14., 23., 10.,  0.,  8., 14.,  7., 19.,\n",
       "         19., 14., 17., 10.,  0.,  7., 19., 19., 19., 19., 14., 17., 10.,  0.,\n",
       "          8.,  4.,  7., 19., 19., 14., 14.,  7., 19., 19., 19., 19., 19., 19.,\n",
       "         14., 20., 24., 14.,  8., 14.,  7., 19., 19., 14.,  1.,  8., 12.,  7.,\n",
       "         19., 19., 19., 19.,  7.,  0., 10., 14., 20.,  8., 14.,  7., 19.,  7.,\n",
       "          0., 10.,  9.,  8.,  5., 19., 19., 19.,  7.,  9., 22.,  7.,  9.,  7.,\n",
       "         19., 19., 19.,  7., 12.,  8.,  0.,  8., 12.,  7., 19., 19., 10.,  9.,\n",
       "          7., 19., 19., 19., 19., 19., 19., 10.,  9., 24., 14.,  8.,  4.,  7.,\n",
       "         19., 19.,  8.,  4., 20., 24.,  9.,  8.,  5., 19., 19.,  7.,  0.,  8.,\n",
       "         14.,  7., 19., 19., 19., 19.,  0.,  7.,  1.,  8.,  9.,  7., 19., 19.,\n",
       "         19.,  0.,  8.,  4., 10.,  9.,  8.,  5., 19., 19.,  7., 14.,  7., 19.,\n",
       "         19., 19., 19., 19., 19.,  7.,  9., 16.,  5., 19., 19., 19., 19., 19.,\n",
       "         22., 23., 10., 14.,  8.,  5., 19., 19., 19., 22., 15., 24.,  4.,  8.,\n",
       "          5., 19., 19., 19., 22.,  0.,  7.,  0.,  8.,  5., 19., 19., 19., 22.,\n",
       "          0.,  7.,  3.,  6.,  8.,  5., 19., 19., 22.,  6.,  9.,  7.,  4., 12.,\n",
       "          8.,  5., 19., 22.,  1.,  9., 24., 12.,  8., 14.,  8.,  5.,  4.,  7.,\n",
       "         20., 10.,  9.,  8., 14.,  7., 19.,  0., 10., 14.,  7., 19., 19., 19.,\n",
       "         19., 19.,  0.,  8., 18.,  7., 22., 10., 20.,  7., 19.,  6.,  8., 12.,\n",
       "         20.,  8.,  3.,  7., 19., 19.,  9.,  3.,  8., 24., 14.,  8.,  5., 19.,\n",
       "         19.,  7., 14., 14.,  7., 19., 19., 19., 19., 19.,  8., 14.,  7.,  8.,\n",
       "         15.,  7., 19., 19., 19.,  0.,  7., 20.,  7., 19., 19., 19., 19., 19.,\n",
       "         24.,  5., 19., 19., 19., 19., 19., 19., 19., 14., 23.,  7., 19., 19.,\n",
       "         19., 19., 19., 19., 14., 10., 12., 12.,  7., 19., 19., 19., 19., 14.,\n",
       "         14.,  7., 19., 19., 19., 19., 19., 19., 24.,  7., 14., 14.,  7., 19.,\n",
       "         19., 19., 19.,  9.,  7.,  8., 15.,  7., 19., 19., 19., 19.,  9.,  8.,\n",
       "         14.,  7., 19., 19., 19., 19., 19.,  5., 19., 19., 19., 19., 19., 19.,\n",
       "         19., 19.,  7.,  6.,  8., 20., 24.,  0.,  8., 14.,  7.,  7.,  9.,  8.,\n",
       "         14.,  7., 19., 19., 19., 19.,  7.,  9., 24.,  0.,  8., 14.,  7., 19.,\n",
       "         19.,  8.,  9.,  7., 19., 19., 19., 19., 19., 19.,  0.,  7., 22., 15.,\n",
       "          8.,  5., 19., 19., 19., 12., 10., 14.,  8.,  5., 19., 19., 19., 19.,\n",
       "          7., 15.,  7., 19., 19., 19., 19., 19., 19.,  7.,  9.,  8., 12.,  7.,\n",
       "         19., 19., 19., 19.,  8., 15.,  8.,  5., 19., 19., 19., 19., 19.,  8.,\n",
       "          0.,  8.,  5., 19., 19., 19., 19., 19.,  2., 21., 24., 22., 16., 19.,\n",
       "         19., 19., 19.,  2., 15.,  3.,  8.,  0.,  7., 19., 19., 19.,  7.,  9.,\n",
       "         23.,  7.,  9.,  8., 20.,  7., 19.,  7.,  9.,  8., 14.,  7., 19., 19.,\n",
       "         19., 19.,  7.,  9.,  8.,  5., 19., 19., 19., 19., 19.,  7.,  9.,  1.,\n",
       "          7., 19., 19., 19., 19., 19.,  7., 20.,  9., 25., 14.,  7., 19., 19.,\n",
       "         19.,  8.,  0.,  8., 13.,  7., 19., 19., 19., 19.,  8.,  9., 24., 12.,\n",
       "          0.,  7., 22.,  7., 19.,  7., 15., 10., 17., 15.,  7., 19., 19., 19.,\n",
       "          7., 20.,  7.,  0., 16.,  5., 19., 19., 19.,  8., 14.,  7., 19., 19.,\n",
       "         19., 19., 19., 19., 24., 14., 14.,  7., 19., 19., 19., 19., 19.,  4.,\n",
       "         12.,  7., 14.,  7., 19., 19., 19., 19.,  4., 20.,  5., 21.,  9.,  8.,\n",
       "         14.,  7., 19.,  0.,  8.,  3.,  6.,  8.,  7., 15.,  7., 19.,  0., 16.,\n",
       "         23.,  7., 19., 19., 19., 19., 19.,  7., 22.,  0.,  8., 14.,  7., 19.,\n",
       "         19., 19., 10.,  0.,  7., 23., 10.,  5., 19., 19., 19.,  8., 14., 14.,\n",
       "          7., 19., 19., 19., 19., 19., 24.,  0.,  8., 14.,  7., 19., 19., 19.,\n",
       "         19.,  9.,  7., 12.,  4., 24., 22., 16.,  5., 19.,  7., 15.,  7., 19.,\n",
       "         19., 19., 19., 19., 19.,  7.,  8., 12.,  7., 19., 19., 19., 19., 19.,\n",
       "          8.,  3.,  3.,  7., 19., 19., 19., 19., 19., 22., 10., 20.,  0.,  7.,\n",
       "         14.,  7., 19., 19., 10.,  9.,  7.,  1.,  8.,  3.,  7., 19., 19., 14.,\n",
       "         10., 17.,  7., 14.,  7., 19., 19., 19., 24.,  1.,  8.,  5., 19., 19.,\n",
       "         19., 19., 19.,  7.,  8., 12.,  8.,  5., 19., 19., 19., 19.,  7.,  3.,\n",
       "          7.,  9.,  7., 19., 19., 19., 19.,  7., 20., 16.,  5., 14.,  7., 19.,\n",
       "         19., 19.,  0.,  8., 20.,  7., 19., 19., 19., 19., 19.,  0., 16.,  5.,\n",
       "         14.,  7., 19., 19., 19., 19.,  9., 12., 11.,  0.,  7., 19., 19., 19.,\n",
       "         19.,  7.,  8., 14.,  7., 19., 19., 19., 19., 19., 10., 22.,  9., 24.,\n",
       "         14.,  8.,  5., 19., 19., 25.,  4.,  0.,  7., 19., 19., 19., 19., 19.,\n",
       "         10., 24., 15., 24.,  9.,  7., 19., 19., 19., 10.,  0., 10., 12., 20.,\n",
       "          8., 14.,  7., 19.,  0.,  8.,  5., 19., 19., 19., 19., 19., 19., 14.,\n",
       "          7., 19., 19., 19., 19., 19., 19., 19.,  9., 24., 12.,  0.,  7., 22.,\n",
       "          7., 19., 19.]),\n",
       " torch.Size([103, 9]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq.view(-1), target_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100............. Loss: 2.6428\n",
      "Epoch: 20/100............. Loss: 2.0990\n",
      "Epoch: 30/100............. Loss: 1.8213\n",
      "Epoch: 40/100............. Loss: 1.6268\n",
      "Epoch: 50/100............. Loss: 1.4895\n",
      "Epoch: 60/100............. Loss: 1.3958\n",
      "Epoch: 70/100............. Loss: 1.3235\n",
      "Epoch: 80/100............. Loss: 1.2654\n",
      "Epoch: 90/100............. Loss: 1.2167\n",
      "Epoch: 100/100............. Loss: 1.1754\n"
     ]
    }
   ],
   "source": [
    "# Training Run\n",
    "input_seq = input_seq.to(device)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    #input_seq = input_seq.to(device)\n",
    "    output, hidden = model(input_seq)\n",
    "    \n",
    "    output = output.to(device)    \n",
    "    target_seq = target_seq.to(device)\n",
    "    \n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "#     loss = criterion(output.view(-1), target_seq.view(-1).long())\n",
    "    \n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "    character = character.to(device)\n",
    "    \n",
    "    out, hidden = model(character)\n",
    "\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    # TODO: select top_k\n",
    "    \n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return int2char[char_ind], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, out_len, start='hey'):\n",
    "    model.eval() # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    \n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'фелия                                        '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(model, 45, 'фе')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Построение многослойных нейронных сетей на базе архитектуры RNN__\n",
    "\n",
    "\n",
    "* Рассмотрим всю рекуррентную сеть как слой и используем ее выходы как входы для следующего рекуррентного слоя.\n",
    "* Мотивация: каждый слой действует в своем собственном «масштабе времени», примерно как каждый слой сверточной сети действует в своем масштабе, на свой размер окна входов. \n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_7.png\" alt=\"\" style=\"width: 500px;\"/>\n",
    "    <b>Распространение ошибок в узле RNN</b> <br/>\n",
    "</center>\n",
    "\n",
    "\n",
    "__Двунаправленные рекуррентные сети__ (bidirectional RNN): для входной последовательности запустим RNN (обычно с разными весами) два раза: один слой будет __читать последовательность слева направо__, а другой — __справа налево__\n",
    "\n",
    "* Матрицы весов для двух направлений абсолютно независимы и между ними нет взаимодействия\n",
    "* Ограничение: данный подход возможен только для последовательностей, которые даны сразу целиком (например для предложений естественного языка).\n",
    "* Мотивация в том, чтобы получить состояние, отражающее контекст и слева, и справа для каждого элемента последовательности (например для отнесения слова к части речи т.к. важно анализировать все предложение, и слева, и справа от слова)\n",
    "* Вместо классической рекуррентной сети из трех матриц, может использоваться любая другая конструкция, например LSTM или GRU.\n",
    "    \n",
    "<center>         \n",
    "    <img src=\"./img/rnn_6.png\" alt=\"\" style=\"width: 500px;\"/>\n",
    "    <b>Распространение ошибок в узле RNN</b> <br/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LSTM__\n",
    "\n",
    "LSTM (Long Short-Term Memory) \n",
    "\n",
    "* обычные рекуррентные сети очень плохо справляются с ситуациями, когда нужно что-то «запомнить» надолго: влияние скрытого состояния или входа с шага t на последующие состояния рекуррентной сети экспоненциально затухает\n",
    "* LSTM хорошо приспособлена к обучению на задачах классификации, обработки и прогнозирования временных рядов в случаях, когда важные события разделены временными лагами с неопределённой продолжительностью и границами\n",
    "\n",
    "* вместо одного-единственного числа, на которое влияют все последующие состояния, используется специального вида ячейка моделирующая \"долгую память\"\n",
    "    * LSTM моделирует процессы записи и чтения из этой \"ячейки памяти\" \n",
    "    * у ячейки не один набор весов, как у обычного нейрона, а сразу несколько\n",
    "\n",
    "В LSTM есть три основных вида узлов, которые называются гейтами:\n",
    "* входной (input gate)\n",
    "* забывающий (forget gate)\n",
    "* выходной (output gate)\n",
    "* рекуррентная ячейка со скрытым состоянием\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_8.png\" alt=\"\" style=\"width: 350px;\"/>\n",
    "    <b>Структура LSTM</b> <br/>\n",
    "</center>\n",
    "\n",
    "Переменные:\n",
    "* $x_t$ — входной вектор во время t\n",
    "* $h_t$ — вектор скрытого состояния во время t\n",
    "* $c_t$ — вектор ячейки состояния во время t\n",
    "* $W_i$ — матрицы весов, применяющиеся ко входу\n",
    "* $W_h$ — матрицы весов, в рекуррентных соединениях; b - векторы свободных членов\n",
    "\n",
    "* candidate cell state: $c_t^{'}= \\tanh (W_{xc}x_t + W_{hc}h_{t-1}+b_{c^{'}})$\n",
    "* input gate: $i_t=\\sigma (W_{xi}x_t + W_{hi}h_{t-1}+b_{i})$\n",
    "* forget gate: $f_t=\\sigma (W_{xf}x_t + W_{hf}h_{t-1}+b_{f})$\n",
    "* output gate: $o_t=\\sigma (W_{xo}x_t + W_{ho}h_{t-1}+b_{o})$\n",
    "* cell state: $c_t=f_t \\odot c_{t-1} + i_t \\odot c_t^{'}$\n",
    "* block output: $h_t=o_t \\odot \\tanh (c_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Специфика ячейки памяти в LSTM__\n",
    "\n",
    "* Вход в LSTM:\n",
    "    * входные данные $x_t$\n",
    "    * скрытое состояние $h_{t-1}$\n",
    "    * вектор \"ячейки памяти\" (cell) $c_t$:\n",
    "        \n",
    "* Кандидат на новое значение памяти, полученный из входа и предыдущего скрытого состояния вектор: $c_t^{'}$ \n",
    "$$c_t=f_t \\odot c_{t-1} + i_t \\odot c_t^{'}$$\n",
    "\n",
    "* Новое значение $c_t$ получается как линейная комбинация из старого с коэффициентами из забывающего гейта $f_t$ и нового кандидата $c_t^{'}$ с коэффициентами из входного гейта $i_t$.\n",
    "* Покомпонентное умножение приводит к тому, что на очередном шаге может быть перезаписана только часть \"памяти\" LSTM-ячейки и какая это будет часть, тоже определяет сама ячейка.\n",
    "    * LSTM-ячейка может не просто выбрать, записать новое значение или выкинуть его, а еще и сохранить любую линейную комбинацию старого и нового значения, причем коэффициенты могут быть разными в разных компонентах вектора.\n",
    "    * Решения ячейка принимает в зависимости от конкретного входа.\n",
    "\n",
    "Так распространяется градиент ошибки для $c_t$, если рассматривать ее без забывающего гейта:\n",
    "$$\\frac{\\partial c_t}{\\partial c_{t-1}}=1$$\n",
    "\n",
    "* в рекурсивном вычислении состояния ячейки нет никакой нелинейности: т.е. ошибки в сети из LSTM пропагируются без изменений, и скрытые состояния LSTM могут, если сама ячейка не решит их перезаписать, сохранять свои значения неограниченно долго\n",
    "* __Важно__: хотя обычно веса нейронной сети инициализируются маленькими случайными числами свободный член забывающего гейта $b_f$\n",
    "    * все LSTM-ячейки изначально будут иметь значение $f_t$ около 1/2\n",
    "    * ошибки и память будут затухать экспоненциально. Поэтому свободный член $b_f$ нужно инициализировать большими значениями, около 1 или даже 2: тогда значения забывающих гейтов ft в начале обучения будут близки к нулю и градиенты будут свободно распространяться вдоль всей последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует много разных вариантов LSTM: \n",
    "\n",
    "* LSTM без входного гейта $i_t$\n",
    "* LSTM без забывающего гейта $f_t$\n",
    "* LSTM без выходного гейта $o_t$\n",
    "* LSTM без функции активации $\\sigma$ на входном гейте\n",
    "* LSTM без функции активации $\\sigma$ на выходном гейте\n",
    "* LSTM без замочных скважин\n",
    "* LSTM со связанными входным и забывающим гейтом\n",
    "* LSTM с дополнительными рекуррентными связями на каждом гейте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* LSTM требует довольно значительных ресурсов\n",
    "    * В обычном RNN каждая ячейка имеет один вектор скрытого состояния $h$, а веса представлены тремя матрицами (плюс свободные члены)\n",
    "    * В LSTM-ячейке даже в базовой модели участвует сразу восемь матриц весов\n",
    "* Цель: добиться того же эффекта долгосрочной памяти и решить проблему затухающих градиентов более эффективно\n",
    "\n",
    "* Критически важными компонентами для успешной работы LSTM выступают\n",
    "    * два гейта: выходной и забывающий\n",
    "    * «память» $c_t$ и константная ошибка, которая позволяет состоянию LSTM сохраняться надолго\n",
    "\n",
    "* Архитектура GRU использует идею совмещения выходного и забывающего гейта, а скрытое состояние $h_t$ совмещает со значением памяти $c_t$.\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/gru_1.png\" alt=\"\" style=\"width: 350px;\"/>\n",
    "    <b>Структура GRU</b> <br/>\n",
    "</center>\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/gru_2.png\" alt=\"\" style=\"width: 350px;\"/>\n",
    "    <b>Структура GRU</b> <br/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from argparse import Namespace\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from: https://trungtran.io/2019/02/08/text-generation-with-pytorch/\n",
    "\n",
    "# set parameters:\n",
    "\n",
    "# flags = Namespace(\n",
    "#     train_file='oliver.txt',\n",
    "#     seq_size=32,\n",
    "#     batch_size=16,\n",
    "#     embedding_size=64,\n",
    "#     lstm_size=64,\n",
    "#     gradients_norm=5,\n",
    "#     initial_words=['I', 'am'],\n",
    "#     predict_top_k=5,\n",
    "#     checkpoint_path='checkpoint',\n",
    "# )\n",
    "\n",
    "Flags = collections.namedtuple('Flags', 'train_file seq_size batch_size embedding_size lstm_size gradients_norm initial_words predict_top_k checkpoint_path learning_rate')\n",
    "# print with_class._fields\n",
    "\n",
    "flags = Flags(\n",
    "    train_file='AnnaKarenina__.txt',\n",
    "    seq_size=32,\n",
    "    batch_size=16,\n",
    "    embedding_size=64,\n",
    "    lstm_size=64,\n",
    "    gradients_norm=5,\n",
    "    initial_words=['Анна', 'не'],\n",
    "    predict_top_k=5,\n",
    "    checkpoint_path='checkpoint',\n",
    "    learning_rate = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_file(train_file, batch_size, seq_size):\n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    text = text.split()\n",
    "\n",
    "    word_counts = Counter(text)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {k: w for k, w in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
    "    n_vocab = len(int_to_vocab)\n",
    "\n",
    "    print('Vocabulary size', n_vocab)\n",
    "\n",
    "    int_text = [vocab_to_int[w] for w in text]\n",
    "    num_batches = int(len(int_text) / (seq_size * batch_size))\n",
    "    print(f'num_batches: {num_batches}')\n",
    "    in_text = int_text[:num_batches * batch_size * seq_size]\n",
    "    out_text = np.zeros_like(in_text)\n",
    "    out_text[:-1] = in_text[1:]\n",
    "    out_text[-1] = in_text[0]\n",
    "    in_text = np.reshape(in_text, (batch_size, -1))\n",
    "    out_text = np.reshape(out_text, (batch_size, -1))\n",
    "    return int_to_vocab, vocab_to_int, n_vocab, in_text, out_text\n",
    "\n",
    "# TODO: lower case ??\n",
    "# TODO: DataLoader ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(in_text, out_text, batch_size, seq_size):\n",
    "    num_batches = np.prod(in_text.shape) // (seq_size * batch_size)\n",
    "    for i in range(0, num_batches * seq_size, seq_size):\n",
    "        yield in_text[:, i:i+seq_size], out_text[:, i:i+seq_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "        return logits, state       \n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
    "                torch.zeros(1, batch_size, self.lstm_size))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Модель:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn.LSTM(*args, **kwargs)`\n",
    "\n",
    "Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.\n",
    "\n",
    "In a multilayer LSTM, the input $x^{(l)}_t$ of the l-th layer (l >= 2) is the hidden state $h^{(l-1)}_t$ of the previous layer multiplied by dropout $\\delta^{(l-1)}_t$ where each $\\delta^{(l-1)}_t$ is a Bernoulli random variable which is 0 with probability dropout.\n",
    "\n",
    "Shape:\n",
    "\n",
    "_Input:_\n",
    "* __input__ of shape (seq_len, batch, input_size): tensor containing the features of the input sequence.\n",
    "    * The input can also be a packed variable length sequence. \n",
    "* __h_0__ of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch.\n",
    "    * If the LSTM is bidirectional, num_directions should be 2, else it should be 1. \n",
    "* __c_0__ of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial cell state for each element in the batch.\n",
    "* _If (h_0, c_0) is not provided, both h_0 and c_0 default to zero_\n",
    "\n",
    "_Output:_\n",
    "* __output__ of shape (seq_len, batch, num_directions * hidden_size): tensor containing the output features (h_t) from the last layer of the LSTM, for each t. \n",
    "* __h_n__ of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len. \n",
    "* __c_n__ of shape (num_layers * num_directions, batch, hidden_size): tensor containing the cell state for t = seq_len.\n",
    "\n",
    "Parameters:\n",
    "* `input_size` – The number of expected features in the input x\n",
    "* `hidden_size` – The number of features in the hidden state h\n",
    "* `num_layers` – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two LSTMs together to form a stacked LSTM, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1\n",
    "* `bias` – If `False`, then the layer does not use bias weights b_ih and b_hh. Default: `True`\n",
    "* `batch_first` – If `True`, then the input and output tensors are provided as (batch, seq, feature). Default: `False`\n",
    "* `dropout` – If non-zero, introduces a Dropout layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to dropout. Default: 0\n",
    "* `bidirectional` – If True, becomes a bidirectional LSTM. Default: False\n",
    "* `proj_size` – If > 0, will use LSTM with projections of corresponding size. Default: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(device, model, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    model.eval()\n",
    "\n",
    "    state_h, state_c = model.zero_state(1)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    \n",
    "    for w in (w for wl in words for w in wl):\n",
    "        ix = torch.tensor([[vocab_to_int[w]]], dtype=torch.long).to(device)\n",
    "        output, (state_h, state_c) = model(ix, (state_h, state_c))\n",
    "    \n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "    \n",
    "    words_new = list()\n",
    "    words_new.append(int_to_vocab[choice])\n",
    "    \n",
    "    for _ in range(100):\n",
    "        ix = torch.tensor([[choice]], dtype=torch.long).to(device)\n",
    "        output, (state_h, state_c) = model(ix, (state_h, state_c))\n",
    "\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words_new.append(int_to_vocab[choice])\n",
    "\n",
    "    words.append(words_new)\n",
    "    \n",
    "    print('\\n\\n'.join(' '.join(s) for s in words))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_loss_and_train_op(model, lr=0.001):\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#     return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 55567\n",
      "num_batches: 576\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "int_to_vocab, vocab_to_int, n_vocab, in_text, out_text = get_data_from_file(\n",
    "    flags.train_file, flags.batch_size, flags.seq_size)\n",
    "\n",
    "model = RNNModule(n_vocab, flags.seq_size,\n",
    "                flags.embedding_size, flags.lstm_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=flags.learning_rate)\n",
    "\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'себе.'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_vocab[422]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основной цикл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/200 Iteration: 50 Loss: 8.648141860961914\n",
      "Epoch: 0/200 Iteration: 100 Loss: 8.640448570251465\n",
      "Epoch: 0/200 Iteration: 150 Loss: 8.291933059692383\n",
      "Epoch: 0/200 Iteration: 200 Loss: 7.8641743659973145\n",
      "Epoch: 0/200 Iteration: 250 Loss: 7.96994686126709\n",
      "Epoch: 0/200 Iteration: 300 Loss: 8.477243423461914\n",
      "Epoch: 0/200 Iteration: 350 Loss: 8.105463027954102\n",
      "Epoch: 0/200 Iteration: 400 Loss: 8.251829147338867\n",
      "Epoch: 0/200 Iteration: 450 Loss: 7.938296318054199\n",
      "Epoch: 0/200 Iteration: 500 Loss: 7.646656036376953\n",
      "Epoch: 0/200 Iteration: 550 Loss: 7.409121513366699\n",
      "Epoch: 1/200 Iteration: 600 Loss: 6.838401794433594\n",
      "Epoch: 1/200 Iteration: 650 Loss: 6.988497734069824\n",
      "Epoch: 1/200 Iteration: 700 Loss: 6.953343868255615\n",
      "Epoch: 1/200 Iteration: 750 Loss: 6.912400722503662\n",
      "Epoch: 1/200 Iteration: 800 Loss: 6.809935092926025\n",
      "Epoch: 1/200 Iteration: 850 Loss: 6.687542915344238\n",
      "Epoch: 1/200 Iteration: 900 Loss: 6.830479145050049\n",
      "Epoch: 1/200 Iteration: 950 Loss: 6.851489543914795\n",
      "Epoch: 1/200 Iteration: 1000 Loss: 7.043299674987793\n",
      "Анна не\n",
      "\n",
      "может любить с досадой о чем не может его понятию, не только с улыбкой с этим собою но не может быть были в Москве с ними не только с ним с ним к ней. В 1870 г. не только в одном и не только с княжной и, взяв в общем его лицо. Она и в том, как и что не может любить его с ним, в особенности на то, что, что он знал, чего же он мог было сказано. Он не может быть было бы ни было в конце и с профессором, как он мог понять этого Шталь на него, и\n",
      "Epoch: 1/200 Iteration: 1050 Loss: 6.787722110748291\n",
      "Epoch: 1/200 Iteration: 1100 Loss: 6.555397033691406\n",
      "Epoch: 1/200 Iteration: 1150 Loss: 6.443186283111572\n",
      "Epoch: 2/200 Iteration: 1200 Loss: 6.593853950500488\n",
      "Epoch: 2/200 Iteration: 1250 Loss: 6.161530017852783\n",
      "Epoch: 2/200 Iteration: 1300 Loss: 5.91005802154541\n",
      "Epoch: 2/200 Iteration: 1350 Loss: 5.7330851554870605\n",
      "Epoch: 2/200 Iteration: 1400 Loss: 5.688573837280273\n",
      "Epoch: 2/200 Iteration: 1450 Loss: 5.895025253295898\n",
      "Epoch: 2/200 Iteration: 1500 Loss: 5.564666748046875\n",
      "Epoch: 2/200 Iteration: 1550 Loss: 5.812206268310547\n",
      "Epoch: 2/200 Iteration: 1600 Loss: 5.705899238586426\n",
      "Epoch: 2/200 Iteration: 1650 Loss: 5.640429973602295\n",
      "Epoch: 2/200 Iteration: 1700 Loss: 5.670140266418457\n",
      "Epoch: 3/200 Iteration: 1750 Loss: 5.910702705383301\n",
      "Epoch: 3/200 Iteration: 1800 Loss: 5.528991222381592\n",
      "Epoch: 3/200 Iteration: 1850 Loss: 5.289751052856445\n",
      "Epoch: 3/200 Iteration: 1900 Loss: 5.102078914642334\n",
      "Epoch: 3/200 Iteration: 1950 Loss: 5.23981237411499\n",
      "Epoch: 3/200 Iteration: 2000 Loss: 5.028105735778809\n",
      "Анна не\n",
      "\n",
      "могла удержать того, чем прежде. – Я очень рада. А вот награда! Вы вам дать – Я пошлю к нему. – сказала она с тем выражением, в его вопрошающий руки и опять с страстным и он не может себе допытывать господин. Она была круглолицая, белокурая к этому семейству. Она хотела уйти, но не мог жить, как он в ее мужа… и с трудом удерживал было бы позорно было отречение от лестного с которою они мельком останавливались за чувством. Она не только с трудом удерживает на небо. и как ему казалось, что ему нужно было. – Да, да. Она кормит, – говорил\n",
      "Epoch: 3/200 Iteration: 2050 Loss: 4.944355487823486\n",
      "Epoch: 3/200 Iteration: 2100 Loss: 4.839357852935791\n",
      "Epoch: 3/200 Iteration: 2150 Loss: 4.719307899475098\n",
      "Epoch: 3/200 Iteration: 2200 Loss: 4.620072841644287\n",
      "Epoch: 3/200 Iteration: 2250 Loss: 4.938752174377441\n",
      "Epoch: 3/200 Iteration: 2300 Loss: 4.750027656555176\n",
      "Epoch: 4/200 Iteration: 2350 Loss: 5.197540283203125\n",
      "Epoch: 4/200 Iteration: 2400 Loss: 4.788362979888916\n",
      "Epoch: 4/200 Iteration: 2450 Loss: 4.52001428604126\n",
      "Epoch: 4/200 Iteration: 2500 Loss: 4.543013572692871\n",
      "Epoch: 4/200 Iteration: 2550 Loss: 4.484375953674316\n",
      "Epoch: 4/200 Iteration: 2600 Loss: 4.236880779266357\n",
      "Epoch: 4/200 Iteration: 2650 Loss: 4.316172122955322\n",
      "Epoch: 4/200 Iteration: 2700 Loss: 4.403216361999512\n",
      "Epoch: 4/200 Iteration: 2750 Loss: 4.340747833251953\n",
      "Epoch: 4/200 Iteration: 2800 Loss: 4.380462169647217\n",
      "Epoch: 4/200 Iteration: 2850 Loss: 4.184503555297852\n",
      "Epoch: 5/200 Iteration: 2900 Loss: 4.492158889770508\n",
      "Epoch: 5/200 Iteration: 2950 Loss: 4.339122772216797\n",
      "Epoch: 5/200 Iteration: 3000 Loss: 4.3169331550598145\n",
      "Анна не\n",
      "\n",
      "мог добиться. ему, как она отпускала его: и что это чувствовали. в церкви что-то особенное, на Таню, но теперь были из его телу. – Я не не знаю и я полагаю, я не могу быть иначе, как я еду? – сказал он все и что он хотел уйти, как бы я знаю, – сказала она. – Я очень рад, я могу понимать? и что исповедует ты понимаешь, как это эгоизм в счет, и потому я получу и что это было это понятно. Но ты мне опостылели в сад я не держу. Я хочу побыть на бильярде играет. Он опять налетала сначала.\n",
      "Epoch: 5/200 Iteration: 3050 Loss: 4.520609378814697\n",
      "Epoch: 5/200 Iteration: 3100 Loss: 4.173369884490967\n",
      "Epoch: 5/200 Iteration: 3150 Loss: 4.299257278442383\n",
      "Epoch: 5/200 Iteration: 3200 Loss: 4.084503650665283\n",
      "Epoch: 5/200 Iteration: 3250 Loss: 4.199499607086182\n",
      "Epoch: 5/200 Iteration: 3300 Loss: 3.986982583999634\n",
      "Epoch: 5/200 Iteration: 3350 Loss: 3.785687208175659\n",
      "Epoch: 5/200 Iteration: 3400 Loss: 4.10746955871582\n",
      "Epoch: 5/200 Iteration: 3450 Loss: 3.8839871883392334\n",
      "Epoch: 6/200 Iteration: 3500 Loss: 4.009751796722412\n",
      "Epoch: 6/200 Iteration: 3550 Loss: 4.090173721313477\n",
      "Epoch: 6/200 Iteration: 3600 Loss: 4.023983001708984\n",
      "Epoch: 6/200 Iteration: 3650 Loss: 4.015451908111572\n",
      "Epoch: 6/200 Iteration: 3700 Loss: 4.081826686859131\n",
      "Epoch: 6/200 Iteration: 3750 Loss: 3.9443953037261963\n",
      "Epoch: 6/200 Iteration: 3800 Loss: 3.9709174633026123\n",
      "Epoch: 6/200 Iteration: 3850 Loss: 3.6466031074523926\n",
      "Epoch: 6/200 Iteration: 3900 Loss: 3.8154122829437256\n",
      "Epoch: 6/200 Iteration: 3950 Loss: 3.7302956581115723\n",
      "Epoch: 6/200 Iteration: 4000 Loss: 3.520392894744873\n",
      "Анна не\n",
      "\n",
      "могла найти лучше». против иноземного молока, скорым Это была неведающая, испорченная, и потому разгорячился в корпусе, – Я думаю, по-моему, – сказал Катавасов. Она испытывала с слез. Она видела, чтó она не только ждала, и в корпусе, – Да вот и вы не нашли? А эта бессмысленная вас и не могу быть спокоен, но я очень понравился горю. Так – прибавил он, – сказала Анна, сощурив глаза блестели, – сказала княгиня. – Нет, как это будет хорошая. и что он плох, и вы не видали хорошенько, мне быть у него в воде; не было продолжать жить в том, я все равно\n",
      "Epoch: 7/200 Iteration: 4050 Loss: 3.6089231967926025\n",
      "Epoch: 7/200 Iteration: 4100 Loss: 3.82481050491333\n",
      "Epoch: 7/200 Iteration: 4150 Loss: 3.9389851093292236\n",
      "Epoch: 7/200 Iteration: 4200 Loss: 3.95443058013916\n",
      "Epoch: 7/200 Iteration: 4250 Loss: 3.8166093826293945\n",
      "Epoch: 7/200 Iteration: 4300 Loss: 3.7950515747070312\n",
      "Epoch: 7/200 Iteration: 4350 Loss: 3.548967123031616\n",
      "Epoch: 7/200 Iteration: 4400 Loss: 3.528337001800537\n",
      "Epoch: 7/200 Iteration: 4450 Loss: 3.470827579498291\n",
      "Epoch: 7/200 Iteration: 4500 Loss: 3.2781083583831787\n",
      "Epoch: 7/200 Iteration: 4550 Loss: 3.541041851043701\n",
      "Epoch: 7/200 Iteration: 4600 Loss: 3.4364657402038574\n",
      "Epoch: 8/200 Iteration: 4650 Loss: 3.6090986728668213\n",
      "Epoch: 8/200 Iteration: 4700 Loss: 3.7142229080200195\n",
      "Epoch: 8/200 Iteration: 4750 Loss: 3.4267749786376953\n",
      "Epoch: 8/200 Iteration: 4800 Loss: 3.8408362865448\n",
      "Epoch: 8/200 Iteration: 4850 Loss: 3.754572629928589\n",
      "Epoch: 8/200 Iteration: 4900 Loss: 3.569748640060425\n",
      "Epoch: 8/200 Iteration: 4950 Loss: 3.455475330352783\n",
      "Epoch: 8/200 Iteration: 5000 Loss: 3.581632137298584\n",
      "Анна не\n",
      "\n",
      "знала, чтó он знал, что он чувствует себя в своей воздух и все более Лидии Ивановне, но зато и что не могли не обидеть тех, по мере все надежды к нему радости. – Но я знаю, но зато по возвращении с места и вытянула белые собиравшиеся в тарантас, и, скашивая свой угол и «Русском вестнике» Перед летками полной высшей бедности около Там у Петровых? Ведь сохой была хороша, кто лучше охоты, и он не был не мог быть сын; ни в гостиных, приличия, где они были довольны, не образован, здоров, дочерьми. С такими что она поедет, а приготовлением в религии была\n",
      "Epoch: 8/200 Iteration: 5050 Loss: 3.4064903259277344\n",
      "Epoch: 8/200 Iteration: 5100 Loss: 3.072573184967041\n",
      "Epoch: 8/200 Iteration: 5150 Loss: 3.125408887863159\n",
      "Epoch: 9/200 Iteration: 5200 Loss: 3.2205440998077393\n",
      "Epoch: 9/200 Iteration: 5250 Loss: 3.5297653675079346\n",
      "Epoch: 9/200 Iteration: 5300 Loss: 3.6564531326293945\n",
      "Epoch: 9/200 Iteration: 5350 Loss: 3.4664039611816406\n",
      "Epoch: 9/200 Iteration: 5400 Loss: 3.5157501697540283\n",
      "Epoch: 9/200 Iteration: 5450 Loss: 3.59956693649292\n",
      "Epoch: 9/200 Iteration: 5500 Loss: 3.183241128921509\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-146-769d220b215e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# Perform back-propagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# gradient clipping:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyTorch_1_6\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyTorch_1_6\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(50):\n",
    "    batches = get_batches(in_text, out_text, flags.batch_size, flags.seq_size)\n",
    "    state_h, state_c = model.zero_state(flags.batch_size)        \n",
    "    \n",
    "    # Transfer data to device (GPU)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device) \n",
    "    \n",
    "    for x, y in batches:\n",
    "#         print(type(x), x.shape, x)\n",
    "        iteration += 1\n",
    "\n",
    "        # Tell it we are in training mode\n",
    "        model.train()\n",
    "\n",
    "        # Reset all gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Transfer data to GPU\n",
    "        x = torch.tensor(x, dtype=torch.long).to(device)\n",
    "        y = torch.tensor(y, dtype=torch.long).to(device)\n",
    "\n",
    "        logits, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "        loss = criterion(logits.transpose(1, 2), y)\n",
    "\n",
    "        state_h = state_h.detach()\n",
    "        state_c = state_c.detach()\n",
    "\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        # Perform back-propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient clipping:   \n",
    "        _ = torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), flags.gradients_norm)        \n",
    "\n",
    "        # Update the network's parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print the loss value:\n",
    "        if iteration % 50 == 0:\n",
    "            print('Epoch: {}/{}'.format(e, 200),\n",
    "                  'Iteration: {}'.format(iteration),\n",
    "                  'Loss: {}'.format(loss_value))\n",
    "\n",
    "        if iteration % 1000 == 0:\n",
    "            predict(device, model, [flags.initial_words], n_vocab,\n",
    "                    vocab_to_int, int_to_vocab, top_k=5)\n",
    "#             torch.save(model.state_dict(),\n",
    "#                        'checkpoint_pt/model-{}.pth'.format(iteration))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-730c51b3e7e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch_1_5v2",
   "language": "python",
   "name": "pytorch_1_5v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
