{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 6: Рекуррентные нейронные сети RNN  (Recurrent Neural Networks)\n",
    "\n",
    "__Автор: Сергей Вячеславович Макрушин__ e-mail: SVMakrushin@fa.ru \n",
    "\n",
    "Финансовый универсиет, 2021 г. \n",
    "\n",
    "При подготовке лекции использованы материалы:\n",
    "* ...\n",
    "\n",
    "v 0.1 15.04.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделы: <a class=\"anchor\" id=\"разделы\"></a>\n",
    "* [Загрузка и преобразование данных](#загрузка)\n",
    "* [Нормализация](#нормализация)\n",
    "* [Оценка качества моделей](#качество)\n",
    "* [Решение задачи двухклассовой классификации](#двухклассовая)\n",
    "    * [Создание тензоров](#создание-тензоров)\n",
    "    * [Операции с тензорами](#операции-тензоры)    \n",
    "        * [Арифметические операции и математические функции:](#aрифметические)        \n",
    "        * [Операции, изменяющие размер тензора](#размер)        \n",
    "        * [Операции агрегации](#агрегации)        \n",
    "        * [Матричные операции](#aрифметические)                \n",
    "-\n",
    "\n",
    "* [к оглавлению](#разделы)\n",
    "\n",
    "---\n",
    "## Нормализация <a class=\"anchor\" id=\"нормализация\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "﻿<style>\r\n",
       "\r\n",
       "\r\n",
       "b.n {\r\n",
       "    font-weight: normal;        \r\n",
       "}\r\n",
       "\r\n",
       "b.grbg {\r\n",
       "    background-color: #a0a0a0;      \r\n",
       "}\r\n",
       "\r\n",
       "b.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "b.b {    \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "b.g {\r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "// add your CSS styling here\r\n",
       "\r\n",
       "list-style: none;\r\n",
       "\r\n",
       "ul.s {\r\n",
       "//    list-style-type: none;\r\n",
       "    list-style: none;\r\n",
       "//    background-color: #ff0000;  \r\n",
       "//    color: #ffff00;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;\r\n",
       "}\r\n",
       "\r\n",
       "li.t {\r\n",
       "    list-style: none;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "*.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "li.t:before {\r\n",
       "    content: \"\\21D2\";    \r\n",
       "//    content: \"►\";\r\n",
       "//    padding-left: -1.2em;    \r\n",
       "    text-indent: -1.2em;    \r\n",
       "    display: block;\r\n",
       "    float: left;\r\n",
       "    \r\n",
       "    \r\n",
       "//    width: 1.2em;\r\n",
       "//    color: #ff0000;\r\n",
       "}\r\n",
       "\r\n",
       "i.m:before {\r\n",
       "    font-style: normal;    \r\n",
       "    content: \"\\21D2\";  \r\n",
       "}\r\n",
       "i.m {\r\n",
       "    font-style: normal; \r\n",
       "}    \r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "/* em {\r\n",
       "    font-style: normal; \r\n",
       "} */\r\n",
       "\r\n",
       "\r\n",
       "em.bl {\r\n",
       "    font-style: normal;     \r\n",
       "    font-weight: bold;        \r\n",
       "}\r\n",
       "\r\n",
       "/* em.grbg {\r\n",
       "    font-style: normal;         \r\n",
       "    background-color: #a0a0a0;      \r\n",
       "} */\r\n",
       "\r\n",
       "em.cr {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cb {    \r\n",
       "    font-style: normal;         \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cg {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "\r\n",
       "em.qs {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.qs::before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #ff0000;    \r\n",
       "    content: \"Q:\";  \r\n",
       "}\r\n",
       "\r\n",
       "em.an {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.an:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"A:\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.nt {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.nt:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Note:\";  \r\n",
       "}    \r\n",
       "    \r\n",
       "em.ex {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.ex:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #00ff00;    \r\n",
       "    content: \"Ex:\";  \r\n",
       "} \r\n",
       "    \r\n",
       "em.df {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.df:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Def:\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.pl {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.pl:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"+\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.mn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.mn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"-\";  \r\n",
       "}        \r\n",
       "\r\n",
       "em.plmn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.plmn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\00B1\";\\\\\"&plusmn;\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.hn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.hn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\21D2\";\\\\\"&rArr;\";  \r\n",
       "}     \r\n",
       "    \r\n",
       "\r\n",
       "#cssTableCenter td, th \r\n",
       "{\r\n",
       "    text-align: center; \r\n",
       "    vertical-align: middle;\r\n",
       "}\r\n",
       "\r\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем стиль для оформления презентации\n",
    "from IPython.display import HTML\n",
    "from urllib.request import urlopen\n",
    "html = urlopen(\"file:./lec_v2.css\")\n",
    "HTML(html.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Введение <a class=\"anchor\" id=\"установка\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Мотивация для использования рекуррентных нейронных сетей__\n",
    "\n",
    "* Не рекуррентные архитектуры ИНС получают на вход вектор данных и пытаются по нему предсказать тот или иной результат (минимизировать ошибку). \n",
    "* Важно, что входной (и выходной) вектор должен __иметь одну и ту же размерность__. Во многих задачах это не так.\n",
    "\n",
    "<br/>\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_1.png\" alt=\"\" style=\"width: 800px;\"/>\n",
    "    <b>Задачи с последовательностями</b> <br/>\n",
    "    Каждый прямоугольник представляет собой вектор, а стрелки представляют функции (например, умножение матриц). Входные векторы показаны красным, выходные векторы - синим, а зеленые векторы содержат состояние RNN.    \n",
    "</center>\n",
    "\n",
    "1. один вход, один выход (классический случай)\n",
    "* один вход, последовательность выходов\n",
    "* последовательность входов, один выход\n",
    "* последовательность входов, затем последовательность выходов\n",
    "* синхронизированные последовательности входов и выходов    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Рекуррентная нейронная сеть (RNN)__\n",
    "\n",
    "<em class=\"df\"></em> __Рекуррентная нейронная сеть (RNN)__ - это класс искусственных нейронных сетей, в которых узел может получать входы не только от других узлов и текущих входных данных но и выходы узлов, полученные при рассмотрении предыдущих входных данных последовательности.\n",
    "* обмен вектором внутреннего сосотояния, полученного на предыдущем шаге, позволяет использовать информацию о предыдущих шагах, которые сеть уже обработала\n",
    "* при рассмотрении всей последовательности веса каждого узла одни и те же при рассмотрении всех входных данных последовательности\n",
    "\n",
    "\n",
    "* Ткая архитектура сети позволяет обрабатывать серии событий во времени или последовательные пространственные цепочки произвольной размерности\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_3.png\" alt=\"\" style=\"width: 700px;\"/>\n",
    "    <b>Принцип устройства узла RNN</b> <br/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трудность рекуррентной сети:\n",
    "* если учитывать каждый шаг времени, то становится необходимым для каждого шага времени (последовательности) создавать свой слой нейронов, что создает серьёзные вычислительные сложности\n",
    "* многослойные реализации вычислительно неустойчивы: в них как правило либо исчезают либо зашкаливают веса\n",
    "* если ограничить расчёт фиксированным временным окном, то полученные модели не будут отражать долгосрочных трендов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>         \n",
    "    <img src=\"./img/rnn_2.png\" alt=\"\" style=\"width: 200px;\"/>\n",
    "    <b>Распространение ошибок в узле RNN</b> <br/>\n",
    "</center>\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_5.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "    <b>Распространение ошибок в узле RNN</b> <br/>\n",
    "</center>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<center>         \n",
    "    <img src=\"./img/tmp1.png\" alt=\"\" style=\"width: 600px;\"/>\n",
    "    <b>237-238</b> <br/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Распространение ошибки в архитектуре RNN__\n",
    "\n",
    "* В прямой нейронной сети ошибка на конкретном нейроне вычисляется как функция от ошибок нейронов, которые используют его выходное значение <em class=\"hn\"></em> формируется ациклический графы вычислений:\n",
    "\n",
    "<center> \n",
    "    <img src=\"./img/ann_19.png\" alt=\"Прямой и обратный проход \" style=\"width: 300px;\"/>\n",
    "    <b>Прямой и обратный проход процедуры обучения многослойной ИНС </b> <br/>    \n",
    "</center>\n",
    "\n",
    "* В архитектуре RNN нейрон принимает в качестве входа результат вычисления в нем самом (через вектор состояния)\n",
    "    * Важно понимать, что при этом петли в графе вычислений не образуется \n",
    "    * Вычисления, которые делает рекуррентная сеть, можно развернуть обратно до начала обрабатываемой последовательности\n",
    "    * Можно сказать, что на каждом шаге обрабатываемой последовательности сеть создает копии самой себя\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_3.png\" alt=\"\" style=\"width: 700px;\"/>\n",
    "    <b>Принцип устройства узла RNN </b> <br/>\n",
    "</center>\n",
    "\n",
    "* И на каждом последовательности мы фактически обучаем глубокую нейронную сеть, в которой столько слоев, сколько элементов в последовательности на данный момент мы уже видели\n",
    "* Рекуррентная сеть — разворчиватся вдоль элементов последовательности $1 \\dotsc T$ в очень-очень многоуровневую обычную сеть, в которой одни и те же веса переиспользуются на каждом уровне. \n",
    "    * <em class=\"pl\"></em> Для хранения весов достаточно одной матрицы\n",
    "    * <em class=\"pl\"></em> Градиенты по весам не затухают до нуля сразу же (как это бывает в обычных глубких сетях)\n",
    "    * <em class=\"mn\"></em> Если матрица весов меняет норму вектора градиента при проходе через один «слой» обратного распространения, то при проходе через T слоев эта норма изменяется экспоненциально (т.к. веса матрицы одни и те же) это приводит:\n",
    "        * к __\"взрыу градиентов\"__ (exploding gradients), если матрица заметно увеличивает норму вектора градиента\n",
    "        * к экспоненациональному затуханию градиентов (Vanishing gradients), если матрица заметно уменьшает норму вектора градиента\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_4.png\" alt=\"\" style=\"width: 500px;\"/>\n",
    "    <b>Распространение ошибок в узле RNN</b> <br/>\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Построение многослойных нейронных сетей на базе архитектуры RNN__\n",
    "\n",
    "\n",
    "* Рассмотрим всю рекуррентную сеть как слой и используем ее выходы как входы для следующего рекуррентного слоя.\n",
    "* Мотивация: каждый слой действует в своем собственном «масштабе времени», примерно как каждый слой сверточной сети действует в своем масштабе, на свой размер окна входов. \n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_7.png\" alt=\"\" style=\"width: 500px;\"/>\n",
    "    <b>Распространение ошибок в узле RNN</b> <br/>\n",
    "</center>\n",
    "\n",
    "\n",
    "__Двунаправленные рекуррентные сети__ (bidirectional RNN): для входной последовательности запустим RNN (обычно с разными весами) два раза: один слой будет __читать последовательность слева направо__, а другой — __справа налево__\n",
    "\n",
    "* Матрицы весов для двух направлений абсолютно независимы и между ними нет взаимодействия\n",
    "* Ограничение: данный подход возможен только для последовательностей, которые даны сразу целиком (например для предложений естественного языка).\n",
    "* Мотивация в том, чтобы получить состояние, отражающее контекст и слева, и справа для каждого элемента последовательности (например для отнесения слова к части речи т.к. важно анализировать все предложение, и слева, и справа от слова)\n",
    "* Вместо классической рекуррентной сети из трех матриц, может использоваться любая другая конструкция, например LSTM или GRU.\n",
    "    \n",
    "<center>         \n",
    "    <img src=\"./img/rnn_6.png\" alt=\"\" style=\"width: 500px;\"/>\n",
    "    <b>Распространение ошибок в узле RNN</b> <br/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LSTM__\n",
    "\n",
    "LSTM (Long Short-Term Memory) \n",
    "\n",
    "* обычные рекуррентные сети очень плохо справляются с ситуациями, когда нужно что-то «запомнить» надолго: влияние скрытого состояния или входа с шага t на последующие состояния рекуррентной сети экспоненциально затухает\n",
    "* LSTM хорошо приспособлена к обучению на задачах классификации, обработки и прогнозирования временных рядов в случаях, когда важные события разделены временными лагами с неопределённой продолжительностью и границами\n",
    "\n",
    "* вместо одного-единственного числа, на которое влияют все последующие состояния, используется специального вида ячейка моделирующая \"долгую память\"\n",
    "    * LSTM моделирует процессы записи и чтения из этой \"ячейки памяти\" \n",
    "    * у ячейки не один набор весов, как у обычного нейрона, а сразу несколько\n",
    "\n",
    "В LSTM есть три основных вида узлов, которые называются гейтами:\n",
    "* входной (input gate)\n",
    "* забывающий (forget gate)\n",
    "* выходной (output gate)\n",
    "* рекуррентная ячейка со скрытым состоянием\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_8.png\" alt=\"\" style=\"width: 350px;\"/>\n",
    "    <b>Структура LSTM</b> <br/>\n",
    "</center>\n",
    "\n",
    "Переменные:\n",
    "* $x_t$ — входной вектор во время t\n",
    "* $h_t$ — вектор скрытого состояния во время t\n",
    "* $c_t$ — вектор ячейки состояния во время t\n",
    "* $W_i$ — матрицы весов, применяющиеся ко входу\n",
    "* $W_h$ — матрицы весов, в рекуррентных соединениях; b - векторы свободных членов\n",
    "\n",
    "* candidate cell state: $c_t^{'}= \\tanh (W_{xc}x_t + W_{hc}h_{t-1}+b_{c^{'}})$\n",
    "* input gate: $i_t=\\sigma (W_{xi}x_t + W_{hi}h_{t-1}+b_{i})$\n",
    "* forget gate: $f_t=\\sigma (W_{xf}x_t + W_{hf}h_{t-1}+b_{f})$\n",
    "* output gate: $o_t=\\sigma (W_{xo}x_t + W_{ho}h_{t-1}+b_{o})$\n",
    "* cell state: $c_t=f_t \\odot c_{t-1} + i_t \\odot c_t^{'}$\n",
    "* block output: $h_t=o_t \\odot \\tanh (c_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Специфика ячейки памяти в LSTM__\n",
    "\n",
    "* Вход в LSTM:\n",
    "    * входные данные $x_t$\n",
    "    * скрытое состояние $h_{t-1}$\n",
    "    * вектор \"ячейки памяти\" (cell) $c_t$:\n",
    "        \n",
    "* Кандидат на новое значение памяти, полученный из входа и предыдущего скрытого состояния вектор: $c_t^{'}$ \n",
    "$$c_t=f_t \\odot c_{t-1} + i_t \\odot c_t^{'}$$\n",
    "\n",
    "* Новое значение $c_t$ получается как линейная комбинация из старого с коэффициентами из забывающего гейта $f_t$ и нового кандидата $c_t^{'}$ с коэффициентами из входного гейта $i_t$.\n",
    "* Покомпонентное умножение приводит к тому, что на очередном шаге может быть перезаписана только часть \"памяти\" LSTM-ячейки и какая это будет часть, тоже определяет сама ячейка.\n",
    "    * LSTM-ячейка может не просто выбрать, записать новое значение или выкинуть его, а еще и сохранить любую линейную комбинацию старого и нового значения, причем коэффициенты могут быть разными в разных компонентах вектора.\n",
    "    * Решения ячейка принимает в зависимости от конкретного входа.\n",
    "\n",
    "Так распространяется градиент ошибки для $c_t$, если рассматривать ее без забывающего гейта:\n",
    "$$\\frac{\\partial c_t}{\\partial c_{t-1}}=1$$\n",
    "\n",
    "* в рекурсивном вычислении состояния ячейки нет никакой нелинейности: т.е. ошибки в сети из LSTM пропагируются без изменений, и скрытые состояния LSTM могут, если сама ячейка не решит их перезаписать, сохранять свои значения неограниченно долго\n",
    "* __Важно__: хотя обычно веса нейронной сети инициализируются маленькими случайными числами свободный член забывающего гейта $b_f$\n",
    "    * все LSTM-ячейки изначально будут иметь значение $f_t$ около 1/2\n",
    "    * ошибки и память будут затухать экспоненциально. Поэтому свободный член $b_f$ нужно инициализировать большими значениями, около 1 или даже 2: тогда значения забывающих гейтов ft в начале обучения будут близки к нулю и градиенты будут свободно распространяться вдоль всей последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует много разных вариантов LSTM: \n",
    "*\n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from argparse import Namespace\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from: https://trungtran.io/2019/02/08/text-generation-with-pytorch/\n",
    "\n",
    "# set parameters:\n",
    "\n",
    "# flags = Namespace(\n",
    "#     train_file='oliver.txt',\n",
    "#     seq_size=32,\n",
    "#     batch_size=16,\n",
    "#     embedding_size=64,\n",
    "#     lstm_size=64,\n",
    "#     gradients_norm=5,\n",
    "#     initial_words=['I', 'am'],\n",
    "#     predict_top_k=5,\n",
    "#     checkpoint_path='checkpoint',\n",
    "# )\n",
    "\n",
    "Flags = collections.namedtuple('Flags', 'train_file seq_size batch_size embedding_size lstm_size gradients_norm initial_words predict_top_k checkpoint_path learning_rate')\n",
    "# print with_class._fields\n",
    "\n",
    "flags = Flags(\n",
    "    train_file='oliver.txt',\n",
    "    seq_size=32,\n",
    "    batch_size=16,\n",
    "    embedding_size=64,\n",
    "    lstm_size=64,\n",
    "    gradients_norm=5,\n",
    "    initial_words=['I', 'am'],\n",
    "    predict_top_k=5,\n",
    "    checkpoint_path='checkpoint',\n",
    "    learning_rate = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_file(train_file, batch_size, seq_size):\n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    text = text.split()\n",
    "\n",
    "    word_counts = Counter(text)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {k: w for k, w in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {w: k for k, w in int_to_vocab.items()}\n",
    "    n_vocab = len(int_to_vocab)\n",
    "\n",
    "    print('Vocabulary size', n_vocab)\n",
    "\n",
    "    int_text = [vocab_to_int[w] for w in text]\n",
    "    num_batches = int(len(int_text) / (seq_size * batch_size))\n",
    "    print(f'num_batches: {num_batches}')\n",
    "    in_text = int_text[:num_batches * batch_size * seq_size]\n",
    "    out_text = np.zeros_like(in_text)\n",
    "    out_text[:-1] = in_text[1:]\n",
    "    out_text[-1] = in_text[0]\n",
    "    in_text = np.reshape(in_text, (batch_size, -1))\n",
    "    out_text = np.reshape(out_text, (batch_size, -1))\n",
    "    return int_to_vocab, vocab_to_int, n_vocab, in_text, out_text\n",
    "\n",
    "# TODO: lower case ??\n",
    "# TODO: DataLoader ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(in_text, out_text, batch_size, seq_size):\n",
    "    num_batches = np.prod(in_text.shape) // (seq_size * batch_size)\n",
    "    for i in range(0, num_batches * seq_size, seq_size):\n",
    "        yield in_text[:, i:i+seq_size], out_text[:, i:i+seq_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    def __init__(self, n_vocab, seq_size, embedding_size, lstm_size):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "        return logits, state       \n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
    "                torch.zeros(1, batch_size, self.lstm_size))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_loss_and_train_op(model, lr=0.001):\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#     return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size 21659\n",
      "num_batches: 314\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu' # torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "int_to_vocab, vocab_to_int, n_vocab, in_text, out_text = get_data_from_file(\n",
    "    flags.train_file, flags.batch_size, flags.seq_size)\n",
    "\n",
    "model = RNNModule(n_vocab, flags.seq_size,\n",
    "                flags.embedding_size, flags.lstm_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=flags.learning_rate)\n",
    "\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Giles'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_vocab[422]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основной цикл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/200 Iteration: 50 Loss: 7.711149215698242\n",
      "Epoch: 0/200 Iteration: 100 Loss: 7.362364768981934\n",
      "Epoch: 0/200 Iteration: 150 Loss: 7.203067302703857\n",
      "Epoch: 0/200 Iteration: 200 Loss: 7.024230480194092\n",
      "Epoch: 0/200 Iteration: 250 Loss: 6.796504020690918\n",
      "Epoch: 0/200 Iteration: 300 Loss: 7.2662577629089355\n",
      "Epoch: 1/200 Iteration: 350 Loss: 6.4740142822265625\n",
      "Epoch: 1/200 Iteration: 400 Loss: 6.523726463317871\n",
      "Epoch: 1/200 Iteration: 450 Loss: 6.059981822967529\n",
      "Epoch: 1/200 Iteration: 500 Loss: 6.266263484954834\n",
      "Epoch: 1/200 Iteration: 550 Loss: 5.959191799163818\n",
      "Epoch: 1/200 Iteration: 600 Loss: 5.892782211303711\n",
      "Epoch: 2/200 Iteration: 650 Loss: 5.845761299133301\n",
      "Epoch: 2/200 Iteration: 700 Loss: 5.750696182250977\n",
      "Epoch: 2/200 Iteration: 750 Loss: 5.695406913757324\n",
      "Epoch: 2/200 Iteration: 800 Loss: 5.675263404846191\n",
      "Epoch: 2/200 Iteration: 850 Loss: 5.298869609832764\n",
      "Epoch: 2/200 Iteration: 900 Loss: 5.287508487701416\n",
      "Epoch: 3/200 Iteration: 950 Loss: 5.22512149810791\n",
      "Epoch: 3/200 Iteration: 1000 Loss: 5.225240707397461\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict() got an unexpected keyword argument 'top_k'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-240-1cc0b9af9147>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             predict(device, model, flags.initial_words, n_vocab,\n\u001b[1;32m---> 49\u001b[1;33m                     vocab_to_int, int_to_vocab, top_k=5)\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;31m#             torch.save(model.state_dict(),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m#                        'checkpoint_pt/model-{}.pth'.format(iteration))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'top_k'"
     ]
    }
   ],
   "source": [
    "for e in range(50):\n",
    "    batches = get_batches(in_text, out_text, flags.batch_size, flags.seq_size)\n",
    "    state_h, state_c = model.zero_state(flags.batch_size)        \n",
    "    \n",
    "    # Transfer data to device (GPU)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device) \n",
    "    \n",
    "    for x, y in batches:\n",
    "#         print(type(x), x.shape, x)\n",
    "        iteration += 1\n",
    "\n",
    "        # Tell it we are in training mode\n",
    "        model.train()\n",
    "\n",
    "        # Reset all gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Transfer data to GPU\n",
    "        x = torch.tensor(x, dtype=torch.long).to(device)\n",
    "        y = torch.tensor(y, dtype=torch.long).to(device)\n",
    "\n",
    "        logits, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "        loss = criterion(logits.transpose(1, 2), y)\n",
    "\n",
    "        state_h = state_h.detach()\n",
    "        state_c = state_c.detach()\n",
    "\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        # Perform back-propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient clipping:   \n",
    "        _ = torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), flags.gradients_norm)        \n",
    "\n",
    "        # Update the network's parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print the loss value:\n",
    "        if iteration % 50 == 0:\n",
    "            print('Epoch: {}/{}'.format(e, 200),\n",
    "                  'Iteration: {}'.format(iteration),\n",
    "                  'Loss: {}'.format(loss_value))\n",
    "\n",
    "        if iteration % 1000 == 0:\n",
    "            predict(device, model, flags.initial_words, n_vocab,\n",
    "                    vocab_to_int, int_to_vocab, top_k=5)\n",
    "#             torch.save(model.state_dict(),\n",
    "#                        'checkpoint_pt/model-{}.pth'.format(iteration))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(device, model, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    model.eval()\n",
    "\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]]).to(device)\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "    \n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    ix = torch.tensor([[choice]]).to(device)\n",
    "    output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "    words.append(int_to_vocab[choice])\n",
    "\n",
    "print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        , который становится .\n",
    "* \n",
    "* 123\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* <math>W</math>, <math>U</math> и <math>b</math> — матрицы параметров и вектор,\n",
    "* <math>f_t</math>, <math>i_t</math> и <math>o_t</math> — векторы вентилей,\n",
    "** <math>f_t</math> — вектор вентиля забывания, вес запоминания старой информации,\n",
    "** <math>i_t</math> — вектор входного вентиля, вес получения новой информации,\n",
    "** <math>o_t</math> — вектор выходного вентиля, кандидат на выход.\n",
    "\n",
    "\n",
    " <math>c_0 = 0</math> и <math>h_0 = 0</math> (<math>\\circ</math> обозначает [[произведение Адамара]]):\n",
    ": <math>\n",
    "\\begin{align}\n",
    "f_t &= \\sigma_g(W_{f} x_t + U_{f} h_{t-1} + b_f) \\\\\n",
    "i_t &= \\sigma_g(W_{i} x_t + U_{i} h_{t-1} + b_i) \\\\\n",
    "o_t &= \\sigma_g(W_{o} x_t + U_{o} h_{t-1} + b_o) \\\\\n",
    "c_t &= f_t \\circ c_{t-1} + i_t \\circ \\sigma_c(W_{c} x_t + U_{c} h_{t-1} + b_c) \\\\\n",
    "h_t &= o_t \\circ \\sigma_h(c_t)\n",
    "\\end{align}\n",
    "</math>\n",
    "\n",
    "\n",
    "\n",
    "[[Функция активации|Функции активации]]:\n",
    "* <math>\\sigma_g</math>: на основе [[Сигмоида|сигмоиды]].\n",
    "* <math>\\sigma_c</math>: на основе [[Гиперболический тангенс|гиперболического тангенса]].\n",
    "* <math>\\sigma_h</math>: на основе гиперболического тангенса, но в работе о глазках (смотровых отверстиях) для LSTM предполагается, что <math>\\sigma_h(x) = x</math>.<ref name=\"peepholeLSTM\"/><ref name=\"peephole2002\"/>\n",
    "\n",
    "\n",
    "\n",
    "хорошо приспособлена к обучению на задачах классификации, обработки и прогнозирования временных рядов в случаях, когда важные события разделены временными лагами с неопределённой продолжительностью и границами. Относительная невосприимчивость к длительности временных разрывов даёт LSTM преимущество по отношению к альтернативным рекуррентным нейронным сетям, скрытым марковским моделям и другим методам обучения для последовательностей в различных сферах применения\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/rnn_6.png\" alt=\"\" style=\"width: 500px;\"/>\n",
    "    <b>Распространение ошибок в узле RNN</b> <br/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "хорошо, если бы \n",
    "\n",
    "нейронная сеть могла запоминать что-то из истории приходящих на вход данных, сохранять некое внутреннее состояние, которое можно было бы потом использовать для предсказания будущих элементов последовательности\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Эмбеддинг (embedding) ~ векторное представление_\n",
    "\n",
    "\n",
    "\n",
    "связи между элементами образуют направленную последовательность.\n",
    "\n",
    "в которых соединения между узлами образуют ориентированный граф во временной последовательности.\n",
    "\n",
    "Благодаря этому появляется возможность обрабатывать серии событий во времени или последовательные пространственные цепочки.\n",
    "* В отличие от многослойных перцептронов, рекуррентные сети могут использовать свою __внутреннюю память__ для обработки последовательностей произвольной длины. \n",
    "\n",
    "\n",
    "Если схематично, слой RNN использует цикл for для итерации по упорядоченной по времени последовательности, храня при этом во внутреннем состоянии, закодированную информацию о шагах, которые он уже видел.\n",
    "\n",
    "Рекуррентная нейронная сеть - это тип нейронной сети глубокого обучения, которая запоминает входную последовательность, сохраняет ее в состояниях памяти / состояниях ячеек и предсказывает будущие слова / предложения.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "это класс искусственных нейронных сетей, в которых соединения между узлами образуют ориентированный граф во временной последовательности. Это позволяет ему демонстрировать динамическое поведение во времени. Полученные из нейронных сетей прямого распространения, RNN могут использовать свое внутреннее состояние (память) для обработки последовательностей входных данных переменной длины.\n",
    "\n",
    "вид нейронных сетей, где связи между элементами образуют направленную последовательность. Благодаря этому появляется возможность обрабатывать серии событий во времени или последовательные пространственные цепочки. В отличие от многослойных перцептронов, рекуррентные сети могут использовать свою внутреннюю память для обработки последовательностей произвольной длины. \n",
    "\n",
    "\n",
    "<b class=\"b\">Problem:</b> Решение задачи машинного обучения (с учителем) требует конструирования признаков для каждой конкретной задачи!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трудность рекуррентной сети заключается в том, что если учитывать каждый шаг времени, то становится необходимым для каждого шага времени создавать свой слой нейронов, что вызывает серьёзные вычислительные сложности. Кроме того, многослойные реализации оказываются вычислительно неустойчивыми, так как в них как правило исчезают или зашкаливают веса. Если ограничить расчёт фиксированным временным окном, то полученные модели не будут отражать долгосрочных трендов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты:\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Входные данные:\n",
    "\n",
    "text = ['hey how are you','good i am fine','have a nice day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('name2.csv', encoding='cp1251') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)    \n",
    "    text = list(n[0].lower() for n in csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['агафья', 'аглая', 'агния']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодировка символов числами:\n",
    "\n",
    "# Join all the sentences together and extract the unique characters from the combined sentences\n",
    "chars = set(''.join(text)+' ')\n",
    "\n",
    "# Creating a dictionary that maps integers to the characters\n",
    "int2char = dict(enumerate(chars))\n",
    "\n",
    "# Creating another dictionary that maps characters to integers\n",
    "char2int = {char: ind for ind, char in int2char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'о': 0, 'з': 1, 'л': 2, 'ё': 3, 'я': 4, 'а': 5, 'м': 6, 'б': 7, 'г': 8, 'и': 9, 'ж': 10, ' ': 11, 'р': 12, 'у': 13, 'ф': 14, 'п': 15, 'с': 16, 'ю': 17, 'в': 18, 'е': 19, 'н': 20, 'ц': 21, 'т': 22, 'к': 23, 'ь': 24, 'д': 25}\n"
     ]
    }
   ],
   "source": [
    "print(char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest string has 10 characters\n"
     ]
    }
   ],
   "source": [
    "# Выравнивание всех строк до фиксированной (максимальной) длины:\n",
    "\n",
    "maxlen = len(max(text, key=len))\n",
    "print(\"The longest string has {} characters\".format(maxlen))\n",
    "\n",
    "# Padding\n",
    "\n",
    "# A simple loop that loops through the list of sentences and adds a ' ' whitespace until the length of the sentence matches\n",
    "# the length of the longest sentence\n",
    "\n",
    "for i in range(len(text)):\n",
    "    while len(text[i])<maxlen:\n",
    "        text[i] += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence: агафья   \n",
      "Target Sequence: гафья    \n",
      "Input Sequence: аглая    \n",
      "Target Sequence: глая     \n",
      "Input Sequence: агния    \n",
      "Target Sequence: гния     \n",
      "Input Sequence: агриппина\n",
      "Target Sequence: гриппина \n",
      "Input Sequence: акулина  \n",
      "Target Sequence: кулина   \n",
      "Input Sequence: алевтина \n",
      "Target Sequence: левтина  \n",
      "Input Sequence: александр\n",
      "Target Sequence: лександра\n",
      "Input Sequence: алина    \n",
      "Target Sequence: лина     \n",
      "Input Sequence: алла     \n",
      "Target Sequence: лла      \n",
      "Input Sequence: анастасия\n",
      "Target Sequence: настасия \n",
      "Input Sequence: ангелина \n",
      "Target Sequence: нгелина  \n",
      "Input Sequence: анжела   \n",
      "Target Sequence: нжела    \n",
      "Input Sequence: анжелика \n",
      "Target Sequence: нжелика  \n",
      "Input Sequence: анна     \n",
      "Target Sequence: нна      \n",
      "Input Sequence: антонина \n",
      "Target Sequence: нтонина  \n",
      "Input Sequence: анфиса   \n",
      "Target Sequence: нфиса    \n",
      "Input Sequence: валентина\n",
      "Target Sequence: алентина \n",
      "Input Sequence: валерия  \n",
      "Target Sequence: алерия   \n",
      "Input Sequence: варвара  \n",
      "Target Sequence: арвара   \n",
      "Input Sequence: василиса \n",
      "Target Sequence: асилиса  \n",
      "Input Sequence: вера     \n",
      "Target Sequence: ера      \n",
      "Input Sequence: вероника \n",
      "Target Sequence: ероника  \n",
      "Input Sequence: виктория \n",
      "Target Sequence: иктория  \n",
      "Input Sequence: галина   \n",
      "Target Sequence: алина    \n",
      "Input Sequence: глафира  \n",
      "Target Sequence: лафира   \n",
      "Input Sequence: гликерия \n",
      "Target Sequence: ликерия  \n",
      "Input Sequence: дана     \n",
      "Target Sequence: ана      \n",
      "Input Sequence: дарья    \n",
      "Target Sequence: арья     \n",
      "Input Sequence: евгения  \n",
      "Target Sequence: вгения   \n",
      "Input Sequence: евдокия  \n",
      "Target Sequence: вдокия   \n",
      "Input Sequence: евлалия  \n",
      "Target Sequence: влалия   \n",
      "Input Sequence: евлампия \n",
      "Target Sequence: влампия  \n",
      "Input Sequence: евпраксия\n",
      "Target Sequence: впраксия \n",
      "Input Sequence: евфросини\n",
      "Target Sequence: вфросиния\n",
      "Input Sequence: екатерина\n",
      "Target Sequence: катерина \n",
      "Input Sequence: елена    \n",
      "Target Sequence: лена     \n",
      "Input Sequence: елизавета\n",
      "Target Sequence: лизавета \n",
      "Input Sequence: епистима \n",
      "Target Sequence: пистима  \n",
      "Input Sequence: ермиония \n",
      "Target Sequence: рмиония  \n",
      "Input Sequence: жанна    \n",
      "Target Sequence: анна     \n",
      "Input Sequence: зинаида  \n",
      "Target Sequence: инаида   \n",
      "Input Sequence: злата    \n",
      "Target Sequence: лата     \n",
      "Input Sequence: зоя      \n",
      "Target Sequence: оя       \n",
      "Input Sequence: инга     \n",
      "Target Sequence: нга      \n",
      "Input Sequence: инесса   \n",
      "Target Sequence: несса    \n",
      "Input Sequence: инна     \n",
      "Target Sequence: нна      \n",
      "Input Sequence: иоанна   \n",
      "Target Sequence: оанна    \n",
      "Input Sequence: ираида   \n",
      "Target Sequence: раида    \n",
      "Input Sequence: ирина    \n",
      "Target Sequence: рина     \n",
      "Input Sequence: ия       \n",
      "Target Sequence: я        \n",
      "Input Sequence: капитолин\n",
      "Target Sequence: апитолина\n",
      "Input Sequence: карина   \n",
      "Target Sequence: арина    \n",
      "Input Sequence: каролина \n",
      "Target Sequence: аролина  \n",
      "Input Sequence: кира     \n",
      "Target Sequence: ира      \n",
      "Input Sequence: клавдия  \n",
      "Target Sequence: лавдия   \n",
      "Input Sequence: ксения   \n",
      "Target Sequence: сения    \n",
      "Input Sequence: лада     \n",
      "Target Sequence: ада      \n",
      "Input Sequence: лариса   \n",
      "Target Sequence: ариса    \n",
      "Input Sequence: лидия    \n",
      "Target Sequence: идия     \n",
      "Input Sequence: лилия    \n",
      "Target Sequence: илия     \n",
      "Input Sequence: любовь   \n",
      "Target Sequence: юбовь    \n",
      "Input Sequence: людмила  \n",
      "Target Sequence: юдмила   \n",
      "Input Sequence: маргарита\n",
      "Target Sequence: аргарита \n",
      "Input Sequence: марина   \n",
      "Target Sequence: арина    \n",
      "Input Sequence: мария    \n",
      "Target Sequence: ария     \n",
      "Input Sequence: марфа    \n",
      "Target Sequence: арфа     \n",
      "Input Sequence: матрёна  \n",
      "Target Sequence: атрёна   \n",
      "Input Sequence: милица   \n",
      "Target Sequence: илица    \n",
      "Input Sequence: мирослава\n",
      "Target Sequence: ирослава \n",
      "Input Sequence: надежда  \n",
      "Target Sequence: адежда   \n",
      "Input Sequence: наталья  \n",
      "Target Sequence: аталья   \n",
      "Input Sequence: нина     \n",
      "Target Sequence: ина      \n",
      "Input Sequence: нонна    \n",
      "Target Sequence: онна     \n",
      "Input Sequence: оксана   \n",
      "Target Sequence: ксана    \n",
      "Input Sequence: октябрина\n",
      "Target Sequence: ктябрина \n",
      "Input Sequence: олимпиада\n",
      "Target Sequence: лимпиада \n",
      "Input Sequence: ольга    \n",
      "Target Sequence: льга     \n",
      "Input Sequence: павлина  \n",
      "Target Sequence: авлина   \n",
      "Input Sequence: пелагея  \n",
      "Target Sequence: елагея   \n",
      "Input Sequence: пинна    \n",
      "Target Sequence: инна     \n",
      "Input Sequence: полина   \n",
      "Target Sequence: олина    \n",
      "Input Sequence: прасковья\n",
      "Target Sequence: расковья \n",
      "Input Sequence: рада     \n",
      "Target Sequence: ада      \n",
      "Input Sequence: раиса    \n",
      "Target Sequence: аиса     \n",
      "Input Sequence: римма    \n",
      "Target Sequence: имма     \n",
      "Input Sequence: светлана \n",
      "Target Sequence: ветлана  \n",
      "Input Sequence: серафима \n",
      "Target Sequence: ерафима  \n",
      "Input Sequence: снежана  \n",
      "Target Sequence: нежана   \n",
      "Input Sequence: софия    \n",
      "Target Sequence: офия     \n",
      "Input Sequence: таисия   \n",
      "Target Sequence: аисия    \n",
      "Input Sequence: тамара   \n",
      "Target Sequence: амара    \n",
      "Input Sequence: татьяна  \n",
      "Target Sequence: атьяна   \n",
      "Input Sequence: улита    \n",
      "Target Sequence: лита     \n",
      "Input Sequence: ульяна   \n",
      "Target Sequence: льяна    \n",
      "Input Sequence: урсула   \n",
      "Target Sequence: рсула    \n",
      "Input Sequence: фаина    \n",
      "Target Sequence: аина     \n",
      "Input Sequence: феврония \n",
      "Target Sequence: еврония  \n",
      "Input Sequence: фёкла    \n",
      "Target Sequence: ёкла     \n",
      "Input Sequence: феодора  \n",
      "Target Sequence: еодора   \n",
      "Input Sequence: целестина\n",
      "Target Sequence: елестина \n",
      "Input Sequence: юлия     \n",
      "Target Sequence: лия      \n",
      "Input Sequence: яна      \n",
      "Target Sequence: на       \n",
      "Input Sequence: ярослава \n",
      "Target Sequence: рослава  \n"
     ]
    }
   ],
   "source": [
    "# Подготовка входных и выходных последовательностей:\n",
    "\n",
    "input_seq = [] # исходная последовательность\n",
    "target_seq = [] # последовательность, смещенная на 1 (без первого символа)\n",
    "\n",
    "for i in range(len(text)):\n",
    "    # Remove last character for input sequence\n",
    "    input_seq.append(text[i][:-1])\n",
    "    \n",
    "    # Remove firsts character for target sequence\n",
    "    target_seq.append(text[i][1:])\n",
    "    \n",
    "    print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot энкодер (для батча примеров фиксированной длины)\n",
    "\n",
    "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
    "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
    "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "    \n",
    "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
    "    for i in range(batch_size):\n",
    "        for u in range(seq_len):\n",
    "            features[i, u, sequence[i][u]] = 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['агафья   ', 'аглая    ', 'агния    ', 'агриппина', 'акулина  ', 'алевтина ', 'александр', 'алина    ', 'алла     ', 'анастасия', 'ангелина ', 'анжела   ', 'анжелика ', 'анна     ', 'антонина ', 'анфиса   ', 'валентина', 'валерия  ', 'варвара  ', 'василиса ', 'вера     ', 'вероника ', 'виктория ', 'галина   ', 'глафира  ', 'гликерия ', 'дана     ', 'дарья    ', 'евгения  ', 'евдокия  ', 'евлалия  ', 'евлампия ', 'евпраксия', 'евфросини', 'екатерина', 'елена    ', 'елизавета', 'епистима ', 'ермиония ', 'жанна    ', 'зинаида  ', 'злата    ', 'зоя      ', 'инга     ', 'инесса   ', 'инна     ', 'иоанна   ', 'ираида   ', 'ирина    ', 'ия       ', 'капитолин', 'карина   ', 'каролина ', 'кира     ', 'клавдия  ', 'ксения   ', 'лада     ', 'лариса   ', 'лидия    ', 'лилия    ', 'любовь   ', 'людмила  ', 'маргарита', 'марина   ', 'мария    ', 'марфа    ', 'матрёна  ', 'милица   ', 'мирослава', 'надежда  ', 'наталья  ', 'нина     ', 'нонна    ', 'оксана   ', 'октябрина', 'олимпиада', 'ольга    ', 'павлина  ', 'пелагея  ', 'пинна    ', 'полина   ', 'прасковья', 'рада     ', 'раиса    ', 'римма    ', 'светлана ', 'серафима ', 'снежана  ', 'софия    ', 'таисия   ', 'тамара   ', 'татьяна  ', 'улита    ', 'ульяна   ', 'урсула   ', 'фаина    ', 'феврония ', 'фёкла    ', 'феодора  ', 'целестина', 'юлия     ', 'яна      ', 'ярослава '] 25 9 103\n"
     ]
    }
   ],
   "source": [
    "print(input_seq, dict_size, seq_len, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение входного и выходного тензора:\n",
    "# batch_size x seq_len x dict_size ; seq_len = maxlen - 1\n",
    "\n",
    "dict_size = len(char2int)\n",
    "seq_len = maxlen - 1\n",
    "batch_size = len(text)\n",
    "\n",
    "# Symbol seq to int seq:\n",
    "for i in range(len(text)):\n",
    "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
    "    target_seq[i] = [char2int[character] for character in target_seq[i]]\n",
    "\n",
    "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
    "input_seq = torch.from_numpy(input_seq)\n",
    "# print(f\"Input shape: {input_seq.shape} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\", input_seq)\n",
    "\n",
    "# --- --- --- ---\n",
    "# target_seq = one_hot_encode(target_seq, dict_size, seq_len, batch_size)\n",
    "target_seq = torch.Tensor(target_seq) # from list; without one-hot encoding\n",
    "\n",
    "# print(f\"Target shape: {input_seq.shape} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\", target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = False # torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Модель__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn.RNN(*args, **kwargs)`\n",
    "\n",
    "For each element in the input sequence, each layer computes the following function:\n",
    "\n",
    "$$ h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh}) $$\n",
    "\n",
    "Shape:\n",
    "\n",
    "_Input:_\n",
    "\n",
    "* __input__ of shape (seq_len, batch, input_size): tensor containing the features of the input sequence. The input can also be a packed variable length sequence.\n",
    "* __h_0__ of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. If the RNN is bidirectional, num_directions should be 2, else it should be 1.\n",
    "\n",
    "_Output:_\n",
    "* __output__ of shape (seq_len, batch, num_directions * hidden_size): tensor containing the output features (h_t) from the last layer of the RNN, for each t.\n",
    "* __h_n__ of shape (num_layers * num_directions, batch, hidden_size): tensor containing the hidden state for t = seq_len.\n",
    "\n",
    "Parameters:\n",
    "* `input_size` -  The number of expected features in the input `x`\n",
    "* `hidden_size` - The number of features in the hidden state `h`\n",
    "* `num_layers` - Number of recurrent layers. E.g., setting ``num_layers=2`` would mean stacking two RNNs together to form a `stacked RNN`, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1\n",
    "* `nonlinearity` - The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n",
    "* `bias` - If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`. Default: ``True``\n",
    "* `batch_first` - If ``True``, then the input and output tensors are provided as `(batch, seq, feature)`. Default: ``False``\n",
    "* `dropout` - If non-zero, introduces a `Dropout` layer on the outputs of each RNN layer except the last layer, with dropout probability equal to `dropout`. Default: 0\n",
    "* `bidirectional` - If ``True``, becomes a bidirectional RNN. Default: ``False``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "#         print('d1: ', out.size())\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "#         print('d2: ', out.size())\n",
    "        out = self.fc(out)\n",
    "#         print('d3: ', out.size())\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем инстанс модели с установленными гиперпараметрами\n",
    "\n",
    "model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n",
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = model(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.,  5., 14., 24.,  4., 11., 11., 11., 11.,  8.,  2.,  5.,  4., 11.,\n",
       "         11., 11., 11., 11.,  8., 20.,  9.,  4., 11., 11., 11., 11., 11.,  8.,\n",
       "         12.,  9., 15., 15.,  9., 20.,  5., 11., 23., 13.,  2.,  9., 20.,  5.,\n",
       "         11., 11., 11.,  2., 19., 18., 22.,  9., 20.,  5., 11., 11.,  2., 19.,\n",
       "         23., 16.,  5., 20., 25., 12.,  5.,  2.,  9., 20.,  5., 11., 11., 11.,\n",
       "         11., 11.,  2.,  2.,  5., 11., 11., 11., 11., 11., 11., 20.,  5., 16.,\n",
       "         22.,  5., 16.,  9.,  4., 11., 20.,  8., 19.,  2.,  9., 20.,  5., 11.,\n",
       "         11., 20., 10., 19.,  2.,  5., 11., 11., 11., 11., 20., 10., 19.,  2.,\n",
       "          9., 23.,  5., 11., 11., 20., 20.,  5., 11., 11., 11., 11., 11., 11.,\n",
       "         20., 22.,  0., 20.,  9., 20.,  5., 11., 11., 20., 14.,  9., 16.,  5.,\n",
       "         11., 11., 11., 11.,  5.,  2., 19., 20., 22.,  9., 20.,  5., 11.,  5.,\n",
       "          2., 19., 12.,  9.,  4., 11., 11., 11.,  5., 12., 18.,  5., 12.,  5.,\n",
       "         11., 11., 11.,  5., 16.,  9.,  2.,  9., 16.,  5., 11., 11., 19., 12.,\n",
       "          5., 11., 11., 11., 11., 11., 11., 19., 12.,  0., 20.,  9., 23.,  5.,\n",
       "         11., 11.,  9., 23., 22.,  0., 12.,  9.,  4., 11., 11.,  5.,  2.,  9.,\n",
       "         20.,  5., 11., 11., 11., 11.,  2.,  5., 14.,  9., 12.,  5., 11., 11.,\n",
       "         11.,  2.,  9., 23., 19., 12.,  9.,  4., 11., 11.,  5., 20.,  5., 11.,\n",
       "         11., 11., 11., 11., 11.,  5., 12., 24.,  4., 11., 11., 11., 11., 11.,\n",
       "         18.,  8., 19., 20.,  9.,  4., 11., 11., 11., 18., 25.,  0., 23.,  9.,\n",
       "          4., 11., 11., 11., 18.,  2.,  5.,  2.,  9.,  4., 11., 11., 11., 18.,\n",
       "          2.,  5.,  6., 15.,  9.,  4., 11., 11., 18., 15., 12.,  5., 23., 16.,\n",
       "          9.,  4., 11., 18., 14., 12.,  0., 16.,  9., 20.,  9.,  4., 23.,  5.,\n",
       "         22., 19., 12.,  9., 20.,  5., 11.,  2., 19., 20.,  5., 11., 11., 11.,\n",
       "         11., 11.,  2.,  9.,  1.,  5., 18., 19., 22.,  5., 11., 15.,  9., 16.,\n",
       "         22.,  9.,  6.,  5., 11., 11., 12.,  6.,  9.,  0., 20.,  9.,  4., 11.,\n",
       "         11.,  5., 20., 20.,  5., 11., 11., 11., 11., 11.,  9., 20.,  5.,  9.,\n",
       "         25.,  5., 11., 11., 11.,  2.,  5., 22.,  5., 11., 11., 11., 11., 11.,\n",
       "          0.,  4., 11., 11., 11., 11., 11., 11., 11., 20.,  8.,  5., 11., 11.,\n",
       "         11., 11., 11., 11., 20., 19., 16., 16.,  5., 11., 11., 11., 11., 20.,\n",
       "         20.,  5., 11., 11., 11., 11., 11., 11.,  0.,  5., 20., 20.,  5., 11.,\n",
       "         11., 11., 11., 12.,  5.,  9., 25.,  5., 11., 11., 11., 11., 12.,  9.,\n",
       "         20.,  5., 11., 11., 11., 11., 11.,  4., 11., 11., 11., 11., 11., 11.,\n",
       "         11., 11.,  5., 15.,  9., 22.,  0.,  2.,  9., 20.,  5.,  5., 12.,  9.,\n",
       "         20.,  5., 11., 11., 11., 11.,  5., 12.,  0.,  2.,  9., 20.,  5., 11.,\n",
       "         11.,  9., 12.,  5., 11., 11., 11., 11., 11., 11.,  2.,  5., 18., 25.,\n",
       "          9.,  4., 11., 11., 11., 16., 19., 20.,  9.,  4., 11., 11., 11., 11.,\n",
       "          5., 25.,  5., 11., 11., 11., 11., 11., 11.,  5., 12.,  9., 16.,  5.,\n",
       "         11., 11., 11., 11.,  9., 25.,  9.,  4., 11., 11., 11., 11., 11.,  9.,\n",
       "          2.,  9.,  4., 11., 11., 11., 11., 11., 17.,  7.,  0., 18., 24., 11.,\n",
       "         11., 11., 11., 17., 25.,  6.,  9.,  2.,  5., 11., 11., 11.,  5., 12.,\n",
       "          8.,  5., 12.,  9., 22.,  5., 11.,  5., 12.,  9., 20.,  5., 11., 11.,\n",
       "         11., 11.,  5., 12.,  9.,  4., 11., 11., 11., 11., 11.,  5., 12., 14.,\n",
       "          5., 11., 11., 11., 11., 11.,  5., 22., 12.,  3., 20.,  5., 11., 11.,\n",
       "         11.,  9.,  2.,  9., 21.,  5., 11., 11., 11., 11.,  9., 12.,  0., 16.,\n",
       "          2.,  5., 18.,  5., 11.,  5., 25., 19., 10., 25.,  5., 11., 11., 11.,\n",
       "          5., 22.,  5.,  2., 24.,  4., 11., 11., 11.,  9., 20.,  5., 11., 11.,\n",
       "         11., 11., 11., 11.,  0., 20., 20.,  5., 11., 11., 11., 11., 11., 23.,\n",
       "         16.,  5., 20.,  5., 11., 11., 11., 11., 23., 22.,  4.,  7., 12.,  9.,\n",
       "         20.,  5., 11.,  2.,  9.,  6., 15.,  9.,  5., 25.,  5., 11.,  2., 24.,\n",
       "          8.,  5., 11., 11., 11., 11., 11.,  5., 18.,  2.,  9., 20.,  5., 11.,\n",
       "         11., 11., 19.,  2.,  5.,  8., 19.,  4., 11., 11., 11.,  9., 20., 20.,\n",
       "          5., 11., 11., 11., 11., 11.,  0.,  2.,  9., 20.,  5., 11., 11., 11.,\n",
       "         11., 12.,  5., 16., 23.,  0., 18., 24.,  4., 11.,  5., 25.,  5., 11.,\n",
       "         11., 11., 11., 11., 11.,  5.,  9., 16.,  5., 11., 11., 11., 11., 11.,\n",
       "          9.,  6.,  6.,  5., 11., 11., 11., 11., 11., 18., 19., 22.,  2.,  5.,\n",
       "         20.,  5., 11., 11., 19., 12.,  5., 14.,  9.,  6.,  5., 11., 11., 20.,\n",
       "         19., 10.,  5., 20.,  5., 11., 11., 11.,  0., 14.,  9.,  4., 11., 11.,\n",
       "         11., 11., 11.,  5.,  9., 16.,  9.,  4., 11., 11., 11., 11.,  5.,  6.,\n",
       "          5., 12.,  5., 11., 11., 11., 11.,  5., 22., 24.,  4., 20.,  5., 11.,\n",
       "         11., 11.,  2.,  9., 22.,  5., 11., 11., 11., 11., 11.,  2., 24.,  4.,\n",
       "         20.,  5., 11., 11., 11., 11., 12., 16., 13.,  2.,  5., 11., 11., 11.,\n",
       "         11.,  5.,  9., 20.,  5., 11., 11., 11., 11., 11., 19., 18., 12.,  0.,\n",
       "         20.,  9.,  4., 11., 11.,  3., 23.,  2.,  5., 11., 11., 11., 11., 11.,\n",
       "         19.,  0., 25.,  0., 12.,  5., 11., 11., 11., 19.,  2., 19., 16., 22.,\n",
       "          9., 20.,  5., 11.,  2.,  9.,  4., 11., 11., 11., 11., 11., 11., 20.,\n",
       "          5., 11., 11., 11., 11., 11., 11., 11., 12.,  0., 16.,  2.,  5., 18.,\n",
       "          5., 11., 11.]),\n",
       " torch.Size([103, 9]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq.view(-1), target_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100............. Loss: 2.6348\n",
      "Epoch: 20/100............. Loss: 2.1549\n",
      "Epoch: 30/100............. Loss: 1.9723\n",
      "Epoch: 40/100............. Loss: 1.7659\n",
      "Epoch: 50/100............. Loss: 1.5775\n",
      "Epoch: 60/100............. Loss: 1.4626\n",
      "Epoch: 70/100............. Loss: 1.3804\n",
      "Epoch: 80/100............. Loss: 1.3168\n",
      "Epoch: 90/100............. Loss: 1.2665\n",
      "Epoch: 100/100............. Loss: 1.2247\n"
     ]
    }
   ],
   "source": [
    "# Training Run\n",
    "input_seq = input_seq.to(device)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    #input_seq = input_seq.to(device)\n",
    "    output, hidden = model(input_seq)\n",
    "    \n",
    "    output = output.to(device)    \n",
    "    target_seq = target_seq.to(device)\n",
    "    \n",
    "    loss = criterion(output, target_seq.view(-1).long())\n",
    "#     loss = criterion(output.view(-1), target_seq.view(-1).long())\n",
    "    \n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, character):\n",
    "    # One-hot encoding our input to fit into the model\n",
    "    character = np.array([[char2int[c] for c in character]])\n",
    "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
    "    character = torch.from_numpy(character)\n",
    "    character = character.to(device)\n",
    "    \n",
    "    out, hidden = model(character)\n",
    "\n",
    "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
    "    # Taking the class with the highest probability score from the output\n",
    "    char_ind = torch.max(prob, dim=0)[1].item()\n",
    "\n",
    "    return int2char[char_ind], hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, out_len, start='hey'):\n",
    "    model.eval() # eval mode\n",
    "    start = start.lower()\n",
    "    # First off, run through the starting characters\n",
    "    chars = [ch for ch in start]\n",
    "    size = out_len - len(chars)\n",
    "    \n",
    "    # Now pass in the previous characters and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(model, chars)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'гутана                                       '"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(model, 45, 'гут')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch_1_5v2",
   "language": "python",
   "name": "pytorch_1_5v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
